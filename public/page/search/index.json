[{"content":"Rust takes forever to build. Im sure I could do alot better deploying the application. But who knows, maybe im doing great at deploying my [comment board](https://unorthodoxdev. net/comment) but what if there is some bug that I introduced that crashes the server 👻. What if while the server is crashed, Im at work??? Well good thing we can customize the default 504 page that nginx uses. So lets get started.\nFirst we will go to our /var/www/html folder and create a page called maintenance.html. Inside of maintenance I have put the following.\n\u0026lt;!doctype html\u0026gt; \u0026lt;title\u0026gt;Site Maintenance\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; body { text-align: center; padding: 150px; } h1 { font-size: 50px; } body { font: 20px Helvetica, sans-serif; color: #333; } article { display: block; text-align: left; width: 650px; margin: 0 auto; } a { color: #dc8100; text-decoration: none; } a:hover { color: #333; text-decoration: none; } \u0026lt;/style\u0026gt; \u0026lt;article\u0026gt; \u0026lt;h1\u0026gt;We\u0026amp;rsquo;ll be back soon!\u0026lt;/h1\u0026gt; \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;Sorry for the inconvenience but we\u0026amp;rsquo;re performing some maintenance at the moment. If you need to you can always \u0026lt;a href=\u0026#34;mailto:#\u0026#34;\u0026gt;contact us\u0026lt;/a\u0026gt;, otherwise I\u0026amp;rsquo;ll be back online shortly!\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026amp;mdash; Joshua Winters-Brown\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/article\u0026gt; Simple and sweet right? next, we have to edit our nginx default config. You can find that at /etc/nginx/sites-available/default.\nRemember! You must edit this files as sudo!\nInside of our config file, just below your ssl certificates (or your port 80 config. Who knows maybe your rocking http naked). paste the following\nerror_page 502 /maintenance.html; location = /maintenance.html { root /var/www/html; internal; } Next, you will need to restart your nginx server. You can do so via the following command\nsudo systemctl restart nginx Now, kill your service, and run to the url to try to capture the error.\n","date":"2023-07-27T12:09:39-04:00","permalink":"https://unorthodoxdev.net/post/implementing-a-sick-504-page/","title":"Implementing a Sick 504 Page"},{"content":"Boss: You cannot joke like that, they we take serious and get cofunded.\nBoss: Enjoy your hell burgers. (they had jalapenos in it).\nMe: What did you give me\u0026hellip; What is in my mouth\u0026hellip; CoWorker 1: I feel like over the course of the year ive dranke one yankee candle. CoWorker 2: (Enters Office, chatting with another CoWorker) Yeah he came out of my butt 24 years ago.\nMe: Wheres the boss? CoWorker: Hes out doing meat stuff.\nMe: Wow! I really dont read!\nCoWorker: Go get tea you\u0026rsquo;re an adult.\nCoWorker: You;ve just touched 20 years of weird hands, germs, and possible wank.\nCoWorker: Dont ride with him he basically maintains a blood alcohol level of .5.\nBoss: Well I guess you and him can make a plan based on what they did or didnt say. Plus what your CoWorker knows.\nBoss: Do she go to both places? Make sure we know what came from each place.\nBoss: So any day you cant work on? (sends picture of schedule) or (sends picture thursday friday). Me: I will work as much as you want to schedule me. I have nothing going on and no friends. Boss: I am your friend.\nCoWorker 1: The mood at the Pizza Party is like a bread line in the great depression. CoWorker 2: (Busting into the room) History.com has me fucked up this morning.\nCoWorker: Babies are cute, but I wouldnt want to touch one.\nBoss: Please make work order for dong. Put good notes in the josh log.\nBoss: Client, \\n\\n We are dong.\nClient to me: I think I may have a virus or something\u0026hellip; I dont know it just stopped working\u0026hellip; Y\u0026rsquo;know, things like porn creep up on you.\nCoWorker: All, \\n After talking internally, please hold the reset button for 15 seconds. \\n regards, coworker\n","date":"2023-07-27T09:47:54-04:00","permalink":"https://unorthodoxdev.net/post/quotes-associated-with-work/","title":"Quotes Associated With Work"},{"content":"Actix and Askama Webserver and Rendering Now we move onto the main.rs file, this is particularly simple as we will only be worried about two routes. a get('/comment/') and a post('/comment/new'). To start, I chose to use Askama for templating since its closest to what im comforatble with (mustache templating). Overall askama is pretty simple. We have to create a Template that links to our template file. We will then add the content that we want to send to the template. Typically this is done with a struct.\nSince we are interfacing with the library, we will have to duplicate our code here and create a template of our array of templates instead of just passing a long our array of templates. We can do so by\u0026hellip;\n#[derive(Template)] // this will generate the code... #[template(path = \u0026#34;index.html\u0026#34;)] pub struct CommentTemplate { comments: Vec\u0026lt;cmanager::Comment\u0026gt;, } Next we will, create our #[actix_web::main] function.\n#[actix_web::main] async fn main() -\u0026gt; std::io::Result\u0026lt;()\u0026gt; { HttpServer::new(|| { App::new() .service(web::resource(\u0026#34;/\u0026#34;).to(|| async { CommentTemplate {comments: cmanager::get_all()}})) }) .bind((\u0026#34;0.0.0.0\u0026#34;, 8080))? .run() .await } Notice that we build the route, we are creating a function with the || async {} and then calling on our CommentTemplate that should have all the needed code generated with the macro. Before we run this thing though, were missing one more file. The index.html refrenced by the template. To get that we will have to create a folder in our root directory called templates. Then include a file called index.html. I wont link my css here but you can view the active template file HERE.\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;IE=edge\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Comments\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;input-section\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;Submit Your Comment\u0026lt;/h2\u0026gt; \u0026lt;form action=\u0026#34;/comment/new\u0026#34; method=\u0026#34;post\u0026#34; id=\u0026#34;new_comment\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;username\u0026#34; id=\u0026#34;username\u0026#34; placeholder=\u0026#34;whats your name anon?\u0026#34; maxlength=\u0026#34;500\u0026#34; required\u0026gt; \u0026lt;textarea id=\u0026#34;comment\u0026#34; name=\u0026#34;comment\u0026#34; maxlength=\u0026#34;10000\u0026#34; placeholder=\u0026#34;whats on your mind....\u0026#34; spellcheck=\u0026#34;true\u0026#34; required \u0026gt;\u0026lt;/textarea\u0026gt; \u0026lt;button id=\u0026#34;submit\u0026#34;\u0026gt;Send!\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;comment-section\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;Comments\u0026lt;/h2\u0026gt; \u0026lt;ul id=\u0026#34;comments\u0026#34;\u0026gt; {% for comment in comments %} \u0026lt;div id=\u0026#34;comment\u0026#34;\u0026gt; {% if comment.visible == 1 %} \u0026lt;li id=\u0026#34;comment_id\u0026#34; hidden\u0026gt;{{comment.id}}\u0026lt;/li\u0026gt; \u0026lt;li id=\u0026#34;comment_ip\u0026#34; hidden\u0026gt;{{comment.ip}}\u0026lt;/li\u0026gt; \u0026lt;li id=\u0026#34;comment_username\u0026#34;\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;{{comment.username}}\u0026lt;/b\u0026gt; says...\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li id=\u0026#34;comment_input\u0026#34;\u0026gt;{{comment.comment}}\u0026lt;/li\u0026gt; \u0026lt;li id=\u0026#34;comment_timestamp\u0026#34;\u0026gt;{{comment.timestamp}}\u0026lt;/li\u0026gt; {% endif %} \u0026lt;/div\u0026gt; {% endfor %} \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Above, you can see the {% for comment in comments %}. Thats all voodo stuff askama does. So no need for us to worry about it other than, know it is a loop that iterates over our vector. Also ive got a conditional statement, {% if comments.visible == 1 %}. This only shows the comments that are visible and not hiddne. Im sure that eventually I need to completely remove that conditional and do it at the sql request side, but I kind of like the idea of being able to pull all comments, regardless of weather or not I want to show them or not.\nFinally, when you run your instance, You will probably see that there nothing populates. That is most likely because there are no comments yet. That brings us into the next step, lets work on the POST function. We will start by creating the new function on in our main.rs\n#[derive(Deserialize)] #[derive(Debug)] struct FormData { username: String, comment: String, } async fn new(web::Form(form): web::Form\u0026lt;FormData\u0026gt;, req: HttpRequest) -\u0026gt; impl Responder { let ip = req.peer_addr().unwrap_or(SocketAddr::new(IpAddr::V4(Ipv4Addr::new(6, 6, 6, 6)), 666)).ip(); let username = form.username; let comment = form.comment; let _ = cmanager::new(ip.to_string(), username, comment); // CommentTemplate {comments: cmanager::get_all()} web::redirect(\u0026#34;/comment/new\u0026#34;, \u0026#34;/\u0026#34;) } Starting from top to bottom, we create a new function that intakes FormData a new struct we have created that represents the content being sent to us from the HTML form. We also take in as an accept parameter the req: HttpRequest this allows us to capture the IP address of the sender. After translating the FormData into some new variables, we input it into our cmanager::new(); to create a new comment entry. Wrapping it all up with a redirect to the root domain, scince I dont really want to deal with re rendering the in every function. Although in the future that may change. What if I want to give a dynamic error message about how you didnt read the rules? How would that work? Either way, to actually use the new() function we need to add it as a route, in our App::new(). The new main function looks like below,\n#[actix_web::main] async fn main() -\u0026gt; std::io::Result\u0026lt;()\u0026gt; { HttpServer::new(|| { App::new() .service(web::resource(\u0026#34;/\u0026#34;).to(|| async { CommentTemplate {comments: cmanager::get_all()}})) .route(\u0026#34;/comment/new\u0026#34;, web::post().to(new)) }) .bind((\u0026#34;0.0.0.0\u0026#34;, 8080))? .run() .await } Now go ahead and build your comment board, and run it. It should be able to accept comments and display them when you go to the homepage.\n","date":"2023-07-26T12:08:38-04:00","permalink":"https://unorthodoxdev.net/post/making-a-comment-board-part-3/","title":"Making a Comment Board Part 3"},{"content":"Finishing Up CManager Between the last post and the current post, ive made a few changes to the CManager. The first is the struct now contains a time stamp.\n#[derive(Debug)] pub struct Comment { pub id: Uuid, pub ip: String, pub username: String, pub comment: String, pub timestamp: String, pub visible: i64, } besides that everything else stays the same. Currently there are two functions new() and get_all(). New intakes only two paramters, a String for the username and a string for the comment.\nOne of the first things I do is take create a sha256 sum of the IP by doing the following\nlet sha_ip = digest(\u0026amp;ip.replace(\u0026#34;:\u0026#34;, \u0026#34;\u0026#34;)); Fun fact, I found out that sha256 sums do not work well with special characters like a :. So replacing it with noting helped make the string replacable. After converting our IP it was time to move onto some content filtering. Im sure that some of this code could be extrapulated into a private function, something like check_content_length() but for now its here.\nWe basically sift through a series of if statements to confirm that none of the values are over a maximum lenght. Looking at the code im sure that I could do a for loop here.\nif username.len() \u0026gt; 500 { let problem_comment = Comment { id: Uuid::new_v4(), ip: sha_ip.to_string(), username: \u0026#34;error\u0026#34;.to_string(), comment: comment, timestamp: Utc::now().to_string(), visible: 0, }; let username_too_long = CommentError { error: \u0026#34;Error, your user name was over 500 characters, this attempt has been logged, and will be reviewed later. Pleas try again :)\u0026#34;.to_string(), comment: problem_comment, }; return Err(username_too_long); } if comment.len() \u0026gt; 10000 { let problem_comment = Comment { id: Uuid::new_v4(), ip: sha_ip.to_string(), username: username, comment: \u0026#34;error\u0026#34;.to_string(), timestamp: Utc::now().to_string(), visible: 0, }; let comment_too_long = CommentError { error: \u0026#34;Error, your comment was over 10,000 characters, this attempt has been logged, and will be reviewed later. Pleas try again :)\u0026#34;.to_string(), comment: problem_comment }; return Err(comment_too_long); } Finally, we commit our comment, into a new variable, and open our database up. We then generate a query and insert the comment into the database forming a record. To finish off the function, we return an Ok and the incoming comment.\n// Everything looks good, lets move forward with commiting the information to the database. let incoming_comment = Comment { id: Uuid::new_v4(), ip: sha_ip.to_string(), username: username, comment: comment, timestamp: Utc::now().to_string(), visible: 1, }; let connection = sqlite::open(\u0026#34;comments.db\u0026#34;).unwrap(); let query = format!(\u0026#34; CREATE TABLE IF NOT EXISTs comments (id TEXT NOT NULL PRIMARY KEY, ip TEXT, username TEXT NOT NULL, comment TEXT NOT NULL, timestamp TEXT, visible INT NOT NULL); INSERT INTO comments VALUES (\u0026#39;{}\u0026#39;, \u0026#39;{}\u0026#39;, \u0026#39;{}\u0026#39;, \u0026#39;{}\u0026#39;, \u0026#39;{}\u0026#39;, {})\u0026#34;, incoming_comment.id, incoming_comment.ip, incoming_comment.username, incoming_comment.comment, incoming_comment.timestamp, incoming_comment.visible ); connection.execute(query).unwrap(); // All looks good, lets return it. Ok(incoming_comment) That was about the most complicated part of the CManager library. The next function we will cover is the get_all() function. Every now and then I get the urge to just overload a function in rust. Then I remember thats no bueno. So I think traits. But traits confuse me. So I keep my brain smooth by making functions like get_all() which I think is unanimously acceptable.\nThe get_all() function is pretty simple. We return a vector of Comment, we affecitionally will reffer to this as comments. We return our comments by running a query SELECT * FROM comments ORDER BY timestamp DESC LIMIT 50;. We then iterate through our Statements and create a comment for each row. Then before iterating to the next row in our statement, we will commit our comment, by adding it to the vector comments.\nFinally, we will return our vector and allow the client to whatever they would like with it.\npub fn get_all() -\u0026gt; Vec\u0026lt;Comment\u0026gt; { let mut comments: Vec\u0026lt;Comment\u0026gt; = vec![]; let connection = sqlite::open(\u0026#34;comments.db\u0026#34;).unwrap(); // Note we had to split up the blow two statements. For some reason, the statement.next() function later down the program would not pull comments when we ran the CREATE TABLE command. // Maybe its because I didnt do the format!() like i did in the new comment function??? // The compiler is angry here, i know. Ill fix it all later, but for now it looks aesthetically pleasing uwu. let mut query = \u0026#34;SELECT * FROM comments ORDER BY timestamp DESC LIMIT 50;\u0026#34;; let mut statement = connection.prepare(query).unwrap(); while let Ok(State::Row) = statement.next() { let temp_id = statement.read::\u0026lt;String, _\u0026gt;(\u0026#34;id\u0026#34;).unwrap(); let id: Uuid = Uuid::parse_str(\u0026amp;temp_id).unwrap(); comments.push(Comment { id: id, ip: statement.read::\u0026lt;String, _\u0026gt;(\u0026#34;ip\u0026#34;).unwrap().to_string(), username: statement.read::\u0026lt;String, _\u0026gt;(\u0026#34;username\u0026#34;).unwrap().to_string(), comment: statement.read::\u0026lt;String, _\u0026gt;(\u0026#34;comment\u0026#34;).unwrap().to_string(), timestamp: statement.read::\u0026lt;String, _\u0026gt;(\u0026#34;timestamp\u0026#34;).unwrap(), visible: statement.read::\u0026lt;i64, _\u0026gt;(\u0026#34;visible\u0026#34;).unwrap(), }); } comments } While I dont think we have gone over a lot, i think that we are a bit too far as is to continue going on with the main.rs implementation. So I would like to put a pause here and continue forward in the next part.\n","date":"2023-07-24T10:11:15-04:00","permalink":"https://unorthodoxdev.net/post/making-a-comment-board-part-2/","title":"Making a Comment Board Part 2"},{"content":"comment.unorthodoxdev.net Currently, my blog is made using hugo. The theme that I am using has the capability to enable comments, although they would all be hosted on a third party. Unfortunately for me, im unwilling to signup for said third parties. One saturday morning as I was drinking my coffee and browsing the blogs that I follow, landed on a favorite of mine: https://blog.ari-web.xyz/.\nI really love ari\u0026rsquo;s blog. I think that Ari does what the web was supposed to do and really embodies the the nature of blogging. Something that I aspire to do. But am too introverted to even post things about my self online, personally I get too wrapped up in making sure everything is perfect, that when I do get the urge to post something I post it and avoid my computer for the rest of the day in fear of finding a misspelled word (which happens more often than not).\nOne of the features of Ari\u0026rsquo;s blog that I really like is the https://user.ari-web.xyz/ section. Its a comment board that anyone can post to anon or not. While i havent looked at what Ari\u0026rsquo;s comment section was written in, im planning on writing this comment section in rust. My goal for now is to seperate the project into two secions\nBinary: comment.unorthodoxdev.net\nLibrary: cmanager (Comments Manager)\nThe Binary will contain the code related to the web hooks and buisness logic.\nThe Library will contain the code that will store said comments into a JSON file or whatever database I decide to use (a JSON file).\nImplementation Of course, we always must start with the library. The first step to making this comment board is figuring out what kind of data structure we will use. For now I will avoid thinking about databases, and focus on just figuring out what our data is going to look like.\nI start by imaginging that we have a html web page, that users connect to. There we will have a form that allows users to input into the form, the following information\nUser Name Their Comment From there, they will click submit and then it will create a post or a put to some backend service that will gather the following information\nid ip username comment visible time ( i just thought of this and will need to add it in the future) From there it will do some kind of content filtering, checking that the string length is appropriate, checking that there arent any vulgar words, here we could have a filter list, Censored Words, and Banned Words. Banned Words will have the comment shown as hidden and be logged and stored, along with the banned word being censored. Censored words will just replace the word that is not allowed or approriate, and replace it with @@@@@. for example, \u0026ldquo;God i @@@@@@@ you joshua. I hope you die \u0026mdash; Anon\u0026rdquo;\nIm sure I wont be able to catch all the possible ban able words and or censored words, but it will be a fun experiment to work on with word processing.\nWhere I have left off, you can currently create a new comment using cmanager::new(ip, username, comment); the next step here is saving it. I initially wanted to do just a json file, but decided to go against that to get me comfortable with using SQL. So far, im hoping to use a sqlite database, since it can one file, uploaded with the repository, and! it doesnt make a lot of overhang on my project.\nSo far I have also done some content filtering in the data that cmanager::new recieves. Currently limits are set at 500 characters for all values with the exclusion of the comment in which, I have allowed a small hate filled paragraph to be typed out and submitted on the comment board (10,000 characters). Anything more than that is one of two things, not worth reading, or an spam/advertisement.\nThe reason I bring this feature up is because there are no try fail, loops in rust. If someone where to buffer overload my program, it would just simply quit to a unrecoverable fail state where I would have to then manually log in and start the program. But whos to say someone isnt constantly submitting comments to my comment board, breaking my system. To prevent that kind of behaviour you can strongly type into the program the abbility to encounter those errors, and tell the compiler what to do.\nFor example, within the cmanager::new() function, I have written an if statement that checks the length of those values. It then returns a Enum containing a struct, that contains two parts. Information about the reason the program errored out. And a sample of the data that caused the error. This allows for me to log, what caused that error, and continue moving on as if it was intended behaviour.\nSimply put, that error, that previously crashed the program is now intended behaviour.\n#[derive(Debug)] pub struct Comment { id: Uuid, ip: String, username: String, comment: String, visible: bool, } #[derive(Debug)] pub struct CommentError { error: String, comment: Comment, } enum CommentResult\u0026lt;Comment, CommentError\u0026gt; { Ok(Comment), Err(CommentError), } if ip.len() \u0026gt; 500 { let problem_comment = Comment { id: Uuid::new_v4(), ip: \u0026#34;error\u0026#34;.to_string(), username: username, comment: comment, visible: false, }; let ip_too_long = CommentError { error: \u0026#34;Error, your ip address was over 500 characters, this attempt has been logged, and will be reviewed later. Pleas try again :)\u0026#34;.to_string(), comment: problem_comment, }; return Err(ip_too_long); } ","date":"2023-07-21T12:48:09-04:00","permalink":"https://unorthodoxdev.net/post/making-a-comment-board-part-1/","title":"Making a Comment Board Part 1"},{"content":"Ive migrated my website from the ghost blogging platform to hugo (go hugo, go hugo, go!). Its a little simpler and easier to manage. I also feel as though I have more controll. Currently, im using the hugo-stacked-theme as it looks the most appealing to me, and is not a massive website with insane overhead. It also comes with a indexing feature that allows me (and you ofcourse) to search my content for specific keywords.\nAnother great thing about it being simple is I dont have to constantly monitor that the ghost instance isnt taking too much resources as the web server just lives on a static nginx route. The only thing I will have to get used to is making sure that before I push to the remote repository, that I have ran hugo so that it can build each of my pages.\nCurrently I am manually logging into the web server and pulling the repostory whenever I feel like it. In the future, ideally id set a cron job for every 30 minutes or something like that.\nehhh either way this new cms seems to be working. Keep in touch as im hoping to release a new feature to my website soon :)\n","date":"2023-07-21T10:58:35-04:00","image":"https://unorthodoxdev.net/post/new-blogging-system/this-is-fine_hu86dab14ef87193dda900efad440e3c50_48368_120x120_fill_box_smart1_3.png","permalink":"https://unorthodoxdev.net/post/new-blogging-system/","title":"New Bloging System"},{"content":"Read the damn instructions. Im working on a new project for the website, and Im trying to upload what I have to github (a simple readme nothing more).\nI create an empty repository, init, add, and commit locally. Set the remote repository, and try to push to the remote\u0026hellip; And it fails? What have I done? What did I do? I have done this probably thousands of times. Where did I mess up? Will I have to recreate the folder? Should I re init the local repo?\nWhat do i do?\nimmediately I search the error error, failed to push some refs to the remote github repository.. I find some stack overflow repository, and I begin reading. I trust stack over flow, they got some smart guys on there. Alot smarter guys on there than me because theres always awnsers to my questions.\nIt doesnt work. It doesnt work, what did I do. I followed the advice of this internet stranger. They posted the awnser recently (2021) what have I done. This is a catosrophic faliure on my end. Ill never be able to recover from this.\nI switch tabs back to my github repository after reading the advice one strange lonlely internet post, and I read the instructions given to me by github.\nOh\u0026hellip;\nIve forgotten to set the primary branch. Maybe ive had too much coffee.\n","date":"2023-07-21T10:50:07-04:00","permalink":"https://unorthodoxdev.net/post/read-the-damn-instructions/","title":"Read the Damn Instructions"},{"content":"Ive recently had an encounter with a printer that creates 100s of copies of its self within the computers printer settings. Ive spent quite a bit of time tinkering with this printer and its settings. I think I’ve come to a resolution. Overall, to recap what I did; Opening up the Regedit there were 100’s of keys associated with the Xerox printer. Typically, these registry keys are created when installing the printer and the windows printui.dll handles it. But the amount of registry keys meant that windows kept recreating these keys. I dug a little bit more into the registry keys and it appears that each of these keys had the following properties assigned to them. Name “PRT-AWH-321-COLOR”, Driver “Xerox …” that was pretty much it. The rest of the fields were empty.\nI started off looking into removing these printers via a script etc. Doing so I found the existence of a registry key we can create that would have windows remove the printers on exit. To enable this feature you would have to create a 32bit dWord key in the following location \u0026quot;HKLM:\\Software\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Providers\\Client Side Rendering Print Provider\u0026quot; with the name \u0026quot;RemovePrintersAtLogoff\u0026quot; and the value of 1.\nAfter creating this key, when a user logs out it should clear out any installed printers, and apply the group policy user settings next time a user logs in. Well creating that key and then logging out seemed to work. But those xerox registry keys persisted for some reason. I grabbed one of the GUIDS from a ghost printer and ran a search for all the instances I could find it in regedit. I ran across quite a few instances and ended up writing a script.\nWe start by stopping the printer spooler, and then removing the following:\nHKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Connections HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Printers HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Providers HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\V4 Connections HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Connections HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Printers HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Providers HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\V4 Connections HKCU:\\Printers HKCU:\\Software\\Microsoft\\Windows NT\\CurrentVersion\\PrinterPorts HKEY_USERS\\.DEFAULT\\Printers The following below you need a system user context to remove. You can do so by using PSExec from Windows PowerToys.\nHKLM:\\SYSTEM\\CurrentControlSet\\Enum\\SWD\\PRINTENUM HKLM:\\SYSTEM\\CurrentControlSet\\Control\\DeviceClasses\\{0ecef634-6ef0-472a-8085-5ad023ecbccd} HKLM:\\SYSTEM\\ControlSet001\\Enum\\SWD\\PRINTENUM HKLM:\\SYSTEM\\ControlSet001\\Control\\DeviceClasses\\{0ecef634-6ef0-472a-8085-5ad023ecbccd} HKLM:\\SYSTEM\\ControlSet002\\Enum\\SWD\\PRINTENUM HKLM:\\SYSTEM\\ControlSet002\\Control\\DeviceClasses\\{0ecef634-6ef0-472a-8085-5ad023ecbccd} HKLM:\\SYSTEM\\CurrentControlSet\\Control\\Class\\{1ed2bbf9-11f0-4084-b21f-ad83a8e6dcdc} After doing so, when you open up the control panel all the printers should be grayed out. Because these printers are being added via group policy, doing a reboot, should resolve any issues we had previously. Once the computer comes back up again, all of those printers should remain grey, and anything that gets installed via group policy should then fill in with color. But shortly after, it started happening again. I kept getting notifications of the printer installing, over and over and over again.\nWith that, its confirms that it is not some residual left over install, but narrows it down to one or two things. A messed up group policy or a bad driver. Looking at the group policy I could find anything wrong, so I decided to start at the driver. I took the computer off the domain, and downloaded the PCL, General, and PS, driver for the printer.\nOnce the computers off the domain, I remove all printers. And repeat the above steps. After doing so I started with the identical driver installed, the General driver. I setup the printer and as soon as the install finishes. I immediately get the same issue again.\nIts no longer a group policy issue, its now a driver issue. Uninstall all the printers again and start from step one. Once I get to installing the printer I use the PCL driver. I had similar issues. Finally the Post Script (PS) driver ended up working for me and resolved in no issues.\nEither way, cleaning up the ghost printers is a pain in my ass, and is nothing but manual labor. I ended up reimaging the comptuers after fixing the driver on the print server and going from there.\nSince then its seemed to have been fixed.\nScripts part-one.ps1\nNew-ItemProperty -Path \u0026#34;HKLM:\\Software\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Providers\\Client Side Rendering Print Provider\u0026#34; -Name \u0026#34;RemovePrintersAtLogoff\u0026#34; -Value 1 -Force Restart-Computer -Force part-two.ps1\nStop-Service spooler -Force Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Connections\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Printers\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Providers\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\V4 Connections\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Connections\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Printers\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Providers\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\V4 Connections\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKCU:\\Printers\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKCU:\\Software\\Microsoft\\Windows NT\\CurrentVersion\\PrinterPorts\u0026#34; -Recurse Remove-Item -Path \u0026#34;Registry::HKEY_USERS\\.DEFAULT\\Printers\u0026#34; -Recurse .\\PsExec.exe /accepteula .\\PsExec.exe powershell Remove-Item -Path \u0026#34;HKLM:\\SYSTEM\\CurrentControlSet\\Enum\\SWD\\PRINTENUM\u0026#34; -Recurse .\\PsExec.exe powershell Remove-Item -Path \u0026#34;HKLM:\\SYSTEM\\CurrentControlSet\\Control\\DeviceClasses\\{0ecef634-6ef0-472a-8085-5ad023ecbccd}\u0026#34; -Recurse .\\PsExec.exe powershell Remove-Item -Path \u0026#34;HKLM:\\SYSTEM\\ControlSet001\\Enum\\SWD\\PRINTENUM\u0026#34; -Recurse -ErrorAction SilentlyContinue .\\PsExec.exe powershell Remove-Item -Path \u0026#34;HKLM:\\SYSTEM\\ControlSet001\\Control\\DeviceClasses\\{0ecef634-6ef0-472a-8085-5ad023ecbccd}\u0026#34; -Recurse -ErrorAction SilentlyContinue .\\PsExec.exe powershell Remove-Item -Path \u0026#34;HKLM:\\SYSTEM\\ControlSet002\\Enum\\SWD\\PRINTENUM\u0026#34; -Recurse -ErrorAction SilentlyContinue .\\PsExec.exe powershell Remove-Item -Path \u0026#34;HKLM:\\SYSTEM\\ControlSet002\\Control\\DeviceClasses\\{0ecef634-6ef0-472a-8085-5ad023ecbccd}\u0026#34; -Recurse -ErrorAction SilentlyContinue .\\PsExec.exe powershell Remove-Item -Path \u0026#34;HKLM:\\SYSTEM\\CurrentControlSet\\Control\\Class\\{1ed2bbf9-11f0-4084-b21f-ad83a8e6dcdc}\u0026#34; -Recurse Restart-Computer -Force ","date":"2023-07-20T16:03:40-04:00","permalink":"https://unorthodoxdev.net/post/ghost-printers/","title":"Ghost Printers"},{"content":"Currently im looking into creating an application to harvest device information using the MECM API. Since I constantly have to research where the MECM Admin service has its hooks, i thought it would be a good idea to add some general information here.\nThe Basics The AdminService is a REST API that runs as a service, independent of the other web components in IIS on your site servers.\nService You can check the status of the service in the console under \\Monitoring\\Overview\\System Status\\Component Status - SMS_REST_PROVIDER\nRead-Only Query Basics Note: All queries in this section use a HTTP GET method. Also, everything is CASE SenSiTiVe.\nGet all Devices https://\u0026lt;ServerName\u0026gt;/AdminService/wmi/SMS_R_System Get All Users https://\u0026lt;ServerName\u0026gt;/AdminService/wmi/SMS_R_User Get Device By ResourceID (same syntax for users) https://\u0026lt;ServerName\u0026gt;/AdminService/wmi/SMS_R_System(12345678) Get User By ResourceID https://\u0026lt;ServerName\u0026gt;/AdminService/wmi/SMS_R_User(12345678) Retrieve related class information. This example gets Operating System information for a specific device. https://\u0026lt;ServerName\u0026gt;/AdminService/wmi/SMS_R_System(12345678)/SMS_G_System_OPERATING_SYSTEM ","date":"2023-07-19T21:02:50-04:00","permalink":"https://unorthodoxdev.net/post/mecm-api/","title":"MECM API"},{"content":"\nRepository: https://github.com/ofgrenudo/tattoo/tree/master\nTattoo is the first complete program that I have written in rust. It consists of two parts, a library and the binary. One of the challenges I experienced when writing this application was the lack of abbility to include files outside of module\u0026rsquo;s folder that I was writing in. While I understand now why you should not do so and the kinds of compiler problems you would encounter. I think that forcing me to write a library to manage my goals was very benificial for me.\nThis is the first library that I have had to write that actually does something. Something more than one plus one, or something simple you make when you learn C. This library was immediately applicable to my needs. It also helped me keep my programs logically seperate from eachother. The UI was allowed to get input from the UI and handle that. The backend was able to take the information from the UI and transcribe it into the database. This way of seperating the program made a dream like fusion for me when it came to keeping things clean.\nWriting the library also forced me to leverage the rust documentation feature. Really cementing the whole experience together.\nOverall, I really enjoyed the experience making this application and hope to have many more safe adventures with rust :)\nDescription Tattoo is a program designed to automatically collect device information on run, and insert it into the registry of the device. This information is intended for archival purposes and will remain there for later inspection. Some of the bennifits of storing information in the registry is that it provides a static and proctected way to maintain information like,\nThe day the computer was deployed. The task sequence used when you deployed the computer. The asset tag assigned. The device name when deployed. The serial number of the device. The device model. The device make. Requirements Windows \u0026gt;=10, or Windows Server 2016. PowerShell 5.1 or later Running In order to run tattoo.exe you will need at a minimum, the following file along side the executable.\ntatto.exe.manifest\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; standalone=\u0026#34;yes\u0026#34;?\u0026gt; \u0026lt;assembly xmlns=\u0026#34;urn:schemas-microsoft-com:asm.v1\u0026#34; manifestVersion=\u0026#34;1.0\u0026#34;\u0026gt; \u0026lt;assemblyIdentity version=\u0026#34;1.0.0.0\u0026#34; processorArchitecture=\u0026#34;*\u0026#34; name=\u0026#34;app\u0026#34; type=\u0026#34;win32\u0026#34; /\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;dependentAssembly\u0026gt; \u0026lt;assemblyIdentity type=\u0026#34;win32\u0026#34; name=\u0026#34;Microsoft.Windows.Common-Controls\u0026#34; version=\u0026#34;6.0.0.0\u0026#34; processorArchitecture=\u0026#34;*\u0026#34; publicKeyToken=\u0026#34;6595b64144ccf1df\u0026#34; language=\u0026#34;*\u0026#34; /\u0026gt; \u0026lt;/dependentAssembly\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/assembly\u0026gt; Otherwise it will throw an error exit code: 0xc0000139, STATUS_ENTRYPOINT_NOT_FOUND when trying to run the program. This is a bug with the native windows gui API that has not been resolved.\nExample Screenshots ","date":"2023-07-19T21:01:44-04:00","permalink":"https://unorthodoxdev.net/post/tattoo/","title":"Tattoo"},{"content":"Give a man a fish, and you feed him for a day. Teach a man to fish, and you feed him for a lifetime.\nCI, Continuous onus Integration allows for each member of a team to integrate their changes into the main branch, multiple times a day.\nContinuous Integration allows us to tighten the feed back loop. We are less likely to go off on your own and develop for days or weeks just to find out the approach you have taken isn\u0026rsquo;t working, or isn\u0026rsquo;t approved by peers. Continuous Integration forces you to work with your teammates earlier than when you feel is comfortable allowing for course correcting actions to be taken before you have wasted your time. So how do we make Continuous Integration a reality?\nTests Code Coverage Linting Formatting Security Vulnerabilities Tests Tests in rust are a first-class concept. This being said rust allows you to easily leverage the rust ecosystem to run unit and integration tests using\ncargo test cargo test also takes care of building the project before running tests saving you a command or two.\nCode Coverage Code coverage is a easy way to see if we have overlooked any section of the code base that have been poorly tested. The easiest way to measure code coverage of a rust project is via cargo tarpaulin a cargo subcommand developed by xd009642. You can install tarpaulin with\ncargo install cargo-tarpaulin You can run cargo-tarpaulin with\ncargo tarpaulin --ignore-tests Linting Rust maintains clippy the official rust linter. Clippy is included in the set of components installed by rustup if you are using the default profile. You can run clippy with\ncargo clippy In this CI pipeline we would like to fail the linter check if clippy emits any warnings. To do so we can run the following command\ncargo clippy -- -D warnings Note, from time to time clippy might suggest something you do not belive to be correct or desirable. You can mute these warnings with the following\n#[allow(clippy::lint_name)] Formatting Let machines deal with formatting while reviewers focus on architecture, testing thoroughness, reliability, and observability. Automated formatting removes a distraction from the complex equation of the PR review process. You might dislike this or that formatting choice but the complete erasure of formatting bikeshedding is worth the minor discomfort.\nRust actually has a built in formatter called rustfmt. rustfmt should be included in the default rustup components but if you are missing it you can install it via\nrustup component add rustfmt To format your whole project you can run\ncargo fmt In the CI pipeline we will ad a formatting step.\ncargo fmt -- --check This will ultimately fail when a commit contains unformatted code, printing the difference to the console. You can tune a project with a configuration file rustfmt.toml.\nSecurity Vulnerabilities Caro makes it very easy to leverage existing crates in the ecosystem to solve at hand. On the flip side, each of those crates might hide an exploitable vulnerability that could compromise the security posture of your software. The Rust Secure Code group maintains an Advisory Database on reported vulnerabilities for crates published on crates.io. You can leverage this advisory database with a tool called cargo-audit. You can install it with\ncargo install cargo-audit To use it you can run\ncargo audit Github Actions Below are some github actions you can add to your CI routines. To use them you will want too create the github actions folder and drop each of these files inside.\nmkdir -p .github/workflows cd .github/workflows audit.yml\nname: Security audit on: schedule: - cron: \u0026#39;0 0 * * *\u0026#39; push: paths: - \u0026#39;**/Cargo.toml\u0026#39; - \u0026#39;**/Cargo.lock\u0026#39; jobs: security_audit: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - uses: taiki-e/install-action@cargo-deny - name: Scan for vulnerabilities run: cargo deny check advisories general.yml\nname: Rust on: push: branches: - main pull_request: types: [ opened, synchronize, reopened ] branches: - main env: CARGO_TERM_COLOR: always SQLX_VERSION: 0.6.2 SQLX_FEATURES: \u0026#34;rustls\u0026#34; jobs: test: name: Test runs-on: ubuntu-latest services: steps: - uses: actions/checkout@v3 - uses: dtolnay/rust-toolchain@stable - uses: Swatinem/rust-cache@v2 - name: Run tests run: cargo test fmt: name: Rustfmt runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - uses: dtolnay/rust-toolchain@stable with: components: rustfmt - name: Enforce formatting run: cargo fmt --check clippy: name: Clippy runs-on: ubuntu-latest services: postgres: image: postgres:14 env: POSTGRES_USER: postgres POSTGRES_PASSWORD: password POSTGRES_DB: postgres ports: - 5432:5432 steps: - uses: actions/checkout@v3 - uses: dtolnay/rust-toolchain@stable with: components: clippy - uses: Swatinem/rust-cache@v2 - name: Linting run: cargo clippy -- -D warnings coverage: name: Code coverage runs-on: ubuntu-latest services: steps: - name: Checkout repository uses: actions/checkout@v3 - uses: dtolnay/rust-toolchain@stable - name: Generate code coverage run: cargo tarpaulin --verbose --workspace ","date":"2023-07-19T21:01:12-04:00","permalink":"https://unorthodoxdev.net/post/ci-pipelines-with-rust/","title":"Ci Pipelines With Rust"},{"content":"Everybody knows about uBlock Origin. The browser extension that blocks ads right? Well most ads. Theres often ads from social medias sites like facebook and twitter that slip through really.\nAlthough I recently learned that uBlock has the capability to extend those block lists. The easiset way to add capabilities to your uBlock is to find these pre made lists of URLs and it should begin to block those ads for you. These are really the same lists that DNS filters like pi-hole use.\nA good website that has some of these lists are https://easylist.to\nBrowse to the website, and find what ever list you want and then select the button add it to your blocker.\nThis will open a new tab, and then uBlock will prompt you to subscribe it it. Select \u0026lsquo;Subscribe\u0026rsquo; and then you will be live with that list.\n","date":"2023-07-19T21:00:06-04:00","permalink":"https://unorthodoxdev.net/post/ublock-origin-and-more/","title":"Ublock Origin and More"},{"content":"Outline What is a Digital Garden? A place for ideas to grow. A place for critiques. An exercise in learning in public. Learn In Public Humility. Honesty. Generate Resources that you wish you had. Work In Public Document Your Self. Document Your Steps Working In Public Forces you to Work your Metacognitive Mind. Resources What is a digital garden? https://notes.joschua.io/50+Slipbox/Digital+garden Work In Public https://nesslabs.com/work-in-public Learn In Public https://www.swyx.io/learn-in-public Pick Up What They Put Down https://www.swyx.io/puwtpd Learn In Private https://www.swyx.io/learn-in-private How do Rocket Scientists Learn https://www.govloop.com/community/blog/how-do-rocket-scientists-learn-aka-knowledge-management-lessons-learned-at-goddard-nasa/ What is a Digital Garden? A digital garden to me is a place for for my ideas, projects, and thoughts to be planted in, and sprout and grow in the future. Besides a personal journal on my computer Ive decided to make it a publicly facing blog. Ive decided to so for a few reasons. A digital garden allows space for critiques from others. I don\u0026rsquo;t know everything, nor do I know the best way to do one thing. Posting things publicly allows for a criticism from netizens.\n\u0026ldquo;As I grow, my notes will grow. They will mature from that seed to a full grown plant later in the future.\u0026rdquo; (Digital Garden, Joschua) This is a practice of Working in Public.\nWorking In Public Studies show that statistically, people are more likely to do stuff if they keep their intentions in private. But at times though that statement can seem counter intuitive. Often, people share their weight loss publicly on Facebook or Twitter or Instagram. Many report that doing so is a great way to stay motivated.\nWhen you think about it, some of the reason, people post things online is because it provides a way for you to receive praise along the way. A quote that sticks with me is\n\u0026ldquo;Become a documentarian of what you do\u0026rdquo; - Austin Kleon, Author of Show Your Work\nBecoming a documentarian means that you will develop very quickly\nYour Metacognition Quick Feedback Loops on Content Increased Creativity. By documenting your self, you are working your Metacognition. You are working on thinking of your thoughts. Should I have done that? Should I have done this instead. Why did I take that route? Was it because of an experience I had? Working your metacognition and thinking about your thinking allows for you to quickly determine fallacies in your thought pattern. It also helps you explain in better depth, what you are working on.\nWorking in public also forces you to document not only your thoughts, but also your steps taken to get there. Doing this its self can help you identify un necessary steps and find better work flows.\n","date":"2023-07-19T20:59:39-04:00","permalink":"https://unorthodoxdev.net/post/digital-gardens/","title":"Digital Gardens"},{"content":" ⚠️ Danger You will need administrative access to the device in question. Changing a hostname can have unintended catastrophic consequences if done without proper consideration.\nA hostname is a computers human readable address that allows you to communicate with it, regardless of weather or not you know what its IP address is. Hostnames are pratcial and easy to remember. For whatever reason if you need to reset your hostname on a linux machine, you can follow the below instructions\nTo view your current hostname type\n$ hostname When I do so on the current machine, I see that for whatever reason the machines name is set to localhost. This is a problem as localhost also happens to be an alias to 127.0.0.1.\nTemporarily To temporarily reset the hostname of the machine I should do the following\n$ hostname changeme Again though, unfortunately this only keeps the hostname that way until the next reboot. This might be good for testing or even just to get a prod server off of a bearing load and replace it with a backup server. But for a more permanent and serious effect, we should do the following.\nPermanently $ hostnamectl set-hostname imstuck The above command should set the hostname immediately as well as it should stick beyond a reboot. To confirm that the name has been configured permanently we can check the following file /etc/hostname and confirm the contents are what we are expecting. The thing I would do in this case is to reboot as soon as possible so that permanent hostname can really take affect and your DNS servers can update accordingly.\n","date":"2023-07-19T20:58:46-04:00","permalink":"https://unorthodoxdev.net/post/setting-a-hostname-on-linux/","title":"Setting a Hostname on Linux"},{"content":"These notes should work on given any GNU / Linux based operating system. Although, should you run into any road blocks future me. Im sorry for lying to you :(.\nService Monitoring Services are a integral part of every operating system. How can I monitor and troubleshoot system services when things go wrong?\nSystem Services This command in a very cute way, will display all of the services installed on your server, and then display them accordingly with + or - signs to indicate weather or not it is running.\nservice --status-all Using grep, you can highlight services that are running (+) or stopped (-) for easy identification.\nservice --status-all | grep \u0026#34;[ + ]\u0026#34; Grep can also help you identify a specific service given you know the name like ssh\nRunning Process\u0026rsquo;s PS displays information about a selection of the active processes. It is an alternative to TOP that only prints once. By default ps selects all processes with the same user id (EUID). It will show you the Process ID (PID) and the terminal associated with the process (TTY), the cumulated cpu time in [DD-]hh:mm:ss and the executable name (CMD).\nThe below command will display all processes initiated by the user.\nps If you want to see a specific users processes you can do the following\nps -U root -u root u If you want to view every process on the system, you can do\nps -e Network Related Services The below command will allow you to view all current connections and listening services on a system along with the processes and PIDs for each connection. It requires that you have the net-tools package installed.\nnetstat -tulpn Say I wanted to look at what process was running on port 22\nnetstat -tulpn | grep \u0026#34;22\u0026#34; The above command will return an output of any port that has 22 in it. For me currently, I have two services listening on port 22. One for IPv4 and IPv6\nExample Output\n$ netsatat -tulpn | grep \u0026#34;22\u0026#34; tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN - tcp6 0 0 :::22 :::* LISTEN - Networking Shenanigans Soy baboon, hay problemas de redes; ooh ooh ahh ahh.\nFirst things first Where am i on the subnet? The below tools will help you troubleshoot where your are on the subnet, what might be missing, and or misconfigured. To get a quick overview of all of your connected network cards, you can run the following command\nnetworkctl status It will print out the following information:\nState: Routable or Not Online Status Address (IPv4 and IPv6) Gateway Address including the associated port. DNS Servers Domains NTP Servers. Network Card Configurations. If everything above looks good we can move on to looking more closely at our network cards.\nWhats my ip? The ip command allows you to show address information, manipulate routing, and display network devices, interfaces, and tunnels. It is a simple concept and hard tool to learn. There really five (5) modes to ip.\nTunnel (Tunnel over IP) Route (Routing table entry) Rule (rule in routing policy database) VRF (Manage virtual routing and forwarding devices) XFRM (Manage IPSec policies) To find the IP addresses assigned to your server, use\nip address show This will give you each interface, numbered from 1 to ♾️ including the status (UP or DOWN), IPv4 and IPv6 address, and subnet mask and broadcast address.\n![[ip-address-show.png]]\nTo force a static IP address on a interface, you can do the following\nip address add 10.66.10.9/16 dev eth0 Then you will want to reboot the network card.\nip link set eth0 down ip link set eth0 up Make sure for the above command you are physically connected to the server otherwise, you may lose connection if your actively using eth0.\nIf things are still looking good, we can move on too routes.\nip route This will show all of routes advertised by our DHCP server as available as well as their weighted value identified by the metric lable. You should have a few things listed here. If not I would investigate that.\nMy connection is getting dropped, or reset somewhere along the wire. MTR (Matts Trace-route) is a program that allows you to diagnose issues like these. To use MTR, you will want to do the following\nmtr google.com My favorite flag to use with this is -b it shows the dns name as well as the IP side by side allowing for a quick analysis of the network having issues.\nmtr -b google.com You can also send a predetermined amount of pings with the -c flag. Otherwise known as count it allows you to select how many packets to send.\nmtr -c 100 -b google.com The final command you will need to know about with mtr is -r or record. This allows you to output the information into a txt file for later usage.\nmtr -r -c 20 google.com \u0026gt; mtr-google.log Note that doing so will lock your terminal working on dumping that data so I would recommend a smaller count. If you really wanted to get something running and then do something else in the mean time, you could apply a ampersand (\u0026amp;) to the end of your command to have it run in the background. It will spit out a PID that you can search for later to see if its complete with\nps -e | grep 15225 Monitoring network traffic So, everything looks good, but data is still coming back corrupted? Lets look at the raw packets.\nThe below command allows us to capture all traffic that comes or goes from this interface within the following ip and subnet range.\ntcpdump -i eth0 net 10.66.0.0/16 We can also filter based on source (src) or destination (dst).\ntcpdump -i eth src net 10.1.0.0/24 or\ntcpdump -i eth dst net 10.1.0.0/24 Finally we can also capture traffic only coming or going from a specific port.\ntcpdump -i eth0 port 53 Combining the port traffic with a specific host\ntcpdump -i eth0 host 10.66.10.123 and port 53 ","date":"2023-07-19T20:58:00-04:00","permalink":"https://unorthodoxdev.net/post/linux-administration-tips-and-tricks/","title":"Linux Administration Tips and Tricks"},{"content":"Windows 11 and Start Menus suck. Nothing works the way Microsoft says it should unless you use Intune. So to get around it, we just copy the bin. For now I\u0026rsquo;m doing both, considering sometime in the future Microsoft might get its stuff together and allow the JSON file to work.\nCreating a new Layout On a build PC configure your new layout. run the Export-StartLayout command. Modify the StartLayout file and change the pinnedList to primaryOEMPins Copy the JSON file to C:\\Users\\Default\\AppData\\Local\\Microsof\\Windows\\Shell Alternatively, windows holds an encrypted version of the startup file in the %LocalAppData%\\Packages\\Microsoft.Windows.StartMenuExperienceHost_cw5n1h2txyewy\\LocalState folder. Copying the start.bin file to whatever computers same folder, will essentially do the same thing.\nI\u0026rsquo;ve also created a mini program that you can use to quickly do the above commands to quickly reproduce the steps above. I will put the latest version of the source blow, alternatively you can check my Github repository out here https://github.com/ofgrenudo/confs/tree/main/scripts/start-layouts\nInstall.bat\ncmd /c copy LayoutModification.json C:\\Users\\Default\\appdata\\local\\Microsoft\\Windows\\Shell\\LayoutModification.json /y cmd /c copy start.bin C:\\Users\\Default\\AppData\\Local\\Packages\\Microsoft.Windows.StartMenuExperienceHost_cw5n1h2txyewy\\LocalState do-it-again.bat\n@echo off powershell.exe Invoke-Command -scriptbloc {\u0026#34;Export-StartLayout -Path LayoutModifications.json\u0026#34;} cmd /c copy %LocalAppdata%\\Packages\\Microsoft.Windows.StartMenuExperienceHost_cw5n1h2txyewy\\LocalState\\start.bin start.bin /y cmd /c copy %LocalAppdata%\\Packages\\Microsoft.Windows.StartMenuExperienceHost_cw5n1h2txyewy\\LocalState\\start2.bin start.bin /y cls Echo Remember to Update pinnedList to primaryOEMPins pause ","date":"2023-07-19T12:31:03-04:00","permalink":"https://unorthodoxdev.net/post/custom-start-menu-layouts/","title":"Custom Start Menu Layouts"},{"content":" Note! I have migrated away from ghost blog and now manage my site on hugo!\nFor some reason when I was looking up how to change [[domain names]] for my ghost blog, I kept running into recommendations that stated I should just reinstall ghost. I really don\u0026rsquo;t want to do that especially since so much content exists on this server already. It also reminded me that I probably need to take regular backups of the server anyways. Or at least, double book blog posts somewhere just in case! (Truthfully most posts end up in my notebook to begin with, and end up polished on the website). Below are my steps to migrate my blogs DNS record.\nSet your new DNS record, a day in advanced to the IP address of your server. In my case I was migrating from https://blog.unorthodoxdev.net to https://unorthodoxdev.net. I created a ANAME record and allowed it to propagate overnight. In the morning, I did the below steps.\nghost config url {new_url} rm /etc/nginx/sites-enabled/*.conf ghost setup ssl ghost restart Finally you want to visit your website and check your cert and go from there!\nI would also like to throw in that you might want to remove your ANAME record for whatever your website was before and upgrade it to a CNAME record. CNAME records are really just a redirect to whatever ANAME record you provide it.\n","date":"2023-07-19T12:20:21-04:00","permalink":"https://unorthodoxdev.net/post/migrating-ghost-blog-domain-names/","title":"Migrating Ghost Blog Domain Names"}]