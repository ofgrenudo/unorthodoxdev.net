[{"content":"Asset Inventory Management systems are a major pain in the butt for many organizations. I spend quite a bit of time managing, finding, and hunting down devices all day. People come up with millions of ideas to try and simplify the way that we keep track of these devices. One example of this could be the name of the device.\nHow many of you work at a place where you name the device its serial number? Not many? Why is that? Is that because if the device all of a sudden began acting erratically a random assortment of letters and numbers dosing the active directory server gives you absolutely 0 insight other than maybe the type of device thats compromised if you can search it up via the manufacturer website.\nHow many of you work at a place that name your devices something meaningful? A common one is something along the lines of BLD-FLASTNAME01. Ive even seen just lastname01 or BLD-OFFICENUMB.\nWhat happens when someone quits, or you have part time staff sharing a computer, or a hotel desk? What do you name it then? And when someone quits, and when someone changes positions? Do you just re-image the computer change the name then? Id like to say that most of us should.\nOk your right, lets get an asset inventory system going. Im gonna put every device that comes in, into this .xlsx file on the network drive with out backups, or shadowcopys and we will use that as our inventory system. Whats that? the building lost power last night and corrupted the file system? The inventory spreadsheets lost?\nI think you get my point. Ok lets do this thing right now, we either pay for someone else to host our solution. Realistically what do we need?\nDevice Name Manufacturer Model Name Model Number Serial Number Asset Tag Assigned Staff Maybe the date it was Imaged Those aren\u0026rsquo;t too many requirements right? No reason we couldn\u0026rsquo;t just throw up some kind of sql server right? Im sure I could write some kind of quick c or c# program to throw in a row every time we image a device.\nOhhhhhhhhh, my peers want access to pull reports now, and you know what. They don\u0026rsquo;t know sql. So they ask me to run a report all the time, what device is this, what device is that? Very quickly that little sql server database became defunct about as soon as it went up.\nOkay fine, I could build an interface for it. Buttttttt thats too much work. Someone else in the world has ran into the same issue as me right? Probably\u0026hellip;..\nWhat solutions exist out there today? Well the one that I fell on was Snipe-IT. Without going into everything, it meets all of the above check boxes, and I can give access to people who don\u0026rsquo;t have sql skills. Only problem is, now I don\u0026rsquo;t have complete control over the database, and they\u0026rsquo;ve got some relational database gunk (warning hacker news is cancer i\u0026rsquo;m sorry.). Ok lets go to the api docs for snipe.\nWait. Its actually good?\nOh it must be so easy to use the API then!\nWrong :\\\nAll you want to do is add a hardware entry? Oh ok sure, you need to make a status entry. But to make a status entry you need a Status Name, and a Status Type. Oh anddd youll need a Model Entry, but to make a Model Entry you need a Category Entry and a Manufacturer Entry. Dont worry though the Category Entry only needs a Category Name and Category Type. The Manufacturer Entry only needs the Manufacturer Name.\nOh my goodness thats a lot of requirements. So to work from the bottom up i need to complete the following right?\nRequirements Model Entry Category Entry Manufacturer Entry Status Entry So I can use the same status all day long since the status doesn\u0026rsquo;t really change. It can just be set to Imaged, or Inventoried and manually edited later.\nThe model entry does matter though. Essentially for every model you have, you will need to create a category entry (presumably laptop desktop) and a manufacturer entry (if your lucky your company only buys Lenovo ThinkBooks or something).\n","date":"2023-11-17T15:33:30-05:00","permalink":"https://unorthodoxdev.net/post/is-it-just-me-or-is-this-complicated/","title":"Is It Just Me or Is This Complicated"},{"content":"Gah, they make everything so hard. (I need to run two simple commands.) Why cant I just run one command and flush the dns on my mac? Well im sure theres a better way to do this\u0026hellip; (there is)\nWelcome to flushdns(.sh)\n#!/bin/bash # This script will clear your dns cache on your mac. It has been tested on macOS 13.4 Ventura # Joshua Winters-Brown sudo dscacheutil -flushcache; sudo killall -HUP mDNSResponder \u0026gt; /dev/null echo \u0026#34; _____ \u0026#34; echo \u0026#34; | D \u0026#34; echo \u0026#34; | | \u0026#34; echo \u0026#34; | | \u0026#34; echo \u0026#34; \\___| _ \u0026#34; echo \u0026#34; || _______ -( (- \u0026#34; echo \u0026#34; |_\u0026#39;(-------) \u0026#39;-\u0026#39; \u0026#34; echo \u0026#34; | / \u0026#34; echo \u0026#34; _____,-\\__..__|_____ \u0026#34; echo \u0026#34; \u0026#34; echo \u0026#34; Your DNS has been flushed... \u0026#34; Throw this script into your /usr/local/bin and you can run flushdns from anywhere in the terminal.\nTada!\n","date":"2023-10-12T16:45:31-04:00","permalink":"https://unorthodoxdev.net/post/flush-dns-on-mac/","title":"Flush Dns on Mac"},{"content":"Allrght, I did a vulnerability scan on the web server, there was something about the version of nginx installed had a flaw in it, so I went ahead and patched the nginx install. Ofcourse only because it is patch thursday and it might as well be on a list of things todo. Well, everything went smoothly; I upgraded to the latest version, refreshed the website in the browser, checked my config file, and were good to go. I then promptly left for lunch and didnt get the chance to check back at the website until approximately 7 UTC. Well, the website was infact not good. it was down, and probably down since i made those changes. I began to search for the issue. A quick grep, showed that my config files all existed and contained the domain name and hostname of the website. So whats the issue, why is it not reading my configs? Well that was the problem, and quickly came the solution. When you upgrade the nginx installation it overwrites your previous config file. Im not sure if there was any other magick stuff I was doing in the config file before I updated, but I included the sites-available directory, and were good to go. So yeah, the site was down for aproximately 3 hours. Thanks chaps :)\n","date":"2023-10-05T14:58:10-04:00","permalink":"https://unorthodoxdev.net/post/dont-update-nginx-without-a-backup-of-configs/","title":"Dont Update Nginx Without a Backup of Configs"},{"content":"This guide is intended for Ubuntu 22.04 and is intended for use with a Apache2 web server. To get started we need to make sure you have Apache2 installed, we can use grep to check. These instructions were written on a Ubuntu Server.\napt list --installed | grep \u0026#34;apache2\u0026#34; Next will need to allow Apache through the firewall on both http (80) and https (443). We can do so with the below command\nsudo ufw allow \u0026#34;Apache Full\u0026#34; Next we will need to enable the Apache mod_ssl module. The Apache mod_ssl module will allow Apache to support SSL encryption. The command to do so is below.\nsudo a2enmod ssl sudo systemctl restart apache2 Now, Apache is configured and ready for encryption. We can move onto generating a TLS certificate. To do so we will need to do the following below command\nsudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/ssl/private/apache-selfsigned.key -out /etc/ssl/certs/apache-selfsigned.crt Running the above command will prompt you to enter a bunch of information. Please follow through each of the steps and answer them completely. The following flags on the above command do as listed below\nFlag Description req -x509 This specifies that we want to use the X.509 certificate signing request managment. X.509 is a public key infrastructure standard that TLS adhears too. -nodes Nodes tells OpenSSL to skip the option to secure our certificate with a passphrase because we want apache to be able to read the file. A passphrase would prevent apache from being able to do so. -days 365 This option sets the length of time that the certificate will be considered valid. Here we have set it for one year. Browsers will reject just about any certificate that is valid for longer than a year. -newkey rsa:2048 This tells the program we want to generate a new certificate and key at the same time. the rsa:2048 makes it a RSA key that is 2048 bits long. -keyout This line tells the program where to place the private key file. -out This line tells the program where to place the certificate that we are creating. As a general note, certificates and their keys are generally recommended to be put in the /etc/ssl/private (for keys) and /etc/ssl/certs/ (for certificates). It is a best practice that we should employ.\nTo recap we have just created a key and a certificate.\n/etc/ssl/private/apache-selfsigned.key /etc/ssl/certs/apache-selfsigned.crt You can test if either file exists by, running the following command\nsudo locate apache-selfsigned.key locate apache-selfsigned.key Configure Apache to use TLS Since we have created our self signed certificates. We will then need to tell Apache to use them. We can do so by editing our Apache .conf file. These are typically in the /etc/apache2/sites-availabe folder. We will start by creating a new file in the /etc/apache2/sites-available/ folder.\nsudo vim /etc/apache2/sites-available/my_website.conf next you will want to paste in the following information. Make sure to update it accordingly to before creating this file.\n\u0026lt;VirtualHost *:443\u0026gt; ServerName your_domain_or_ip DocumentRoot /var/www/your_domain_or_ip SSLEngine on SSLCertificateFile /etc/ssl/certs/apache-selfsigned.crt SSLCertificateKeyFile /etc/ssl/private/apache-selfsigned.key \u0026lt;/VirtualHost\u0026gt; Next we will need to enable the configuration file with the a2ensite tool.\nsudo a2ensite my_website.conf sudo systemctl reload apache2 Finally, your web server should be good to go with a self signed cert. Now I would recommend you visit it and ensuring that you are using the https:// prefix. If alls well, you should get a error, saying that it cant verify the identity of the server. This is normal behavior because in fact, we gave it a self signed cert. In the future, It would be advisable to get your certificates from a CA vender.\nI no longer want any http:// requests We can redirect all http:// to your https:// route relatively easily. To do so you will need to edit your .conf that we created above, and add the following configuration to it:\n\u0026lt;VirtualHost *:80\u0026gt; ServerName your_domain_or_ip Redirect / https://your_domain_or_ip/ \u0026lt;/VirtualHost\u0026gt; I would recommend doing a backup of the conf before hand just incase you break something in the process. You never really know what may happen.\nNow all you will need to do is bounce the service, and give it a run.\nsudo apachectl configtest sudo systemctl reload apache2 You can test this by attempting to force your browser to visit the insecure version of the site. To do so ensure that the prefix to the websites name is http://.\n","date":"2023-09-21T16:39:17-04:00","permalink":"https://unorthodoxdev.net/post/creating-and-managing-a-ssl-cert/","title":"Creating and Managing a SSL Cert"},{"content":"NMAP really needs some kind of file output option that isnt leetcode, xml, or gibberish. I would kill for a csv output from nmap. Regardless, lets solve this problem. I chose to ues python because I figured it would be quick and easy and would take no time. I was in fact wrong; Im not quite as comfortable with python as I am with rust at this point, but thats ok. It took about 2-3 hours to build and test a simple program. This stupid script, took a little over 40 minutes trying to figure out how to build a stupid CLI interface and I immediately realized I miss rusts built in fail handling. Your telling me that I have to try, except everything???. Oh well it doesnt matter anyways this doesnt actually compile down to machine code there are no assembly jumps or calls, lets just do it\u0026hellip;.\nGod I hate this I decided to just cave and research a few CLI libraries and landed on plac, which has some very terrible documentation. For example, they do not explicilty provide a way for you to accept a file path or string lol. I just had to play around with the program until I found something that works, but this library could literally kill for some more english in the documentation. After I got that going it was easy peasy lemon squeezy. Except, when you error out, it doesnt really tell you why if your in a try catch loop. So I have to effectively comment out the try catch loop, and lower my code a indentation bracket figure out what the hell is breaking my code, just to realize I forgot to pass a variable to a function but was referencing it anyways\u0026hellip;. Another downside to try catch. Why the hell is my program failing. Otherwise, this program is less than 40 lines without all the stupid comments.\nAll I could think about was those intro to CS classes in college where your just recycling CSV parsing code over and over again for a whole semester and building stupid text UI. All those hours of code, ammounted to a waste of three hours at work trying to get a CSV. But was it worth the three hours one might ask? well, the fact that I can run and scan the network using NMAP, and imemdiately convert it to a csv file to later open in XSLX or another stupid app to make a report later in my day in seconds, I would say that yes. Yes spending the three hours fighting with try, catch loops was worth it.\nTLDR, noob gets wrekt by pythons immaculate error handling. Check out my project, noparser\n","date":"2023-09-21T09:53:13-04:00","permalink":"https://unorthodoxdev.net/post/simple-file-parsing-takes-three-hours/","title":"Simple File Parsing Takes Three Hours"},{"content":" Preface In a behavioural organization class, we have an assignment to watch a movie and pick a sceene from it where we notice some organizational behaviour coming into play. Below are my awnsers to this assignment.\nOrganizational Behaviours in Media This clip is from the movie Free Guy. It is a movie about a bank teller, who learns that he is a non-playable character or NPC in an open-world video game, akin to GTA. In the story, the character goes on to become the hero, and saving two real life peoples lives as they discover the code that is running his character was stolen from them. In the recorded scene, we witness many Organizational Behaviors exhibited by Antwan, the owner of the company. One of the first things that Antwan does is use some conceptual skills.\nInitially the Main Character, Blue Shirt Guy, being an out of control NPC causes issues. Antwan sees the publicity of this event as an Opportunity to embellish and grow the company\u0026rsquo;s profits by maximizing the character\u0026rsquo;s image. We could also consider the Art Nerds a Technical Skill, in being able to create and design the new Blue Shirt Guy Character.\nAnother example of Technical Skills could be Keys being asked if he would like to be promoted to a developer or programmer. An example of Differentiation Strategy in this clip could be Keys attempting to wager Antwan on making a new and unique game that masters its craft through careful consideration and development.\nAntwan unfortunately shuts Keys down by rather taking an operational Excellence approach, demanding that they instead stick to what they are good at, and continue to profit on the framework that already exists.\n","date":"2023-09-19T17:36:35-04:00","permalink":"https://unorthodoxdev.net/post/organizational-behaviour-examples/","title":"Organizational Behaviour Examples"},{"content":"Ever needed to find something in a directory filled with text files. Use grep. The command I enjoy to using is as follows:\ngrep -Ril \u0026#34;what the H E double hockey sticks\u0026#34; ","date":"2023-09-08T07:55:32-04:00","permalink":"https://unorthodoxdev.net/post/searching-text-files-with-grep/","title":"How to search Text files with grep"},{"content":"Ever wonder what port your connected to when plugged into a ethernet jack? Open up wireshark and apply a filter, searching for cdp or lldp traffic. That will kick back:\nThe switches MAC Address. The port description. The switch system name. Some information about the operating system running on the switch. Don\u0026rsquo;t see any information populating? Most likely your network admins have disabled your switches from transmitting CDP or LLDP traffic. In this case, im sorry this wont work for you.\nHave fun troubleshooting.\n","date":"2023-09-07T16:51:44-04:00","permalink":"https://unorthodoxdev.net/post/where-am-i-on-the-network/","title":"Where am i on the network?"},{"content":"Im back!\nIve been gone for a little while now. I went on vacation to mexico for about 21 days to visit friends. I had a blast. Everything there is vastly different than here in the states. Where I live, if you need anything other than beer you need to drive about 5-20 minutes to get whatever you need. In Druango Durango Mexico, If I need to go to the store, its about a 5 minute walk to a Ley; The equivalent of a walmart or meijers. If im in the mood for some chips and a soda, theres a conveince store, or Oxxo within 2 to 5 minutes. Hungry for a burger, theres a place that sells hamburgesas down the street. Come on lets walk its only 10 minutes away! I will tell you though, I was a little dissapointed in the hamburgessa. I was expecting a american hamburger but instead found, carne asada, a salchica split in two, hamon, lettuce tomatoe, onion, pickles, mayo, mustrard, ketchup all on a bun. It was decent, but wasnt what I was looking for.\nAcross the street from where I stayed was a community center. A place where the community can host classes to teach all kinds of things. On Tuesdays and Thursdays theres karate class. On fridays theres dance class teaching you how to perform traditional Aztecan and Mayan dances. On Mondays and Wednesdays theres Singing Class. Tuesday evening they show you how to use a sowing machine and make dresses. Theres a park, with soccer goals, baskeball hoops, playground equipment, etc available all the time. Theres washers and dryers available for those who need them, etc. Over all the community center is something very strange to me. There arent many things like that in america. The closest I could think of is boys and girls club, but im not even sure thats everywhere in the states and Its most definetly not as flexiable as the community center.\nOver all I really enjoyed my trip and cant wait to go back. But for now, ive got school and work to focus on. Ill attach a few photos below.\n","date":"2023-09-07T10:32:58-04:00","image":"https://unorthodoxdev-bucket-public.s3.amazonaws.com/scorpion-hand.jpeg","permalink":"https://unorthodoxdev.net/post/vacation/","title":"Vacation"},{"content":"Advent of Code is a annual set of Christmas themed programming problem that follow an advent calendar. I have heard about Advent of Code (AoC from now on) before but never committed time or resources to it.\nStruggling to learn C, I decided to go through the AoC content from 2015 to current and complete each of the challenges with at a minimum, attempting to use C. The nice thing about doing the older problems, well really any problem, is that there are plenty of resources around online to help me work through and solve the problems.\nI plan to go through at least one problem a day on my lunch break if not more given time permits and upload it to my github repository. Depending on how I feel I may produce a write up of the problem, challenges I faced, my resolutions, how I could optimize, etc\u0026hellip; I think that this will be a fun exercise and prep me for when the 2023 AoC comes around.\nFun Fact! I did not know that people could prestige programming problems but I recently learned, that people have prestige AoC. I guess at the end of the day, it is a game :)\n","date":"2023-08-09T15:07:00-04:00","permalink":"https://unorthodoxdev.net/post/advent-of-code/","title":"Advent of Code"},{"content":"This is a guide i\u0026rsquo;ve created with some notes I have created while working through the networking+ content. While I do plenty of networking troubleshooting experience, these instructions ensure that I STOP, and SLOWN DOWN and think about the changes. Something else I enjoy about these instructions is they force me to think more about change management. Something I need more practice with.\nGather as much information as possible. If possible, duplicate the problem. Break the problem down into meaningful bytes. What steps need to occur and in what order? a lot of people use this step as an opportunity to begin working their way up or down the OSI Model identifying the processes that take place. Generate a few different hypothesis\u0026rsquo;s and the steps needed to take to resolve these issues. Document these issues somewhere publicly where you and your peers can look back at them. When you begin making changes, document the steps taken to test your hypothesis and perform one change at a time. After you have completed the change, assess the situation and determine if the change has produced a favorable result. Once you have confirmed that you have resolved the issue, reach out the customer and confirm that they are seeing the same behavior as you are. Document, Document, Document everything. ","date":"2023-08-09T14:17:19-04:00","permalink":"https://unorthodoxdev.net/post/network-troubleshooting-methodology/","title":"Network Troubleshooting Methodology"},{"content":"I am the ultimate procrastinator. I can never seem to commit, or consider a project done. I have a perpetual train of thought going on when I think of projects or problems. I often wont even start a project, unless I can envision the end. Some people may see this as a good trait, being that I am able to plan the project, and goals out from start to finish instead of aimlessly working on something. Sometimes, I may already have the end goal of my project or problem determined, but my issue is then, finding a way to complete it. Maybe not all the tools are there for me that I hope there would have been.\nLately I have been learning C. Not C++, not C#\u0026hellip; C. One thing I learned very quickly with C is that there is no hand holding. If you do not manage your memory, you\u0026rsquo;ve blown your program up. You don\u0026rsquo;t know how to do something, you\u0026rsquo;ve made your project 100 times harder now trying to include some foreign library, versus developing the solution your self. My initial Idea was to create a program, that pulls the API information from the local Transit station, and parses out the information into a pleasant way. This program in rust, hypothetically would be pretty quick, and i\u0026rsquo;ve already got an idea on how I would do it!\nI would start by using actix to pull the API get request. parse the JSON response using serde. Then use rata-tui to generate a beautiful text UI for it. All together, given I didn\u0026rsquo;t run into any hiccups, this project would probably be done in maybe~ 2 to 3 days If I used rust.\nAfter almost a month of running through C projects and experiments. Ive found that, I am absolutely destroyed by the lack of features with C. My first challenge was making a get request to the Transit web api. I eventually resolved that issue using libcurl which is very terribly documented, and everything is just a pain in the ass to read an understand. But one other issue with using libcurl, is that it requires that the system the program is running on, contains the application curl. That is an issue that I haven\u0026rsquo;t really ran into before when programming with rust. Everything is just code, that compiles to assembler that compiles to binary, that the machine understands and executes. Now i have to add another contingent, an application I cant/don\u0026rsquo;t want to package with my application.\nNow I understand why applications ship with DLLs. Or why the applications have underlying conditions when installing them. Regardless of how I felt about including libcurl, I moved forth and began to deal with my newly found string that contains the response from my API. After many segfault\u0026rsquo;s I\u0026rsquo;ve got to parse this JSON string. Like I stated above, I would simply just use the serde library. But because C doesn\u0026rsquo;t have a JSON library (C was made way before the web, or JSON existed) I need to create my own parser.\nThe above two issues, is reason enough for me to understand why some hardcore C developers keep every piece of code they have. Because when they run into the same JSON parsing issue, they can look at the function, or file that they made last time, and implement the same function or file into the new program.Rust and most modern languages have provided such a standard, containing large standard libraries and easy to import and manage 3rd party libraries that It was hard for me to think of a time where that wasn\u0026rsquo;t an option.\nThe thing I like the most about C is that it forces me to think. To use my smooth brain on how to parse a JSON element, what are the rules that JSON employs? How can I connect to a HTTP Web server, on port 80? How can I save the response? All of these thoughts come from a rough brain. One with ridges and valleys and peaks. Not mine.\nWhile, I think the Transit app i was planning on building with C was a bit too big for me to handle right now, my plan now is to finish it in Rust, and then In preparation for the 2023 Advent of Code, i would like to begin practicing my C solving those problems. Problems which are small and manageable, and I\u0026rsquo;m sure have plenty of resources online for the language that I will be using. Shoot, I\u0026rsquo;ve even found a guy who created an entire language, for solving the Advent of Code problems conveniently in\u0026hellip;. Rust. So while i\u0026rsquo;ve completely changed the way I will handle my next app. I have added a completely other thing that I have dedicated my self to. Finding more things to do, when there is already so much.\n","date":"2023-08-07T09:36:33-04:00","permalink":"https://unorthodoxdev.net/post/finding-things-to-do/","title":"Finding Things to Do..."},{"content":"I recently migrated my website from ghost blog to hugo which is a static site generator compared to the all in one package you get with ghost blog. One of the reasons I decided to make this change was honestly, I had no need for all of the many features that ghost blog provided. Something like Hugo was simple, and effective. It also allowed me to write my documents in mark down, and store the entirety of it in a git repository. Making the portability of my website insanely simple, compared to managing the ghost blog.\nOne of the features I missed from ghost blog though, was the comment feature. Something I really enjoyed. With some Hugo blogs, they do enable you to add a comment feature, but requires that you have some kind of third party application that you sign up for. That pretty much was a no go for me. I don\u0026rsquo;t want to have my self or readers sign up for some ooey gooey third party provider. So because i\u0026rsquo;m lazy, I decided to create my own comment board.\nIve been learning rust for some time now so I settled on that language. It would be a good proof of concept and really help me get my foot in the door when it comes to getting confidence in the language.\nPlanning Lets break down how we are going to do this.\nUser must reach URL. User inputs the following, username, comment. User submits comment. Program submits comment to database after running it through some checks. Comment board is updated. Now that we have a general road map there are quite a few things we can extrapolate from this. One, I can already imagine how my data will look. Two, we can create a general rest API from this point forward. Lets start with our data template\nData I decided to go with sqlite because Im not sure that this website will ever get enough use that I will need to migrate away from an sqlite file. Although if it ever did, im sure it wouldn\u0026rsquo;t be too much more complicated to migrate to a MariaDB or a full fledged Sql database.\nIn general lets get what our data structure will look like\nComment { id: String, ip: String, username: String, timestamp: String, visible: int32, } You\u0026rsquo;ll notice there are a few things here that I have added besides the username and comment. One of them being ID. That will be our entry\u0026rsquo;s primary key. I plan on keeping the IP for governance reasons (issue bans, etc), as well as a timestamp, for historical records. The visible key, will be a simple 1 or 0. If it is 1 then it is visible. If it is 0 then it is hidden. Say I get a derogatory or inappropriate comment, I would\u0026rsquo;t want to necessarily delete it these comments should be kept to be referenced to for example for a ban appeal.I would want to especially keep them if it were to say be life threatening etc. So to prevent displaying it, I will switch the visible to 0 and contact or inform the police of said threat. This way, I still have the comment but its not visible.\nAPI From the requirements above, theres a few things we can already build out API wise.\n/comment/new /comment/id/ /comment/ip/ /comment/username/ Building out the API this way also allows us to tailor, how and what we write when we begin to create our program. I now know that I will need quite a few get functions that return data based off of 3 unique queries. I can also identify that I only need one query to create any data.\nI hope that by now you can very clearly see the benefit of planning your program out, before actually typing any code. This will help you keep from getting lost while creating your program.\nThats about it for the theory on how this comment board will work. In the future, when i\u0026rsquo;ve got everything figured out. I may look into creating either a tutorial series on what i\u0026rsquo;ve done so far, or create youtube videos (as there are not many tutorials out on youtube for rust quite yet).\n","date":"2023-08-01T10:07:32-04:00","permalink":"https://unorthodoxdev.net/post/comment-board/","title":"In dire need of comments."},{"content":"Rust takes forever to build. Im sure I could do alot better deploying the application. But who knows, maybe im doing great at deploying my [comment board](https://unorthodoxdev. net/comment) but what if there is some bug that I introduced that crashes the server 👻. What if while the server is crashed, Im at work??? Well good thing we can customize the default 504 page that nginx uses. So lets get started.\nFirst we will go to our /var/www/html folder and create a page called maintenance.html. Inside of maintenance I have put the following.\n\u0026lt;!doctype html\u0026gt; \u0026lt;title\u0026gt;Site Maintenance\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; body { text-align: center; padding: 150px; } h1 { font-size: 50px; } body { font: 20px Helvetica, sans-serif; color: #333; } article { display: block; text-align: left; width: 650px; margin: 0 auto; } a { color: #dc8100; text-decoration: none; } a:hover { color: #333; text-decoration: none; } \u0026lt;/style\u0026gt; \u0026lt;article\u0026gt; \u0026lt;h1\u0026gt;I\u0026amp;rsquo;ll be back soon!\u0026lt;/h1\u0026gt; \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;Sorry for the inconvenience but Im performing some maintenance at the moment. If you need to you can always \u0026lt;a href=\u0026#34;mailto:joshuawintersbrown@gmail.com\u0026#34;\u0026gt;contact me\u0026lt;/a\u0026gt;, otherwise I\u0026amp;rsquo;ll be back online shortly!\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026amp;mdash; Joshua Winters-Brown\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/article\u0026gt; Simple and sweet right? next, we have to edit our nginx default config. You can find that at /etc/nginx/sites-available/default.\nRemember! You must edit this files as sudo!\nInside of our config file, just below your ssl certificates (or your port 80 config. Who knows maybe your rocking http naked). paste the following\nerror_page 502 /maintenance.html; location = /maintenance.html { root /var/www/html; internal; } Next, you will need to restart your nginx server. You can do so via the following command\nsudo systemctl restart nginx Now, kill your service, and run to the url to try to capture the error.\n","date":"2023-07-27T12:09:39-04:00","permalink":"https://unorthodoxdev.net/post/implementing-a-sick-504-page/","title":"Implementing a Sick 504 Page"},{"content":"Ive migrated my website from the ghost blogging platform to hugo (go hugo, go hugo, go!). Its a little simpler and easier to manage. I also feel as though I have more controll. Currently, im using the hugo-stacked-theme as it looks the most appealing to me, and is not a massive website with insane overhead. It also comes with a indexing feature that allows me (and you ofcourse) to search my content for specific keywords.\nAnother great thing about it being simple is I dont have to constantly monitor that the ghost instance isnt taking too much resources as the web server just lives on a static nginx route. The only thing I will have to get used to is making sure that before I push to the remote repository, that I have ran hugo so that it can build each of my pages.\nCurrently I am manually logging into the web server and pulling the repostory whenever I feel like it. In the future, ideally id set a cron job for every 30 minutes or something like that.\nehhh either way this new cms seems to be working. Keep in touch as im hoping to release a new feature to my website soon :)\n","date":"2023-07-21T10:58:35-04:00","image":"https://unorthodoxdev.net/post/new-blogging-system/this-is-fine_hu86dab14ef87193dda900efad440e3c50_48368_120x120_fill_box_smart1_3.png","permalink":"https://unorthodoxdev.net/post/new-blogging-system/","title":"New Bloging System"},{"content":"Read the damn instructions. Im working on a new project for the website, and Im trying to upload what I have to github (a simple readme nothing more).\nI create an empty repository, init, add, and commit locally. Set the remote repository, and try to push to the remote\u0026hellip; And it fails? What have I done? What did I do? I have done this probably thousands of times. Where did I mess up? Will I have to recreate the folder? Should I re init the local repo?\nWhat do i do?\nimmediately I search the error error, failed to push some refs to the remote github repository.. I find some stack overflow repository, and I begin reading. I trust stack over flow, they got some smart guys on there. Alot smarter guys on there than me because theres always awnsers to my questions.\nIt doesnt work. It doesnt work, what did I do. I followed the advice of this internet stranger. They posted the awnser recently (2021) what have I done. This is a catosrophic faliure on my end. Ill never be able to recover from this.\nI switch tabs back to my github repository after reading the advice one strange lonlely internet post, and I read the instructions given to me by github.\nOh\u0026hellip;\nIve forgotten to set the primary branch. Maybe ive had too much coffee.\n","date":"2023-07-21T10:50:07-04:00","permalink":"https://unorthodoxdev.net/post/read-the-damn-instructions/","title":"Read the Damn Instructions"},{"content":"Ive recently had an encounter with a printer that creates 100s of copies of its self within the computers printer settings. Ive spent quite a bit of time tinkering with this printer and its settings. I think I’ve come to a resolution. Overall, to recap what I did; Opening up the Regedit there were 100’s of keys associated with the Xerox printer. Typically, these registry keys are created when installing the printer and the windows printui.dll handles it. But the amount of registry keys meant that windows kept recreating these keys. I dug a little bit more into the registry keys and it appears that each of these keys had the following properties assigned to them. Name “PRT-AWH-321-COLOR”, Driver “Xerox …” that was pretty much it. The rest of the fields were empty.\nI started off looking into removing these printers via a script etc. Doing so I found the existence of a registry key we can create that would have windows remove the printers on exit. To enable this feature you would have to create a 32bit dWord key in the following location \u0026quot;HKLM:\\Software\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Providers\\Client Side Rendering Print Provider\u0026quot; with the name \u0026quot;RemovePrintersAtLogoff\u0026quot; and the value of 1.\nAfter creating this key, when a user logs out it should clear out any installed printers, and apply the group policy user settings next time a user logs in. Well creating that key and then logging out seemed to work. But those xerox registry keys persisted for some reason. I grabbed one of the GUIDS from a ghost printer and ran a search for all the instances I could find it in regedit. I ran across quite a few instances and ended up writing a script.\nWe start by stopping the printer spooler, and then removing the following:\nHKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Connections HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Printers HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Providers HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\V4 Connections HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Connections HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Printers HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Providers HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\V4 Connections HKCU:\\Printers HKCU:\\Software\\Microsoft\\Windows NT\\CurrentVersion\\PrinterPorts HKEY_USERS\\.DEFAULT\\Printers The following below you need a system user context to remove. You can do so by using PSExec from Windows PowerToys.\nHKLM:\\SYSTEM\\CurrentControlSet\\Enum\\SWD\\PRINTENUM HKLM:\\SYSTEM\\CurrentControlSet\\Control\\DeviceClasses\\{0ecef634-6ef0-472a-8085-5ad023ecbccd} HKLM:\\SYSTEM\\ControlSet001\\Enum\\SWD\\PRINTENUM HKLM:\\SYSTEM\\ControlSet001\\Control\\DeviceClasses\\{0ecef634-6ef0-472a-8085-5ad023ecbccd} HKLM:\\SYSTEM\\ControlSet002\\Enum\\SWD\\PRINTENUM HKLM:\\SYSTEM\\ControlSet002\\Control\\DeviceClasses\\{0ecef634-6ef0-472a-8085-5ad023ecbccd} HKLM:\\SYSTEM\\CurrentControlSet\\Control\\Class\\{1ed2bbf9-11f0-4084-b21f-ad83a8e6dcdc} After doing so, when you open up the control panel all the printers should be grayed out. Because these printers are being added via group policy, doing a reboot, should resolve any issues we had previously. Once the computer comes back up again, all of those printers should remain grey, and anything that gets installed via group policy should then fill in with color. But shortly after, it started happening again. I kept getting notifications of the printer installing, over and over and over again.\nWith that, its confirms that it is not some residual left over install, but narrows it down to one or two things. A messed up group policy or a bad driver. Looking at the group policy I could find anything wrong, so I decided to start at the driver. I took the computer off the domain, and downloaded the PCL, General, and PS, driver for the printer.\nOnce the computers off the domain, I remove all printers. And repeat the above steps. After doing so I started with the identical driver installed, the General driver. I setup the printer and as soon as the install finishes. I immediately get the same issue again.\nIts no longer a group policy issue, its now a driver issue. Uninstall all the printers again and start from step one. Once I get to installing the printer I use the PCL driver. I had similar issues. Finally the Post Script (PS) driver ended up working for me and resolved in no issues.\nEither way, cleaning up the ghost printers is a pain in my ass, and is nothing but manual labor. I ended up reimaging the comptuers after fixing the driver on the print server and going from there.\nSince then its seemed to have been fixed.\nScripts part-one.ps1\nNew-ItemProperty -Path \u0026#34;HKLM:\\Software\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Providers\\Client Side Rendering Print Provider\u0026#34; -Name \u0026#34;RemovePrintersAtLogoff\u0026#34; -Value 1 -Force Restart-Computer -Force part-two.ps1\nStop-Service spooler -Force Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Connections\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Printers\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Providers\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\V4 Connections\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Connections\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Printers\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Providers\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\V4 Connections\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKCU:\\Printers\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKCU:\\Software\\Microsoft\\Windows NT\\CurrentVersion\\PrinterPorts\u0026#34; -Recurse Remove-Item -Path \u0026#34;Registry::HKEY_USERS\\.DEFAULT\\Printers\u0026#34; -Recurse .\\PsExec.exe /accepteula .\\PsExec.exe powershell Remove-Item -Path \u0026#34;HKLM:\\SYSTEM\\CurrentControlSet\\Enum\\SWD\\PRINTENUM\u0026#34; -Recurse .\\PsExec.exe powershell Remove-Item -Path \u0026#34;HKLM:\\SYSTEM\\CurrentControlSet\\Control\\DeviceClasses\\{0ecef634-6ef0-472a-8085-5ad023ecbccd}\u0026#34; -Recurse .\\PsExec.exe powershell Remove-Item -Path \u0026#34;HKLM:\\SYSTEM\\ControlSet001\\Enum\\SWD\\PRINTENUM\u0026#34; -Recurse -ErrorAction SilentlyContinue .\\PsExec.exe powershell Remove-Item -Path \u0026#34;HKLM:\\SYSTEM\\ControlSet001\\Control\\DeviceClasses\\{0ecef634-6ef0-472a-8085-5ad023ecbccd}\u0026#34; -Recurse -ErrorAction SilentlyContinue .\\PsExec.exe powershell Remove-Item -Path \u0026#34;HKLM:\\SYSTEM\\ControlSet002\\Enum\\SWD\\PRINTENUM\u0026#34; -Recurse -ErrorAction SilentlyContinue .\\PsExec.exe powershell Remove-Item -Path \u0026#34;HKLM:\\SYSTEM\\ControlSet002\\Control\\DeviceClasses\\{0ecef634-6ef0-472a-8085-5ad023ecbccd}\u0026#34; -Recurse -ErrorAction SilentlyContinue .\\PsExec.exe powershell Remove-Item -Path \u0026#34;HKLM:\\SYSTEM\\CurrentControlSet\\Control\\Class\\{1ed2bbf9-11f0-4084-b21f-ad83a8e6dcdc}\u0026#34; -Recurse Restart-Computer -Force ","date":"2023-07-20T16:03:40-04:00","permalink":"https://unorthodoxdev.net/post/ghost-printers/","title":"Ghost Printers"},{"content":"Currently im looking into creating an application to harvest device information using the MECM API. Since I constantly have to research where the MECM Admin service has its hooks, i thought it would be a good idea to add some general information here.\nThe Basics The AdminService is a REST API that runs as a service, independent of the other web components in IIS on your site servers.\nService You can check the status of the service in the console under \\Monitoring\\Overview\\System Status\\Component Status - SMS_REST_PROVIDER\nRead-Only Query Basics Note: All queries in this section use a HTTP GET method. Also, everything is CASE SenSiTiVe.\nGet all Devices https://\u0026lt;ServerName\u0026gt;/AdminService/wmi/SMS_R_System Get All Users https://\u0026lt;ServerName\u0026gt;/AdminService/wmi/SMS_R_User Get Device By ResourceID (same syntax for users) https://\u0026lt;ServerName\u0026gt;/AdminService/wmi/SMS_R_System(12345678) Get User By ResourceID https://\u0026lt;ServerName\u0026gt;/AdminService/wmi/SMS_R_User(12345678) Retrieve related class information. This example gets Operating System information for a specific device. https://\u0026lt;ServerName\u0026gt;/AdminService/wmi/SMS_R_System(12345678)/SMS_G_System_OPERATING_SYSTEM ","date":"2023-07-19T21:02:50-04:00","permalink":"https://unorthodoxdev.net/post/mecm-api/","title":"MECM API"},{"content":"\nRepository: https://github.com/ofgrenudo/tattoo/tree/master\nTattoo is the first complete program that I have written in rust. It consists of two parts, a library and the binary. One of the challenges I experienced when writing this application was the lack of abbility to include files outside of module\u0026rsquo;s folder that I was writing in. While I understand now why you should not do so and the kinds of compiler problems you would encounter. I think that forcing me to write a library to manage my goals was very benificial for me.\nThis is the first library that I have had to write that actually does something. Something more than one plus one, or something simple you make when you learn C. This library was immediately applicable to my needs. It also helped me keep my programs logically seperate from eachother. The UI was allowed to get input from the UI and handle that. The backend was able to take the information from the UI and transcribe it into the database. This way of seperating the program made a dream like fusion for me when it came to keeping things clean.\nWriting the library also forced me to leverage the rust documentation feature. Really cementing the whole experience together.\nOverall, I really enjoyed the experience making this application and hope to have many more safe adventures with rust :)\nDescription Tattoo is a program designed to automatically collect device information on run, and insert it into the registry of the device. This information is intended for archival purposes and will remain there for later inspection. Some of the bennifits of storing information in the registry is that it provides a static and proctected way to maintain information like,\nThe day the computer was deployed. The task sequence used when you deployed the computer. The asset tag assigned. The device name when deployed. The serial number of the device. The device model. The device make. Requirements Windows \u0026gt;=10, or Windows Server 2016. PowerShell 5.1 or later Running In order to run tattoo.exe you will need at a minimum, the following file along side the executable.\ntatto.exe.manifest\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; standalone=\u0026#34;yes\u0026#34;?\u0026gt; \u0026lt;assembly xmlns=\u0026#34;urn:schemas-microsoft-com:asm.v1\u0026#34; manifestVersion=\u0026#34;1.0\u0026#34;\u0026gt; \u0026lt;assemblyIdentity version=\u0026#34;1.0.0.0\u0026#34; processorArchitecture=\u0026#34;*\u0026#34; name=\u0026#34;app\u0026#34; type=\u0026#34;win32\u0026#34; /\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;dependentAssembly\u0026gt; \u0026lt;assemblyIdentity type=\u0026#34;win32\u0026#34; name=\u0026#34;Microsoft.Windows.Common-Controls\u0026#34; version=\u0026#34;6.0.0.0\u0026#34; processorArchitecture=\u0026#34;*\u0026#34; publicKeyToken=\u0026#34;6595b64144ccf1df\u0026#34; language=\u0026#34;*\u0026#34; /\u0026gt; \u0026lt;/dependentAssembly\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/assembly\u0026gt; Otherwise it will throw an error exit code: 0xc0000139, STATUS_ENTRYPOINT_NOT_FOUND when trying to run the program. This is a bug with the native windows gui API that has not been resolved.\nExample Screenshots ","date":"2023-07-19T21:01:44-04:00","permalink":"https://unorthodoxdev.net/post/tattoo/","title":"Tattoo"},{"content":"Give a man a fish, and you feed him for a day. Teach a man to fish, and you feed him for a lifetime.\nCI, Continuous onus Integration allows for each member of a team to integrate their changes into the main branch, multiple times a day.\nContinuous Integration allows us to tighten the feed back loop. We are less likely to go off on your own and develop for days or weeks just to find out the approach you have taken isn\u0026rsquo;t working, or isn\u0026rsquo;t approved by peers. Continuous Integration forces you to work with your teammates earlier than when you feel is comfortable allowing for course correcting actions to be taken before you have wasted your time. So how do we make Continuous Integration a reality?\nTests Code Coverage Linting Formatting Security Vulnerabilities Tests Tests in rust are a first-class concept. This being said rust allows you to easily leverage the rust ecosystem to run unit and integration tests using\ncargo test cargo test also takes care of building the project before running tests saving you a command or two.\nCode Coverage Code coverage is a easy way to see if we have overlooked any section of the code base that have been poorly tested. The easiest way to measure code coverage of a rust project is via cargo tarpaulin a cargo subcommand developed by xd009642. You can install tarpaulin with\ncargo install cargo-tarpaulin You can run cargo-tarpaulin with\ncargo tarpaulin --ignore-tests Linting Rust maintains clippy the official rust linter. Clippy is included in the set of components installed by rustup if you are using the default profile. You can run clippy with\ncargo clippy In this CI pipeline we would like to fail the linter check if clippy emits any warnings. To do so we can run the following command\ncargo clippy -- -D warnings Note, from time to time clippy might suggest something you do not belive to be correct or desirable. You can mute these warnings with the following\n#[allow(clippy::lint_name)] Formatting Let machines deal with formatting while reviewers focus on architecture, testing thoroughness, reliability, and observability. Automated formatting removes a distraction from the complex equation of the PR review process. You might dislike this or that formatting choice but the complete erasure of formatting bikeshedding is worth the minor discomfort.\nRust actually has a built in formatter called rustfmt. rustfmt should be included in the default rustup components but if you are missing it you can install it via\nrustup component add rustfmt To format your whole project you can run\ncargo fmt In the CI pipeline we will ad a formatting step.\ncargo fmt -- --check This will ultimately fail when a commit contains unformatted code, printing the difference to the console. You can tune a project with a configuration file rustfmt.toml.\nSecurity Vulnerabilities Caro makes it very easy to leverage existing crates in the ecosystem to solve at hand. On the flip side, each of those crates might hide an exploitable vulnerability that could compromise the security posture of your software. The Rust Secure Code group maintains an Advisory Database on reported vulnerabilities for crates published on crates.io. You can leverage this advisory database with a tool called cargo-audit. You can install it with\ncargo install cargo-audit To use it you can run\ncargo audit Github Actions Below are some github actions you can add to your CI routines. To use them you will want too create the github actions folder and drop each of these files inside.\nmkdir -p .github/workflows cd .github/workflows audit.yml\nname: Security audit on: schedule: - cron: \u0026#39;0 0 * * *\u0026#39; push: paths: - \u0026#39;**/Cargo.toml\u0026#39; - \u0026#39;**/Cargo.lock\u0026#39; jobs: security_audit: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - uses: taiki-e/install-action@cargo-deny - name: Scan for vulnerabilities run: cargo deny check advisories general.yml\nname: Rust on: push: branches: - main pull_request: types: [ opened, synchronize, reopened ] branches: - main env: CARGO_TERM_COLOR: always SQLX_VERSION: 0.6.2 SQLX_FEATURES: \u0026#34;rustls\u0026#34; jobs: test: name: Test runs-on: ubuntu-latest services: steps: - uses: actions/checkout@v3 - uses: dtolnay/rust-toolchain@stable - uses: Swatinem/rust-cache@v2 - name: Run tests run: cargo test fmt: name: Rustfmt runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - uses: dtolnay/rust-toolchain@stable with: components: rustfmt - name: Enforce formatting run: cargo fmt --check clippy: name: Clippy runs-on: ubuntu-latest services: postgres: image: postgres:14 env: POSTGRES_USER: postgres POSTGRES_PASSWORD: password POSTGRES_DB: postgres ports: - 5432:5432 steps: - uses: actions/checkout@v3 - uses: dtolnay/rust-toolchain@stable with: components: clippy - uses: Swatinem/rust-cache@v2 - name: Linting run: cargo clippy -- -D warnings coverage: name: Code coverage runs-on: ubuntu-latest services: steps: - name: Checkout repository uses: actions/checkout@v3 - uses: dtolnay/rust-toolchain@stable - name: Generate code coverage run: cargo tarpaulin --verbose --workspace ","date":"2023-07-19T21:01:12-04:00","permalink":"https://unorthodoxdev.net/post/ci-pipelines-with-rust/","title":"Ci Pipelines With Rust"},{"content":"Everybody knows about uBlock Origin. The browser extension that blocks ads right? Well most ads. Theres often ads from social medias sites like facebook and twitter that slip through really.\nAlthough I recently learned that uBlock has the capability to extend those block lists. The easiset way to add capabilities to your uBlock is to find these pre made lists of URLs and it should begin to block those ads for you. These are really the same lists that DNS filters like pi-hole use.\nA good website that has some of these lists are https://easylist.to\nBrowse to the website, and find what ever list you want and then select the button add it to your blocker.\nThis will open a new tab, and then uBlock will prompt you to subscribe it it. Select \u0026lsquo;Subscribe\u0026rsquo; and then you will be live with that list.\n","date":"2023-07-19T21:00:06-04:00","permalink":"https://unorthodoxdev.net/post/ublock-origin-and-more/","title":"Ublock Origin and More"},{"content":"Outline What is a Digital Garden? A place for ideas to grow. A place for critiques. An exercise in learning in public. Learn In Public Humility. Honesty. Generate Resources that you wish you had. Work In Public Document Your Self. Document Your Steps Working In Public Forces you to Work your Metacognitive Mind. Resources What is a digital garden? https://notes.joschua.io/50+Slipbox/Digital+garden Work In Public https://nesslabs.com/work-in-public Learn In Public https://www.swyx.io/learn-in-public Pick Up What They Put Down https://www.swyx.io/puwtpd Learn In Private https://www.swyx.io/learn-in-private How do Rocket Scientists Learn https://www.govloop.com/community/blog/how-do-rocket-scientists-learn-aka-knowledge-management-lessons-learned-at-goddard-nasa/ What is a Digital Garden? A digital garden to me is a place for for my ideas, projects, and thoughts to be planted in, and sprout and grow in the future. Besides a personal journal on my computer Ive decided to make it a publicly facing blog. Ive decided to so for a few reasons. A digital garden allows space for critiques from others. I don\u0026rsquo;t know everything, nor do I know the best way to do one thing. Posting things publicly allows for a criticism from netizens.\n\u0026ldquo;As I grow, my notes will grow. They will mature from that seed to a full grown plant later in the future.\u0026rdquo; (Digital Garden, Joschua) This is a practice of Working in Public.\nWorking In Public Studies show that statistically, people are more likely to do stuff if they keep their intentions in private. But at times though that statement can seem counter intuitive. Often, people share their weight loss publicly on Facebook or Twitter or Instagram. Many report that doing so is a great way to stay motivated.\nWhen you think about it, some of the reason, people post things online is because it provides a way for you to receive praise along the way. A quote that sticks with me is\n\u0026ldquo;Become a documentarian of what you do\u0026rdquo; - Austin Kleon, Author of Show Your Work\nBecoming a documentarian means that you will develop very quickly\nYour Metacognition Quick Feedback Loops on Content Increased Creativity. By documenting your self, you are working your Metacognition. You are working on thinking of your thoughts. Should I have done that? Should I have done this instead. Why did I take that route? Was it because of an experience I had? Working your metacognition and thinking about your thinking allows for you to quickly determine fallacies in your thought pattern. It also helps you explain in better depth, what you are working on.\nWorking in public also forces you to document not only your thoughts, but also your steps taken to get there. Doing this its self can help you identify un necessary steps and find better work flows.\n","date":"2023-07-19T20:59:39-04:00","permalink":"https://unorthodoxdev.net/post/digital-gardens/","title":"Digital Gardens"},{"content":" ⚠️ Danger You will need administrative access to the device in question. Changing a hostname can have unintended catastrophic consequences if done without proper consideration.\nA hostname is a computers human readable address that allows you to communicate with it, regardless of weather or not you know what its IP address is. Hostnames are pratcial and easy to remember. For whatever reason if you need to reset your hostname on a linux machine, you can follow the below instructions\nTo view your current hostname type\n$ hostname When I do so on the current machine, I see that for whatever reason the machines name is set to localhost. This is a problem as localhost also happens to be an alias to 127.0.0.1.\nTemporarily To temporarily reset the hostname of the machine I should do the following\n$ hostname changeme Again though, unfortunately this only keeps the hostname that way until the next reboot. This might be good for testing or even just to get a prod server off of a bearing load and replace it with a backup server. But for a more permanent and serious effect, we should do the following.\nPermanently $ hostnamectl set-hostname imstuck The above command should set the hostname immediately as well as it should stick beyond a reboot. To confirm that the name has been configured permanently we can check the following file /etc/hostname and confirm the contents are what we are expecting. The thing I would do in this case is to reboot as soon as possible so that permanent hostname can really take affect and your DNS servers can update accordingly.\n","date":"2023-07-19T20:58:46-04:00","permalink":"https://unorthodoxdev.net/post/setting-a-hostname-on-linux/","title":"Setting a Hostname on Linux"},{"content":"These notes should work on given any GNU / Linux based operating system. Although, should you run into any road blocks future me. Im sorry for lying to you :(.\nService Monitoring Services are a integral part of every operating system. How can I monitor and troubleshoot system services when things go wrong?\nSystem Services This command in a very cute way, will display all of the services installed on your server, and then display them accordingly with + or - signs to indicate weather or not it is running.\nservice --status-all Using grep, you can highlight services that are running (+) or stopped (-) for easy identification.\nservice --status-all | grep \u0026#34;[ + ]\u0026#34; Grep can also help you identify a specific service given you know the name like ssh\nRunning Process\u0026rsquo;s PS displays information about a selection of the active processes. It is an alternative to TOP that only prints once. By default ps selects all processes with the same user id (EUID). It will show you the Process ID (PID) and the terminal associated with the process (TTY), the cumulated cpu time in [DD-]hh:mm:ss and the executable name (CMD).\nThe below command will display all processes initiated by the user.\nps If you want to see a specific users processes you can do the following\nps -U root -u root u If you want to view every process on the system, you can do\nps -e Network Related Services The below command will allow you to view all current connections and listening services on a system along with the processes and PIDs for each connection. It requires that you have the net-tools package installed.\nnetstat -tulpn Say I wanted to look at what process was running on port 22\nnetstat -tulpn | grep \u0026#34;22\u0026#34; The above command will return an output of any port that has 22 in it. For me currently, I have two services listening on port 22. One for IPv4 and IPv6\nExample Output\n$ netsatat -tulpn | grep \u0026#34;22\u0026#34; tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN - tcp6 0 0 :::22 :::* LISTEN - Networking Shenanigans Soy baboon, hay problemas de redes; ooh ooh ahh ahh.\nFirst things first Where am i on the subnet? The below tools will help you troubleshoot where your are on the subnet, what might be missing, and or misconfigured. To get a quick overview of all of your connected network cards, you can run the following command\nnetworkctl status It will print out the following information:\nState: Routable or Not Online Status Address (IPv4 and IPv6) Gateway Address including the associated port. DNS Servers Domains NTP Servers. Network Card Configurations. If everything above looks good we can move on to looking more closely at our network cards.\nWhats my ip? The ip command allows you to show address information, manipulate routing, and display network devices, interfaces, and tunnels. It is a simple concept and hard tool to learn. There really five (5) modes to ip.\nTunnel (Tunnel over IP) Route (Routing table entry) Rule (rule in routing policy database) VRF (Manage virtual routing and forwarding devices) XFRM (Manage IPSec policies) To find the IP addresses assigned to your server, use\nip address show This will give you each interface, numbered from 1 to ♾️ including the status (UP or DOWN), IPv4 and IPv6 address, and subnet mask and broadcast address.\n![[ip-address-show.png]]\nTo force a static IP address on a interface, you can do the following\nip address add 10.66.10.9/16 dev eth0 Then you will want to reboot the network card.\nip link set eth0 down ip link set eth0 up Make sure for the above command you are physically connected to the server otherwise, you may lose connection if your actively using eth0.\nIf things are still looking good, we can move on too routes.\nip route This will show all of routes advertised by our DHCP server as available as well as their weighted value identified by the metric lable. You should have a few things listed here. If not I would investigate that.\nMy connection is getting dropped, or reset somewhere along the wire. MTR (Matts Trace-route) is a program that allows you to diagnose issues like these. To use MTR, you will want to do the following\nmtr google.com My favorite flag to use with this is -b it shows the dns name as well as the IP side by side allowing for a quick analysis of the network having issues.\nmtr -b google.com You can also send a predetermined amount of pings with the -c flag. Otherwise known as count it allows you to select how many packets to send.\nmtr -c 100 -b google.com The final command you will need to know about with mtr is -r or record. This allows you to output the information into a txt file for later usage.\nmtr -r -c 20 google.com \u0026gt; mtr-google.log Note that doing so will lock your terminal working on dumping that data so I would recommend a smaller count. If you really wanted to get something running and then do something else in the mean time, you could apply a ampersand (\u0026amp;) to the end of your command to have it run in the background. It will spit out a PID that you can search for later to see if its complete with\nps -e | grep 15225 Monitoring network traffic So, everything looks good, but data is still coming back corrupted? Lets look at the raw packets.\nThe below command allows us to capture all traffic that comes or goes from this interface within the following ip and subnet range.\ntcpdump -i eth0 net 10.66.0.0/16 We can also filter based on source (src) or destination (dst).\ntcpdump -i eth src net 10.1.0.0/24 or\ntcpdump -i eth dst net 10.1.0.0/24 Finally we can also capture traffic only coming or going from a specific port.\ntcpdump -i eth0 port 53 Combining the port traffic with a specific host\ntcpdump -i eth0 host 10.66.10.123 and port 53 ","date":"2023-07-19T20:58:00-04:00","permalink":"https://unorthodoxdev.net/post/linux-administration-tips-and-tricks/","title":"Linux Administration Tips and Tricks"},{"content":"Windows 11 and Start Menus suck. Nothing works the way Microsoft says it should unless you use Intune. So to get around it, we just copy the bin. For now I\u0026rsquo;m doing both, considering sometime in the future Microsoft might get its stuff together and allow the JSON file to work.\nCreating a new Layout On a build PC configure your new layout. run the Export-StartLayout command. Modify the StartLayout file and change the pinnedList to primaryOEMPins Copy the JSON file to C:\\Users\\Default\\AppData\\Local\\Microsof\\Windows\\Shell Alternatively, windows holds an encrypted version of the startup file in the %LocalAppData%\\Packages\\Microsoft.Windows.StartMenuExperienceHost_cw5n1h2txyewy\\LocalState folder. Copying the start.bin file to whatever computers same folder, will essentially do the same thing.\nI\u0026rsquo;ve also created a mini program that you can use to quickly do the above commands to quickly reproduce the steps above. I will put the latest version of the source blow, alternatively you can check my Github repository out here https://github.com/ofgrenudo/confs/tree/main/scripts/start-layouts\nInstall.bat\ncmd /c copy LayoutModification.json C:\\Users\\Default\\appdata\\local\\Microsoft\\Windows\\Shell\\LayoutModification.json /y cmd /c copy start.bin C:\\Users\\Default\\AppData\\Local\\Packages\\Microsoft.Windows.StartMenuExperienceHost_cw5n1h2txyewy\\LocalState do-it-again.bat\n@echo off powershell.exe Invoke-Command -scriptbloc {\u0026#34;Export-StartLayout -Path LayoutModifications.json\u0026#34;} cmd /c copy %LocalAppdata%\\Packages\\Microsoft.Windows.StartMenuExperienceHost_cw5n1h2txyewy\\LocalState\\start.bin start.bin /y cmd /c copy %LocalAppdata%\\Packages\\Microsoft.Windows.StartMenuExperienceHost_cw5n1h2txyewy\\LocalState\\start2.bin start.bin /y cls Echo Remember to Update pinnedList to primaryOEMPins pause ","date":"2023-07-19T12:31:03-04:00","permalink":"https://unorthodoxdev.net/post/custom-start-menu-layouts/","title":"Custom Start Menu Layouts"},{"content":" Note! I have migrated away from ghost blog and now manage my site on hugo!\nFor some reason when I was looking up how to change [[domain names]] for my ghost blog, I kept running into recommendations that stated I should just reinstall ghost. I really don\u0026rsquo;t want to do that especially since so much content exists on this server already. It also reminded me that I probably need to take regular backups of the server anyways. Or at least, double book blog posts somewhere just in case! (Truthfully most posts end up in my notebook to begin with, and end up polished on the website). Below are my steps to migrate my blogs DNS record.\nSet your new DNS record, a day in advanced to the IP address of your server. In my case I was migrating from https://blog.unorthodoxdev.net to https://unorthodoxdev.net. I created a ANAME record and allowed it to propagate overnight. In the morning, I did the below steps.\nghost config url {new_url} rm /etc/nginx/sites-enabled/*.conf ghost setup ssl ghost restart Finally you want to visit your website and check your cert and go from there!\nI would also like to throw in that you might want to remove your ANAME record for whatever your website was before and upgrade it to a CNAME record. CNAME records are really just a redirect to whatever ANAME record you provide it.\n","date":"2023-07-19T12:20:21-04:00","permalink":"https://unorthodoxdev.net/post/migrating-ghost-blog-domain-names/","title":"Migrating Ghost Blog Domain Names"}]