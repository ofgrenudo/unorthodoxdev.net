[{"content":"GrrCON is a Cyber Security Conference based in Grand Rapids Michigan. Every year, it is hosted in the Devos Center. For the past three years, I have attended to help aid in my Professional Development as well as to keep in touch with the Cyber Security in the industry. GrrCON is spread over two days, and is broken up into three different sections every year. The first section are vendors and recruiters. Vendors typically come in, hoping to sell you and your company on their product or tool. I typically take a stroll through this section to see how the markets changing over time. Ive seen quite a few companies come and go through this section of the event. The other half of this section is the recruiters. This year we had the Army, as well as the FBI who were major recruiters this event. This half of the convention is honestly a really good place to network with peers and other companies. It allows for you to see whats in the market and give you ideas of other ares to look and apply to.\nThe second section to this convention is what is called villages. This year, there was the Car Hacking Village, Lock Picking Village, Integrated Control Systems Village, Hak4Kidz Village, and a Dungeon and Dragons Village. Each of the villages typically contain some kind of hands on lab for you to work with a professional in the field and get some experience, with the kinds of things they do. The final section consists of hour to hour and a half long seminars running back to back all day, where a vendor or a organization gives you either A) a demonstration of an exploit and how they discovered it, or B) they give you a run down on a service or process that may improve your work flow. This year, I only attended one seminar, which was a demonstration of a Denial of Service for the new 2025 ford broncos, where they could de-authenticate your paired Phone as Key and prevent you from getting into the car, forcing you to factory reset the device. In the seminar we discussed the magnitude of scale on this particular vulnerability, and how it wasn’t Ford who was at fault for the vulnerability, but actually Texas Instruments (TI), for deploying Bluetooth chips with vulnerable firmware. After disclosing the vulnerability to TI they reported back that the stored inventory of chips was roughly 8M dollars worth, that had to be put on hold, and brought back into the shop for firmware updates. This number also excludes the number of devices that were already in devices like vehicles, cell phones, smart watches, and medical equipment.\nBesides the one seminar I attended this year, I spent a great deal of my time going through each of the villages village and competed in a number of challenges. Often villages will even hold competitions where you can show your skills off to others and compete for a prize. To give an example of some of the competitions you could compete in last year, I competed In the lock picking competition and placed second place! In this particular competition you were tasked with picking a trigger lock off of a toy water gun, while wearing beer googles. Once you have the trigger lock removed from the toy gun, you must accurately shoot the person in front of you with the water gun. This year, I spent a great deal of my time competing in Capture the Flags (CTF). I competed in three instances of a CTF, including Endpoint Threat Detection and Remediate (placing 7th), Cloud Native Security (placing 4th), and AI enhanced detection and remediation (placing 8th). This was a great experience overall, as I was able to really test my skills and see where I’m at in comparison to others. I think that for something that I only do occasionally in my day to day job, I played very competitively and stayed ahead of the ball for the most part.\n","date":"2024-10-01T22:25:21-04:00","image":"https://images.unsplash.com/photo-1514480439008-da032651eb4a","permalink":"http://localhost:1313/p/2024-10-01-grrcon-2024/","title":"GrrCON 2024"},{"content":"Bicycle Commuting has Greatly Improved Downtown I think every other post ive read on reddit since they have installed the new bike lanes downtown have been relatively negative. Up until the city decided to put the bike lanes in, reaching downtown via means other than car was either impossible, or if not impossible risky/dangerous. Now with the addition of the bike lanes on Lovell, West Michigan, Stadium, Portage, North, and Westnedge, and more it makes access to the heart of the city from all sides of the city bike accessible. Before these additions, I would\u0026rsquo;nt have felt safe to bike from my home to downtown.\nLet alone, riding my bike makes me feel just free. I can go anywhere and do anything. Its converting the energy in my body into momentum that can take me where I need or want to be. It allows for me to skip all the rush hour traffic and enjoy the world around me. Sure, you go faster generally in a car rather than a bike. But I legitemately have to stop a lot less when riding my bike vs when driving in a car.\nWithin 1 to 2 miles from your job! Walk to work, or walk to work more often. If you live one mile away from work, it would take you a max of 22 minutes to get to work walking. If you live two miles, your at a max 45 minute walk. Ive commuted via car before 45 minutes. There are times that I miss that commute time. Especially when work begins to get stressfull. It allows for me to decompress from work and relax before getting home and having to cook or get ready to do homework.\nWithin 2-4 Miles from your job! For those of you who live within a 2-4 mile range of your job, I would really recommend you trial a bike ride in on the weekend. You will considerably cut down on gas usage and save on parking. I for one make it in quicker when I bike than I do when I drive. I don\u0026rsquo;t have to worry about parking, I don\u0026rsquo;t have to worry about traffic for the most part, and I am free to take whatever route is convenient to me. After a long day of work, I can take a detour home, and stop at the park to read a book, or take a different route or trail home, and im not limited by the constrains of traffic and parking. If you fully commit to riding your bike to work every day, and live 4 miles or more, maybe invest in getting an ebike! This can help take the load off when your going up hills, or when you just want to put in less effort getting to work every day.\n4 miles or more from your job! Think about taking public transport, while you could 100% take your car, think about all the free time that just opened up allowing you to do other things you may enjoy. Riding the bus means you get to sitdown and read a book, or scroll the interwebs on your phone! And while it may take a little bit longer to get to work, I guarantee you with propper planning you will be just fine. If public transport isnt quite as available for you, maybe consider getting an ebike if your under 10 miles away. They can take a great deal of pressure off of you, and if you hold out till the end of your ride, you could use the ebike battery to take you the rest of the way there while you just cool down.\nI think that you should 100% one way or another attempt to take a different way into work, just to broaden the horizons and to mix things up a bit. I get stuck to often in a routine of security and comfort. It helps to break out of that every now and then and get some variety in my life.\nI hope to see you on the bike path ! ;)\n","date":"2024-07-24T09:13:47-04:00","image":"https://images.unsplash.com/photo-1584278140365-2ab8bff2be82","permalink":"http://localhost:1313/p/2024-07-24-being-a-commute-warrior/","title":"Being a Commute Warrior"},{"content":"If you didn\u0026rsquo;t know, I read quite a bit of literature. I attempt to fill the time I have that im not doing anything productive with some for of productivity. Weather its watching a video essay, argumentative essay, or studying something im always trying to fill that void with something productive. One form of that habit is reading quite a few books. I think I read too much for me to by every single book that I want, so from time to time, I either have to hit the library and rent a book out (given that they have what I want which is at times unlikely) or purchase ebooks of my preferred books and read them on my phone, tablet, or pc.\nReading ebooks isn\u0026rsquo;t always the most convenient though. It has come a long way though! In this essay, I will go over some of the requirements of a ebook reader that I want, a few options that I pursued, and finally, why I settled on google books being my #1 ebook reader.\nRequirements What makes an ebook reader? Let alone, the best ebook reader? Well in my mind there are a few things that are absolutely required of an ebook reader, anything else is just added gimmicks or bloat.\nThe ability to upload your own epub, pdf, etc\u0026hellip; to the reader. Without this capability, how will I get all of my legally purchased textbooks loaded onto the app. It must have the capability to sync across the plethora of my devices, (Android, Windows PCs, Macbook, iPad, etc\u0026hellip;). Standard Features, like highlighting annotations, etc. Added bonus you can purchase books from the store, or import books from either kindle, or google play books into this reader. Optionally support manga/cbz format. The Hunt With my requirements defined now, we can move forward to hunting for the ideal epub reader. Im partially bias to FOSS, or just open source software in general. While i really really want the capability to read books on my work computer. I will sacrifice for a synced folder between multiple mobile devices. One of the few that popped up on my initial search was as follows.\nLithium Books FBReader KoReader Apple Books Kindle Reader Apple Books At one point, I had an iPhone, and used Apple Books almost exclusively. At one point, I bought a new stephen king book, on the Apple book store and immediately realized that I was unable to access it on any device that wasn\u0026rsquo;t an apple. This quickly became a big nono, and violated option number 4. In the perchance I want to buy a book that id like the author to receive the money for, and then you tell me I all of a sudden I dont own the book anymore is insane.\nKindle Reader I quickly deleted all imported books on the Apple Books app, and migrated to Kindle Reader. For being supposedly one of the largest ebook sellers. As well as touting multiple ebook readers etc, I was surprised that the interface absolutely sucks. Its somewhat glitchy, a pain in the but to upload anything to your phone, and honestly just is rough around the edges. Also, books that you own, can only be downloaded on x amount of devices. I rented a text book for the semester from kindle books, and Id have to delete the downloaded textbook (somewhere around a gig or a half) on one device, then download it onto another device making it an absolute pain in the ass if I dont have the device with the downloaded book on hand. I very quickly marked kindle reader as not suitable.\nKoReader Not long after, I switched from iPhone to android. This was due to a number of reasons, but in general the tipping point was the apple books issue. With my new android, I tried KoReader which is really flushed out, but lacks syncing capabilities, purchasing, etc\u0026hellip; It also visually looks like something that should be loaded onto a eink reader. Its very snappy, no fluid animations etc. Safe to say i migrated away from koreader after a few chapters.\nFBReader FBReader was the next in my adventure, and it is pretty flushed out. It has an OK UI. The biggest benefit is that FBReader allows for connection to a OPDS server. Meaning I could setup a Calibre Web Server, or a Kavita server. I tried this out, but over time having to setup the OPDS connection just kind of frustrated me. I also noticed, that even though I have a OPDS connection, that does not mean that my data gets synced; I mean thats not what OPDS is for. It just displays the books available. So then every device I want, would need to have synced with the FBReader feature, as well as connect to OPDS, which just kind of felt like it was too much to do. Eventually I just moved away from it.\nLithium Books Finally, my second to last attempt was Lithium Reader. By the time I reached lithium reader, I had lost all hope. I just decided ill never find an app with all of the features that I dream of. Lithium Books was a happy medium. It has a great UI, highlighting and annotation. I can upload and include my own books. The only problem is that it quickly becomes then that it doesnt have CBZ support, as well as no OPDS support. And cannot connect or purchase books from amazon, google books, etc. All of those cons though, Im more than comfortable with just dealing with.\nIt wasnt too long after though that I figured Id give a look at the google play store looking for another solution, when I decided to take a look at the google books section. I discovered that in the past I had purchased a number of books from the google play store. I took a browse through the books I had purchased in the past and decided to click on one to see how it would prompt me to read it and low and behold I was prompted to install the google play books app.\nGoogle Play Books Immediately I was excited to see if this app was available on mac, iphone, web, etc. I logged into my computer and searched up google play books, and low and behold theres a web portal where you can read, and download books. Most importantly theres an option on the PC to upload books to your account as well! I grabbed a book from my harddrive and uploaded it to google books. I refreshed the app on my phone and there it was. I opened it up, and flipped a few pages forward. Then I exited the book and closed the app. I refreshed my page on my desktop, and opened the book. I was exactly where I left off at on my phone! Everything I had been wanting before my eyes.\nI began to polit the app on my phone, reading every now and then when I get the chance. Until a few nights ago, where I was laying in bed and reading I decided to experiment with the settings seeing if there was a red light setting. And I discovered that on the mobile application, there is a text to speech feature, where the app will read the book to me! I spend the following 30 minutes, listening the book and following along as it goes. I was entirely impressed by its pronunciation of some hard words. The book i am reading currently has a number of latin and spanish words in it, so from time to time it will butcher a sentence. Otherwise I am generally able to understand what its trying to say to me. Its annotation feature also allows for you to export the annotations to a document within your google drive! One of the downsides to this though, is that the text to speech feature is not available on the web version. Im also unable to test wether or not its available on the iOS version.\nWith that being said, While I know that not everyone likes google, and many people are attempting to de-google their life. If you are looking for a very solid ebook solution, Google Play Books is the way to go. It meets literally all of my requirements and more. With the added text to speech feature, its almost like you get an added ebook thrown in for free!\n","date":"2024-06-12T10:16:32-04:00","permalink":"http://localhost:1313/p/2024-06-12-the-best-ebook-reader/","title":"The Best eBook Reader"},{"content":"Lots of people want to contribute to open source software. Though getting started contributing can be at first a challenge. The easiest way to get started contributing to open source though is to use open source software. With it can come times where you wish there was a feature, or you notice a wierd bug you wish was fixed. One of the first open source projects I contributed to was the creation of the Jellyfin Theater app, (now archived). Having a jellyfin server, since its invention I really desired a native client that I could stream movies and listen to music on. In having that need, I decided to sit down and dig into the jellyfin api. Over the weekend I was able to put together a functioning piece of the Jellyfin Theater App https://github.com/jellyfin-archive/jellyfin-desktop.\nAnother etc\u0026hellip;) I instance of having that itch to contribute, would have been a few weeks or so ago. With the advent windows recall, I decided for any device the I dont need (i know, i know, but there are instances that i need to use windows for schoolwill install linux on whatever isnt needed. I started by installing Ubuntu onto my thinkpad, and then I got started customizing the operating system. In doing so, one of the common tools you will use when customizing the gnome desktop is the Gnome-Tweak tool.\nThe issue that sparked that itch for me was that when you install a theme, the drop down menu, seemingly randomly sorts the themes. So if I wanted to apply the yaru theme, it could be first in the list, or in the middle. So I took it on my own to contribute some form of a sorting algorithm to resolve this issue.\nGoing about scratching To review the steps here,\nFind that Itch. Scratch the Itch. Nah, im just playing the steps really look more like this.\nUse Open Source Software. Discover bug, Desire a feature, whichever comes first. Search under existing issues open or closed if this bug or feature has been discussed. If it has been discussed, and seems like the maintainers were open to the implementation of said bug fix, your good to go! If it has been discussed, and seems like the maintainers are not open to the implementation of said bug fix, fork the project and maintain your own version, or weep. If it has not been discussed, make an issue, and start working on fixing your bug! Fork the Project. Fix the code. Submit a pull request. Await approval (can be ages before you get approved and or a pain in the ass following their weird guidelines.). Filing and Issue and Forking the Project In this case, im only fixing the Gnome-Tweak Too. Honestly, I was surprised to see that the app was written in python, but if it works dont fix it right? To implement my specific pain in the ass issue, we start at step 3. You can see here that there are few sorting issues related to the app, but specifically issue number #487 is the one that relates to us. Looking at the issue it seems like there has been no updates or notifications about fixing the issue, so i took it upon my self to do so.\nFixing the Codes The fix ended up being pretty simple, to fix https://gitlab.gnome.org/ofgrenudo/gnome-tweaks/-/compare/master...master?from_project_id=544\nwe could have just taken the themes variable and apply .sort() to it, but it seems like the structure was a tuple like so (('name', 'filepath?something'), ('name', 'filepath?something')), so i decided to instead use the sorted() function will return the sorted tuple with a special function that decides that we will only sort based on the first item within the tuple. That function looks like so\n1 sorted_themes = sorted(themes, key=lambda x: x[0]) Next we test, and surprisingly it is working the way its intended to!\nSubmit and Wait Now we submit a pull request and wait for it to peer reviewed and approved by maintainers.\nThats pretty much, everything. So if you ever get that itch, or discover a bug dont feel intimidated when looking to contribute to opensource software. For the most part you can follow these 7 steps and you should be good!\n","date":"2024-06-04T08:50:15-04:00","permalink":"http://localhost:1313/p/2024-06-04-how-to-contribute-to-open-source-software/","title":"How to Contribute to Open Source Software"},{"content":"Alot has happened in the past three months. Its not entirely uncommon for me to drop off the face of the earth during finals, but this year it hit me hard. I had quite a large class load, and getting everything in and done was quite a challenge. Now the semesters over, and ive graduated! For the past month or so, ive had the chance to actually breath.\nSo far, ive done primarily house chores in my free time. I took down the old pool in the backyard, fixed the fence up for the most part, and rebuilt the garden bed. I have also gone through and planted quite a few plants. Currently ive got as follows:\n3 tomato plants. 3 jalapeno plants. 2 habanero pepper plants. 5 garlic plants numerous green onions scattered in the back of the garden bed 2 lettuce plants. My biggest challenge this season will be protecting the plants and the fruits they bear from the neighbors chicken. The chicken, is adorable, but it enjoys the freedom a free cage bird should and discovers the neighbors houses. My fear, is it will eat my prized tomatoes, and im not sure what my plan is for that so far, but if anything ill have to put chicken wire on the perimeter of the garden bed. The only challenge is that it might keep not only the chicken out, but me as well (im lazy and navigating a chicken fence around the garden bed, could be detrimental).\nNow that I feel as though i have taken a good break and am feeling quite a bit better, I have a few plans for this website and the things id like to do. Starting with, getting comments back up and running.\nComments Planned updates Right off the bat, id like to get comments up and running again, but before doing so, id like to get a management console up and running. Theres a few reasons i want to get the management console, up. One is because i sometimes dread remoting into the server, and two, I dread running sql commands in fear of fucking up terribly.\nSome management console objectives are as follows\nSecure Authentication. Search comments by all values / fields. Manage visibility of comments. Delete comments. Block IP Addresses. Now this reasonably expands the database quite a bit, meaning ill need a few new tables now. As it stands, ill need a administrators table as well as a blocked_addresses table. I currently dont have a timeline for this project so im not sure how long it will take, but these are the changes needed to the software before im willing to bring it back online.\nHugo CMS The other side of this that im looking to do is implement a homebrewed CMS to the blog. I think it will be simple enough to do, but all im really looking to do with this application is as follows,\nCreate/Manage Articles Create/Manage ArchTypes thats really it.\nThanks for reading ! :)\n","date":"2024-05-22T09:31:43-04:00","permalink":"http://localhost:1313/p/2024-05-22-whats-next/","title":"Whats Next"},{"content":"The below question came from a class discussion, and I really enjoyed it because it is something that I have recently been doing quite a bit of research on personally. While I did respond to the discussion, it was not in the length that I would have wanted. So I summarized the two paragraphs here and shared it with class. Otherwise, my personal response is as follows below.\nDo you think using cell phones too much is bad for our physical or mental health? Why or why not?\nI think collectively, people have gotten to accustom to being chronically online. Personally, I believe that there are times that I come to realize I am obsessed with some internet personality, or I must contribute to my favorite page online or else I\u0026rsquo;m missing out. But eventually I realized that I substitute a lot of my time doing something meaningful with being online. The unfortunate part about all addictions as they are, is that they often start out harmless, without even noticing it. You might justify it in one way or another, but eventually it becomes compulsive, obsessive. To the point where you wake up and reach for that little black box, waiting to see what the algorithm has provided for you today. Many people unable to get out of bed before checking their social media likes and notifications.\nWhen I realized that social media was becoming a problem for me, was when I started to fall down a rabbit hole of car crash accidents and near misses (really near deaths). I remember I liked a post about someone white lining and then I continued to get more and more really good white lining videos. Eventually, that became videos where they got into a crash, and like a jump scare, for its purpose, solely a wow effect I liked the video. Thinking to my self \u0026ldquo;That\u0026rsquo;s insane the wreck those guys got into\u0026rdquo;. Eventually, I like enough videos and my entire feed becomes white lining videos where they end in near death, and again I\u0026rsquo;m sucked into this routine or habit where I like the video purely based on the wow factor, and it feeds my response into the algorithm to send me more and more videos like this. Eventually it went from four door cars to motor cycles, getting in near death accidents, almost falling of bridges on the highway, getting slammed into by a speeding car that blew a red light and so on. Consuming this kind of content on a day to day basis really ended up affecting my mental health state, causing me to get intrusive thoughts on top of the ones that I already get, mostly related to the type of content that I consume.\nWhen I finally realized what had been happening to my feed, it was almost too late. It got to the point where I would wake up in the morning and open my Instagram up, and boom a near death video of someone riding in a motorcycle. I had become utterly desensitized. I realized at that I need to stop using social media the way that I do. The truth is I hardly ever even post anything to it. On top of that, all of my friends I meet in person, on chat with them via text. Social Media is entirely useless for the point of keeping up with others. The most that it does for me is allow me to keep tabs on people I no longer associate with. Ultimately though, the final thing keeping me on social media really was the fear of missing out, or sometimes referred to as FOMO. I don\u0026rsquo;t think that I have a strong case of FOMO, but there are some niche internet personalities that I keep tabs on regularly, for almost purely content purposes. It is the same way with certain friends. Some people I know, just by mishap or something that I once did in life, and we made friends on social media and now I get to see life through your eyes. Ultimately, once you wean your self off of that last bit of FOMO, and you delete the last app from your phone, you\u0026rsquo;ll most likely find your self sitting alone one night with not much to do and left to a few decisions.\nSee what others are doing. Do something your self. Call a friend and do something together. Out of habit we all have come to the first option and see what others are doing, loading up our favorite social media app, and scrolling to their profile. But what a time suck, how much easier is it to call them up and go hey lets go get food, or lets go to the bar and grab a drink. Or even to think of that project that you\u0026rsquo;ve been putting off. Like prototyping that idea you had in your head. Or starting that hobby you always wanted to. Or going for a walk outside with your dog. If you can change your mindset to then be here and now, you\u0026rsquo;ve officially escaped the matrix. Soon, the last a bit of FOMO will leave your nervous systems, and your withdrawal symptoms will fade. With it will be new hobbies and activities. Given responsible usage, you could even maybe catch up with that favorite internet personality, or your distant friends on one of those social media apps. But for now, you\u0026rsquo;ve got full control over your actions and decisions.\nSuggested Reading Again, this decision wasn\u0026rsquo;t something that really happened overnight and it was something that built up for me as time went on and I learned more and more about internet addiction and the ways that I consume content. One of the books that I read that really helped me get a deep understanding of social media and the attention economy as a whole was How to Do Nothing: Resisting the Attention Economy. This book is one of the books that really sparked my awareness to my internet and social media consumption along with a number of other videos and essays on internet addiction.\nhttps://www.goodreads.com/en/book/show/42771901\nIf you get the chance, I would give it a shot and see what correlations you make with the text as you read through it.\nAfter Thoughts While, I don\u0026rsquo;t really participate in social media as religiously as I had before. I would like to say that I do count this website as a form of social media. I get to post what I want here, as well as do what I want here. This website is a form of expression for me, and allows for me to post and share my content with the world and friends. Without this website, I\u0026rsquo;m not entirely sure that I could get rid of social media.\nWhile I don\u0026rsquo;t honestly share this website with many people (truthfully this is mostly a blog about things I do at work) I do share tidbits of information here, and one day hope to post some more personal things onto it.\nIt is something that I am actively working towards. The difference though between this and a traditional social media website like Facebook or snapchat, is the fact that I cant see what others are doing. It is one sided. It wholly or partly, represents me as an individual, and my preferences.\n","date":"2024-02-26T20:46:09-05:00","image":"https://images.unsplash.com/photo-1617049483020-bf5a76956409?q=80\u0026w=2071\u0026auto=format\u0026fit=crop\u0026ixlib=rb-4.0.3\u0026ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D","permalink":"http://localhost:1313/p/2024-02-26-internet-addiction-and-cell-phone-usage/","title":"Internet Addiction and Cell Phone Usage"},{"content":"As a warning, Pedagogy of the Oppressed is a deeply theoretical text, and at that it is a leftist text, that contains many run on and long winded paragraphs for sentences. I recommend the read to anyone who can bear it. It is a 180 pages of though provoking statements. Below are my thoughts on the text as I read through it…\nTo start, what is a Pedagogy? As defined by the Merriam-Webster dictionary, a Pedagogy “the art, science, or profession of teaching”. In the case of this book, it is the art of teaching oppression. Immediately, you might think, who teaches oppression?\n“Who are better prepared than the oppressed, to understand the terrible significance of an oppressed society? Who suffer the effects of oppression more than the oppressed? Who can better understand the necessity of liberation?\nThe answer is the oppressed. Who is better prepared to oppress someone, that an oppressor? The oppressed. They already know all of the methods to exploit someone. Here for example, I think of the Stanford Prison Experiment. When the roles reverse, and the prisoners then become the guards, they forget as though they were never oppressed before. They have switched sides now, and play their role as the oppressor, to prevent becoming the oppressed reinforcing the standard.\nWho suffer the effects of oppression more than the oppressed? The Oppressor. This is because the oppressors maintain the status quo. The easiest example of this, could be again the Stanford Prison Experiment again. They have no insurance gauranting that they will receive any measure of safety when the roles reverse again. So the easiest way to maintain safety, is to continue oppression, in hope to break down their oppressors in to a useless state.\nWho can better understand the necessity of liberation? The oppressed. They relate to any oppression, due to the nature of the oppressor. They can understand the need for liberation among the oppressed immediately. This is why many oppressed groups often team together in resolving group problems. But how do you break this cyclical chain of oppression? It is simply to not oppress.\nIn a simple interview with a great deal of political activists, it is a common theme amongst them all, that at one point or another, the reason that they have become organizers is due to the simple feeling of hopelessness. What many activists hope to do is flip the script, and to then liberate the oppressed. But the means that they do so, is what matters to the author here. It is important, to not just become the new oppressor.\nWith that goal in mind, you may think now, what is oppression? Simply put, Oppression = The dehumanization of individuals. So why do so many liberators of the oppressed, eventually become their new oppressors? This is because often, the oppressed discover that without freedom, they cannot exist authentically. Although, this statement is only true in the fact that there are always oppressed. For without the oppressed, there are no oppressors.\nCombating Oppression Now that we have a good grasp on the definition of oppression as defined in the text, you may wonder how can we combat oppression? One might immediately move to violence. While I don\u0026rsquo;t justify violence in its self, I would like to note that the author him self states “Never Once has violence been started by the oppressed” For the nature of oppression is violent.\nImmediately what comes to mind for me is the difference in tactics between Martin Luther King Jr, and Malcom X. Martin Luther King Jr. was repeated placed in the spotlight and commended for his peaceful approach by the oppressors, because he did not pose a threat to them. I would like you to remember though that, it was the CIA that killed Martin Luther King Jr. Along with that, when we take the example of Malcolm X., many argue that the violence incited by Malcom\u0026rsquo;s protests, was never once provoked, we must remember though, that at every step of the way that the oppressor provided violence, by failing to recognize others as persons, by exploiting individuals. In the media, Malcom X. was portrayed as a criminal, and hunted by the oppressors for mimicking their oppressive tactics. In this case, I would like to remind you as well, that Nelson Mandela even did not believe that he could prevent the oppression the apartheid provided without violence, and did some twenty years in prison for the thought alone.\nThe book though mentions that the way to combat oppression, mostly involves the way that we teach individuals. Education in itself is a form of oppression. For example, every high school teaches why the Vietnam war was unwinnable, but never once do they mention why they were unpopular with minorities and leftists. Schools are advertised as a liberal institutions, but in reality schools are some of the most conservative institutions designed ever. Schools are designed to enforce the status quo. Your deadlines, writing limits, grade requirements, etc. are designed to indoctrinate you into society.\nSo how do we combat the indoctrination of education, and defeat the oppression of society? By challenging the way that you teach. Simply put, the only way to combat oppression is to develop critical consciousness within the oppressed. Making the oppressed aware of the power woven within their means. Critical consciousness forces you to question the status quo assigned to you by your oppressors. Often, what causes critical consciousness is what the author refers to as a limiting situation. A situation in which you begin to understand that the thoughts that were indoctrinated into you via your oppressors are no longer yours.\nOnce you have identified the ways you have been oppressed, to prevent then becoming a oppressor, you should practice co-intentional education, where both the instructor and student are both objects within the dialogue that are spoke and thought of critically. Why do you feel the way you do? What makes you believe that is true? dialogue and challenge the subject at hand, and eventually you will find the answer to your oppression.\nFood for thought What ways are you an oppressor? What ways are you oppressed? If your are an oppressor, how can you become an agent of change? If you are oppressed, in what ways are you oppressed? Why? ","date":"2024-02-23T23:59:14-05:00","permalink":"http://localhost:1313/p/2024-02-23-notes-on-pedagogy-of-the-oppressed/","title":"Notes on Pedagogy of the Oppressed"},{"content":"Recently, in an advent of troubleshooting a network issue, I had to run around and set a number of static IP\u0026rsquo;s onto devices. This being said, having to physically get up and run around a touch a number of devices can be a bit tedious.\nGiven you can get a remote session with each computer, you can issue the following commands using netsh.\nGathering Information Lets start by getting some information on the current device. To do so, you will want to run the following command.\n1 netsh interface ip show config The above command should spit out something along the lines of this, depending on how many network interfaces you have available.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Configuration for interface \u0026#34;Ethernet\u0026#34; DHCP enabled: No IP Address: 10.XX.XX.XX Subnet Prefix: 10.XX.XX.XX/16 (mask 255.255.0.0) Default Gateway: 10.XX.XX.X Gateway Metric: 256 InterfaceMetric: 25 Statically Configured DNS Servers: 8.8.8.8 4.2.2.2 Register with which suffix: Primary only Statically Configured WINS Servers: None Configuration for interface \u0026#34;Loopback Pseudo-Interface 1\u0026#34; DHCP enabled: No IP Address: 127.0.0.1 Subnet Prefix: 127.0.0.0/8 (mask 255.0.0.0) InterfaceMetric: 75 Statically Configured DNS Servers: None Register with which suffix: Primary only Statically Configured WINS Servers: None The key thing here to notice is that the DHCP enabled line says no, meaning that the address shown under IP Address is your statically assigned IP.\nManipulating the Network Card Next, to modify the DHCP enabled value and essentially over write the statically set address, you will want to run the following command.\n1 netsh interface ip set address \u0026#34;Ethernet\u0026#34; dhcp Note that the above command contains \u0026ldquo;Ethernet\u0026rdquo; for the interface that I am manipulating, but you should use whatever interface you want to modifies name is. For example some computers, it shows up as \u0026ldquo;Ethernet 2\u0026rdquo;.\nIf everything works, running the above command will literally brick your session, booting you from the console. Give it a few seconds, then do a NSLOOKUP or a PING to find the new IP assigned by DHCP, and you should be able to ping it again.\nIf the device is pingable, then it should be online and good to go.\n","date":"2024-02-15T06:48:01-05:00","permalink":"http://localhost:1313/p/2024-02-15-manipulating-the-network-card-with-netsh/","title":"Manipulating the network card with Netsh"},{"content":"I console into a number of computers daily. Many running different services etc. I also have a few different devices everywhere I go, whether it be my home PC, laptop, or work laptop etc. Along with the many devices, a good chunk of my work consists of editing text files. Most of that time spent in vim. So a decent configuration is almost a neccesity to keep my productivity up.\nI used to keep my nvim configuration in a configs repo on github, but as time went on, every system I touched, or every update I made to the repository meant that I would have to git pull origin and copy the contents into where ever the hell my nvim config folder was.\nWell, If I seperate the nvim configuration folder/files into its own repository and then clone the repository as my config, I could create an alias called nvim-conf-update to git pull origin in my configuration folder and automatically sync all of my configurations.\nHell this could become an automated task.\nSo i set out to seperate my nvim configuration.\n","date":"2024-01-22T15:34:58-05:00","permalink":"http://localhost:1313/p/2024-01-22-streamlining-your-nvim-config/","title":"Streamlining Your Nvim Config"},{"content":"To start, i like to routinely image my devices just to get a fresh start on them. Often, i add apps or tools that I think that I will use, that I never end up using. Most of my devices get pretty cluttered pretty quickly too so re-imaging them is a way for me to avoid data hoarding. That way, everything that I need thats important ends up backed up somewhere on a different physical device. Typically, I re-image my devices once a semester if not once a year to keep things simple, and assign a time frame so that im not nuke and paving my device in the middle of the semester.\nThat being said, this time I decided to try out using winget to setup my device.\nWhat is WinGet? Well if you didnt already know, WinGet is the windows package manager (sorta). It allows for you to easily search for packages using winget search xxx and to install packages using winget install xxx, and finally winget update xxx. But a major pro to winget, and why it is alive and working today, is because it is for the most part community maintained. The entierty of winget exists in this github repository (https://github.com/microsoft/winget-pkgs). Interestingly enough, windows made some very important design decisions when making winget.\nThere will be no hosted distribution server like debian or arch package managers. Meaning that every package that you create for WinGet, must be publically accessible via other means. Typically, this means that you are creating an application on your own and releasing it, via github or your own applications website, and then creating a manifest file with instructions on where to find your installer, how to install it, and etc.\nA Immediate issue with this kind of methodology is that winget becomes insanely slow to work with. Installing a package on windows already takes up quite a bit of time, but having to download the packages from a million different sites adds times to the installs. WinGet also doesnt asynchronously work like the apt or yum or pacman application managers do, so you are stuck with slow download speeds and slow installs.\nUsing WinGet to your advantage. What apps do you use on a daily basis. Can you find it on winget? Probably.\nGo through all the apps on your computer and create a list. Search for each app on winget and generate a install string for the package. Something along the lines of winget install Mozilla.Firefox Paste the install string into a powershell script. When you setup or touch a new PC, just run that powershell script and when you come back, your computer will be ready to go with freshly installed tools. ","date":"2024-01-22T14:05:35-05:00","permalink":"http://localhost:1313/p/2024-01-22-scripting-a-new-install-with-winget/","title":"Scripting a New Install With Winget"},{"content":"For a long time, I kind of hacked this website along, by modifying the templates core files to get things to work like the favicon, avatar image etc. When I migrated from ghost, it was in the middle of semesters and I just didnt have the energy to dedicate to figuring out how the hell to use the theme. What unfortunately sucks is that the github repository tells you to do it one way, and the support documentation tells you to do it a different way.\nNow that I am a great deal more confident with using hugo and manipulating its properties, I decided to restart the website from scratch and do it the right way. Boy was it a little more complicated than I thought.\nFrom about 2100PM UTC to 2300PM UTC, the website was up and functioning, but without any kind of SASS. The root problem was quickly identified that the starting template that the github provided is either A outdated, or B a development template.\nI quickly reverted back to the old source, and began to follow the instructions from the support documentation website and taking it step by step, and comparing notes with the official hugo documentation.\nThere\u0026rsquo;s quite a few things that the developer of the theme does that he doesnt necessarily explain, along with the hugo documentation doesnt explain either. One of the things that I really enjoyed was the modular configuration/ folder, where inside you just have a bunch of .toml files that can be separated by names that will ultimately compile into one file. This makes a what would be 200 some line configuration file a collection of brief 20-50 line files that are purpose created and sorted.\nFinally, I was also able to fully understand the difference between pages, and posts. Mainly, the difference for hugo is how they are rendered. Pages are more intended for things like about/ or security/ while posts are just posts. That means that I could ideally make a page, and not link to it anywhere on the site, making it a sort of link only page. Its an interesting thing to think about and id be interested in playing around with it in the future.\nOtherwise, there is my update for the brief outage. Again, Ideally, there would be no production outage because I would have a development server that I could test the deployment too. But, because I am cheap, production errors will happen.\n","date":"2024-01-20T22:52:14-05:00","permalink":"http://localhost:1313/p/2024-01-20-website-refactor/","title":"Website Refactor"},{"content":"\rAbove is a screen capture of my progress made with the game fallow. A few things so far, I have no idea what I want this game to be. The best word I have for it so far is an interactive adventure. I think of those terminal story games where you must look around, explore, get into combat, loot, go back, etc. I’m not sure how this will flush out entirely but overall I am taking this as a learning experience.\nIt is my first time writing any kind of game, let alone any kind of game using Godot. On top of that Godot uses GDScript, which is an interpreted language similar to python (if not exactly python).\nBesides the things I talk about in the video, what do I like about it? Well mostly, so far, I really like the fact that GDScript forces you to almost work in a functional aspect. I’m not sure that I ever considered python to be a functional programming language. I also don’t have much experience with it either, so I don’t really know either way.\nGodot offers a C# variant that allows you to program games that way, but my biggest aversion to that, is that it feels almost Tootoo serious for what I want to do. I think so far, I’ve made the right call GDScript is flexible and has what I need to be successful in making this little game.\nObjectives The next few things I need to do in the game are as follows.\nPersistent Player Health and Experience. Combat. Complete the game loop. The ability to go back home or to town. Bloopers At some point in the development proccess, I ran into an issue setting the map. It didnt make the initial cut for the video because it was a bit of flashing between themes, but the behavior was intended. This was a great exercise of some problem solving skills and a reminder that I dont know everything. It takes breaking the problem down into smaller pieces and analyze the issues at hand, and the error presented.\n","date":"2023-12-20T22:22:22-05:00","permalink":"http://localhost:1313/p/2023-12-20-fallow-devlog-02/","title":"Fallow Devlog 02"},{"content":"Finals are over, so you know what that means\u0026hellip; New Favicon :). Well kind of. I\u0026rsquo;ve purposely left the favicon. Deep down, I have always wanted to make the favicon a simple spiral. But unfortunately, my obession with spirals is not strong enough, nor do i think it represents this website appropriately. So as a compromise to my self, ive left the favicon blank until i find or request someone to generate a said favicon. Well, today is the day. Browsing itch.io I came across a pixel planet generate (oh em ghee, i had to check this out) and well it does exactly what it said it would. And im in love. And so i set out on a quest to generate a million planets until I found the one that I wanted. You can find and play with the same exact program I was here https://deep-fold.itch.io/pixel-planet-generator\nIt reminded me of an old program that I made a while ago, where I was experimenting with noise maps, and the rasterization of said noise map. The fun part about this experiment of mine was that it had three decimal points to it, and each decimal point was translated into a RGB color code at some point. Making at times this really magnificent image.\nMoving forward, what are our candidates for the favicon?\nCandidate one What do I like about it? Its simple, the clouds are nice and it is somewhat land, somewhat clouds. There is unfortunately way tooooo much land to be a close representation of earth. But overall I like it.\nCandidate two This is probably the most similar to earth, although my only dislike of this is that it probably represents pangea better than it does the modernday continents. Which is fine with me either way.\nCandidate three I really like this one, It does a good job at displaying the ring around the planet, and the colors are more of my style. Overall this is very high up in the ranking list.\nSo what will I pick? Well, to be honest with you I like each of these individually, but after experimenting with each of these I think that I prefer candidate two as it gives the most texture in the small favicon view. Overall though, it was nice to see the program and shader written in godot, and I got a neat favicon out of it. Win Win :)\n","date":"2023-12-18T14:05:09-05:00","permalink":"http://localhost:1313/p/2023-12-18-finally-a-favicon/","title":"Finally a Favicon"},{"content":"Today, I had an unexpected downtime of roughly 2 hours 2023.11.28 3-4 UTC. I had a Russian visiter Sunday (?) the 25th who commented essentially an ad about their website SEO skills onto the comment board. This is unfortunately the internet, and even more so a comment board where anyone can say and do anything (within the rules).\nNormally I would have no real issues with what they have done, as it is not commit a crime, nor is it necessarilly disruptive. But they did happen to comment three times, each time the same thing without any kind of variation. This was cause for concern\u0026hellip;. (im joking). But as a webadmin, I can do whatever the hell I want and censor whatever kind of things I want to censor, so why not exercise my webadmin rights and change the visibility of the excess comments and then leave a curdious note to the user about why I had to mark their notes as hidden? Naturally, you have to hide the comment on production right?\nHeres where everything starts going down hill\nI decided to begin by running the command sqlite3 comments.db. That is where i messed up first. I should have made a backup of the database. Its prone to human error (me, its prone to me, absolutely fucking it up, im the problem).\nI then, was sitting in the console and it has been so long since ive worked on this project, I have no idea what the hell kind of comannds I need to run to view the database scheema, I know I could look at the source code, but curiosity got me and what if i didnt have access to the source code? well you can run\n1 2 .schema ON .schema and it spits out the schema used to create the database. Cool, ive got my column variable types, and ive got the id from the comment board. So i need to just set the visibility to 0.\nBoom, I do that with the following command, UPDATE comments SET visible = 0 WHERE id = \u0026quot;\u0026lt;id_goes_here\u0026gt;\u0026quot;; it works. I do it for the other post i want to get rid of. And I update the poorly named slqite-commands.md file with the command i used. Boom bam bow, whenever this happens again, i\u0026rsquo;m a prepared web admin.\nI type my relatively polite message up:\nHello MikhailRS, thank you for visting the site. This is by far the internet, you are welcome to do whatever you want to my site. I can simply destroy this website and start it up again. But please, in the future, do not repeat your post as it is breaking the rules (no spam) as listed in the above headers.\nAlthough I appreciate your feed back as you have made a few things apparent to me, One the rules should be numbered in an ordered list so i can refer to them as numbers and not by \u0026ldquo;the rules\u0026rdquo;. Two, when I hide a comment, it still rederns in the html as a comment_ div. I will need to fix that sometime soon, its looking like a bug that will get resolved in probably 5 weeks as finals is coming up.\nThank you my friend :)\nGoogle Translate, do your thang:\nЗдравствуйте, МихаилРС, спасибо, что посетили сайт. Это, безусловно, Интернет, вы можете делать на моем сайте все, что захотите. Я могу просто уничтожить этот сайт и запустить его заново. Но, пожалуйста, в будущем не повторяйте свой пост, поскольку он нарушает правила (без спама), перечисленные в заголовках выше.\nХотя я ценю вашу обратную связь, поскольку вы объяснили мне некоторые вещи, во-первых, правила должны быть пронумерованы в упорядоченном списке, чтобы я мог называть их числами, а не «правилами». Во-вторых, когда я скрываю комментарий, он все равно отображается в HTML как div comment_. Мне нужно будет это исправить в ближайшее время, это похоже на ошибку, которая будет исправлена, вероятно, через 5 недель, когда приближается финал.\nСпасибо, мой друг :)\nAnd post it to the comment board.\nI then try to push the changes to the git repository and run into an authentication error. Why is that? maybe its because I don\u0026rsquo;t have my ssh keys on the server. Why is that? because its publicly accessible and prone to Russian dudes poking my server. And why don\u0026rsquo;t i want my ssh keys on the server? because they are used to authenticate to my GitHub. I at some point used my brain in this convoluted process.\nNo biggie, let me just git pull origin and uncommit all of these stupid changes. LOL. it overwrote the database. All comments lost, Im not back at the tracked testing version of comments.db. About 6 months worth of commenting gold lost in the wind. Only to be held in my memory. This can never happen again.\nSo I go on a bug fixing protocol making rampage, I resolve the bug causing empty divs to show when i hide a comment and fix a number of spelling errors along the way. I also create a backup solution to never do this again. And with that, I hopefully never make changes on prod again.\nTo over view heres a list of ways that I fucked up:\nMake changes on prod. Commit changes on prod. Roll back changes on prod. Don\u0026rsquo;t back changes up on prod. Keep your database in the same folder as your source (shhh we didn\u0026rsquo;t talk about this). Other than that, the kind stranger MikhailRS taught me a few things though. List your rules as numbers so you can refer to them as Rule #4 instead of Rulez. You also pointed out a bug in the templating that I had. Finally, you also reminded me that I need to create a admin panel of sorts to hide comments lol.\nOverall, there is my report on what the went wrong, November 28th, 2023.\n","date":"2023-11-28T12:29:55-05:00","permalink":"http://localhost:1313/p/2023-11-28-comment-downtime-2023.11.28/","title":"Comment Downtime 2023.11.28"},{"content":"Asset Inventory Management systems present challenges for many organizations. The daily task of managing, finding, and tracking devices can be time-consuming. Various ideas emerge to simplify device tracking, such as naming devices after their serial numbers. However, this approach often provides limited insight in case of issues.\nConsider the alternative of assigning meaningful names like BLD-FLASTNAME01 or lastname01—common practices to enhance clarity. Yet, challenges arise when dealing with staff changes or shared devices. Renaming devices becomes a necessity, and the process of re-imaging and renaming raises questions about efficiency.\nImplementing an asset inventory system is the logical next step. But what\u0026rsquo;s the right approach? Perhaps hosting a solution externally? The basic requirements seem straightforward: Device Name, Manufacturer, Model Name, Model Number, Serial Number, Asset Tag, Assigned Staff, and maybe the date of imaging. A SQL server could handle this, right? A simple C or C# program could populate rows for each imaged device.\nHowever, the simplicity fades when colleagues without SQL skills request reports. Running reports becomes a frequent task, and the SQL server database becomes impractical.\nExploring solutions, one might encounter tools like Snipe-IT, which ticks all the essential boxes. It provides access for non-SQL users but relinquishes some control over the database. The relational database structure, as highlighted in this discussion, adds complexity. Navigating the Snipe API documentation reveals that simplicity is elusive.\nUnraveling Complexity with a Graph Adding a hardware entry involves creating a status entry, which requires a Status Name and a Status Type. To create a Model Entry, one needs a Category Entry and a Manufacturer Entry, each with its own set of requirements. While seemingly convoluted, this structure addresses an important issue: human error.\nThe challenge of discrepancies due to typos or variations in entries—whether in spreadsheets, SQL databases, or Snipe-IT—becomes evident. Using relational databases, where entries are referenced by ID rather than name, minimizes type 0 errors.\nWhat initially seemed like a quick and easy solution now demands effort to automate device information entry into Snipe. The transition from manual entries to relational databases may pose challenges, but it ultimately addresses issues of consistency and accuracy in asset inventory management.\n","date":"2023-11-17T15:33:30-05:00","image":"https://images.unsplash.com/photo-1569653402334-2e98fbaa80ee","permalink":"http://localhost:1313/p/2023-11-17-navigating-the-challenges-of-asset-inventory-management/","title":"Navigating the Challenges of Asset Inventory Management"},{"content":"Gah, they make everything so hard. (I need to run two simple commands.) Why cant I just run one command and flush the dns on my mac? Well im sure theres a better way to do this\u0026hellip; (there is)\nWelcome to flushdns(.sh)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #!/bin/bash # This script will clear your dns cache on your mac. It has been tested on macOS 13.4 Ventura # Joshua Winters-Brown if [ \u0026#34;$EUID\u0026#34; -ne 0 ] then echo \u0026#34;Please run this program as root, otherwise it will not work appropriately.\u0026#34; exit fi dscacheutil -flushcache; killall -HUP mDNSResponder \u0026gt; /dev/null echo \u0026#34; _____ \u0026#34; echo \u0026#34; | D \u0026#34; echo \u0026#34; | | \u0026#34; echo \u0026#34; | | \u0026#34; echo \u0026#34; \\___| _ \u0026#34; echo \u0026#34; || _______ -( (- \u0026#34; echo \u0026#34; |_\u0026#39;(-------) \u0026#39;-\u0026#39; \u0026#34; echo \u0026#34; | / \u0026#34; echo \u0026#34; _____,-\\__..__|_____ \u0026#34; echo \u0026#34; \u0026#34; echo \u0026#34; Your DNS has been flushed... \u0026#34; Throw this script into your /usr/local/bin and you can run flushdns from anywhere in the terminal.\nTada!\n","date":"2023-10-12T16:45:31-04:00","permalink":"http://localhost:1313/p/2023-10-12-flush-dns-on-mac/","title":"Flush Dns on Mac"},{"content":"Allrght, I did a vulnerability scan on the web server, there was something about the version of nginx installed had a flaw in it, so I went ahead and patched the nginx install. Ofcourse only because it is patch thursday and it might as well be on a list of things todo. Well, everything went smoothly; I upgraded to the latest version, refreshed the website in the browser, checked my config file, and were good to go. I then promptly left for lunch and didnt get the chance to check back at the website until approximately 7 UTC. Well, the website was infact not good. it was down, and probably down since i made those changes. I began to search for the issue. A quick grep, showed that my config files all existed and contained the domain name and hostname of the website. So whats the issue, why is it not reading my configs? Well that was the problem, and quickly came the solution. When you upgrade the nginx installation it overwrites your previous config file. Im not sure if there was any other magick stuff I was doing in the config file before I updated, but I included the sites-available directory, and were good to go. So yeah, the site was down for aproximately 3 hours. Thanks chaps :)\n","date":"2023-10-05T14:58:10-04:00","permalink":"http://localhost:1313/p/2023-10-05-dont-update-nginx-without-a-backup-of-configs/","title":"Dont Update Nginx Without a Backup of Configs"},{"content":"This guide is intended for Ubuntu 22.04 and is intended for use with a Apache2 web server. To get started we need to make sure you have Apache2 installed, we can use grep to check. These instructions were written on a Ubuntu Server.\n1 apt list --installed | grep \u0026#34;apache2\u0026#34; Next will need to allow Apache through the firewall on both http (80) and https (443). We can do so with the below command\n1 sudo ufw allow \u0026#34;Apache Full\u0026#34; Next we will need to enable the Apache mod_ssl module. The Apache mod_ssl module will allow Apache to support SSL encryption. The command to do so is below.\n1 2 sudo a2enmod ssl sudo systemctl restart apache2 Now, Apache is configured and ready for encryption. We can move onto generating a TLS certificate. To do so we will need to do the following below command\n1 sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/ssl/private/apache-selfsigned.key -out /etc/ssl/certs/apache-selfsigned.crt Running the above command will prompt you to enter a bunch of information. Please follow through each of the steps and answer them completely. The following flags on the above command do as listed below\nFlag Description req -x509 This specifies that we want to use the X.509 certificate signing request managment. X.509 is a public key infrastructure standard that TLS adhears too. -nodes Nodes tells OpenSSL to skip the option to secure our certificate with a passphrase because we want apache to be able to read the file. A passphrase would prevent apache from being able to do so. -days 365 This option sets the length of time that the certificate will be considered valid. Here we have set it for one year. Browsers will reject just about any certificate that is valid for longer than a year. -newkey rsa:2048 This tells the program we want to generate a new certificate and key at the same time. the rsa:2048 makes it a RSA key that is 2048 bits long. -keyout This line tells the program where to place the private key file. -out This line tells the program where to place the certificate that we are creating. As a general note, certificates and their keys are generally recommended to be put in the /etc/ssl/private (for keys) and /etc/ssl/certs/ (for certificates). It is a best practice that we should employ.\nTo recap we have just created a key and a certificate.\n/etc/ssl/private/apache-selfsigned.key /etc/ssl/certs/apache-selfsigned.crt You can test if either file exists by, running the following command\n1 2 sudo locate apache-selfsigned.key locate apache-selfsigned.key Configure Apache to use TLS Since we have created our self signed certificates. We will then need to tell Apache to use them. We can do so by editing our Apache .conf file. These are typically in the /etc/apache2/sites-availabe folder. We will start by creating a new file in the /etc/apache2/sites-available/ folder.\n1 sudo vim /etc/apache2/sites-available/my_website.conf next you will want to paste in the following information. Make sure to update it accordingly to before creating this file.\n1 2 3 4 5 6 7 8 \u0026lt;VirtualHost *:443\u0026gt; ServerName your_domain_or_ip DocumentRoot /var/www/your_domain_or_ip SSLEngine on SSLCertificateFile /etc/ssl/certs/apache-selfsigned.crt SSLCertificateKeyFile /etc/ssl/private/apache-selfsigned.key \u0026lt;/VirtualHost\u0026gt; Next we will need to enable the configuration file with the a2ensite tool.\n1 2 sudo a2ensite my_website.conf sudo systemctl reload apache2 Finally, your web server should be good to go with a self signed cert. Now I would recommend you visit it and ensuring that you are using the https:// prefix. If alls well, you should get a error, saying that it cant verify the identity of the server. This is normal behavior because in fact, we gave it a self signed cert. In the future, It would be advisable to get your certificates from a CA vender.\nI no longer want any http:// requests We can redirect all http:// to your https:// route relatively easily. To do so you will need to edit your .conf that we created above, and add the following configuration to it:\n1 2 3 4 \u0026lt;VirtualHost *:80\u0026gt; ServerName your_domain_or_ip Redirect / https://your_domain_or_ip/ \u0026lt;/VirtualHost\u0026gt; I would recommend doing a backup of the conf before hand just incase you break something in the process. You never really know what may happen.\nNow all you will need to do is bounce the service, and give it a run.\n1 2 sudo apachectl configtest sudo systemctl reload apache2 You can test this by attempting to force your browser to visit the insecure version of the site. To do so ensure that the prefix to the websites name is http://.\n","date":"2023-09-21T16:39:17-04:00","image":"https://images.unsplash.com/photo-1605351792643-fe0c43d18762","permalink":"http://localhost:1313/p/2023-09-21-creating-and-managing-a-ssl-cert/","title":"Creating and Managing a SSL Cert"},{"content":"NMAP really needs some kind of file output option that isnt leetcode, xml, or gibberish. I would kill for a csv output from nmap. Regardless, lets solve this problem. I chose to ues python because I figured it would be quick and easy and would take no time. I was in fact wrong; Im not quite as comfortable with python as I am with rust at this point, but thats ok. It took about 2-3 hours to build and test a simple program. This stupid script, took a little over 40 minutes trying to figure out how to build a stupid CLI interface and I immediately realized I miss rusts built in fail handling. Your telling me that I have to try, except everything???. Oh well it doesnt matter anyways this doesnt actually compile down to machine code there are no assembly jumps or calls, lets just do it\u0026hellip;.\nGod I hate this I decided to just cave and research a few CLI libraries and landed on plac, which has some very terrible documentation. For example, they do not explicilty provide a way for you to accept a file path or string lol. I just had to play around with the program until I found something that works, but this library could literally kill for some more english in the documentation. After I got that going it was easy peasy lemon squeezy. Except, when you error out, it doesnt really tell you why if your in a try catch loop. So I have to effectively comment out the try catch loop, and lower my code a indentation bracket figure out what the hell is breaking my code, just to realize I forgot to pass a variable to a function but was referencing it anyways\u0026hellip;. Another downside to try catch. Why the hell is my program failing. Otherwise, this program is less than 40 lines without all the stupid comments.\nAll I could think about was those intro to CS classes in college where your just recycling CSV parsing code over and over again for a whole semester and building stupid text UI. All those hours of code, ammounted to a waste of three hours at work trying to get a CSV. But was it worth the three hours one might ask? well, the fact that I can run and scan the network using NMAP, and imemdiately convert it to a csv file to later open in XSLX or another stupid app to make a report later in my day in seconds, I would say that yes. Yes spending the three hours fighting with try, catch loops was worth it.\nTLDR, noob gets wrekt by pythons immaculate error handling. Check out my project, noparser\n","date":"2023-09-21T09:53:13-04:00","permalink":"http://localhost:1313/p/2023-09-21-simple-file-parsing-takes-three-hours/","title":"Simple File Parsing Takes Three Hours"},{"content":"\rPreface In a behavioural organization class, we have an assignment to watch a movie and pick a sceene from it where we notice some organizational behaviour coming into play. Below are my awnsers to this assignment.\nOrganizational Behaviours in Media This clip is from the movie Free Guy. It is a movie about a bank teller, who learns that he is a non-playable character or NPC in an open-world video game, akin to GTA. In the story, the character goes on to become the hero, and saving two real life peoples lives as they discover the code that is running his character was stolen from them. In the recorded scene, we witness many Organizational Behaviors exhibited by Antwan, the owner of the company. One of the first things that Antwan does is use some conceptual skills.\nInitially the Main Character, Blue Shirt Guy, being an out of control NPC causes issues. Antwan sees the publicity of this event as an Opportunity to embellish and grow the company\u0026rsquo;s profits by maximizing the character\u0026rsquo;s image. We could also consider the Art Nerds a Technical Skill, in being able to create and design the new Blue Shirt Guy Character.\nAnother example of Technical Skills could be Keys being asked if he would like to be promoted to a developer or programmer. An example of Differentiation Strategy in this clip could be Keys attempting to wager Antwan on making a new and unique game that masters its craft through careful consideration and development.\nAntwan unfortunately shuts Keys down by rather taking an operational Excellence approach, demanding that they instead stick to what they are good at, and continue to profit on the framework that already exists.\n","date":"2023-09-19T17:36:35-04:00","permalink":"http://localhost:1313/p/2023-09-19-organizational-behaviour-examples/","title":"Organizational Behaviour Examples"},{"content":"Ever needed to find something in a directory filled with text files. Use grep. The command I enjoy to using is as follows:\n1 grep -Ril \u0026#34;what the H E double hockey sticks\u0026#34; ","date":"2023-09-08T07:55:32-04:00","permalink":"http://localhost:1313/p/2023-09-08-how-to-search-text-files-with-grep/","title":"How to search Text files with grep"},{"content":"Ever wonder what port your connected to when plugged into a ethernet jack? Open up wireshark and apply a filter, searching for cdp or lldp traffic. That will kick back:\nThe switches MAC Address. The port description. The switch system name. Some information about the operating system running on the switch. Don\u0026rsquo;t see any information populating? Most likely your network admins have disabled your switches from transmitting CDP or LLDP traffic. In this case, im sorry this wont work for you.\nHave fun troubleshooting.\n","date":"2023-09-07T16:51:44-04:00","image":"https://images.unsplash.com/photo-1619468129361-605ebea04b44","permalink":"http://localhost:1313/p/2023-09-07-where-am-i-on-the-network/","title":"Where am i on the network?"},{"content":"Im back!\nIve been gone for a little while now. I went on vacation to mexico for about 21 days to visit friends. I had a blast. Everything there is vastly different than here in the states. Where I live, if you need anything other than beer you need to drive about 5-20 minutes to get whatever you need. In Druango Durango Mexico, If I need to go to the store, its about a 5 minute walk to a Ley; The equivalent of a walmart or meijers. If im in the mood for some chips and a soda, theres a conveince store, or Oxxo within 2 to 5 minutes. Hungry for a burger, theres a place that sells hamburgesas down the street. Come on lets walk its only 10 minutes away! I will tell you though, I was a little dissapointed in the hamburgessa. I was expecting a american hamburger but instead found, carne asada, a salchica split in two, hamon, lettuce tomatoe, onion, pickles, mayo, mustrard, ketchup all on a bun. It was decent, but wasnt what I was looking for.\nAcross the street from where I stayed was a community center. A place where the community can host classes to teach all kinds of things. On Tuesdays and Thursdays theres karate class. On fridays theres dance class teaching you how to perform traditional Aztecan and Mayan dances. On Mondays and Wednesdays theres Singing Class. Tuesday evening they show you how to use a sowing machine and make dresses. Theres a park, with soccer goals, baskeball hoops, playground equipment, etc available all the time. Theres washers and dryers available for those who need them, etc. Over all the community center is something very strange to me. There arent many things like that in america. The closest I could think of is boys and girls club, but im not even sure thats everywhere in the states and Its most definetly not as flexiable as the community center.\nOver all I really enjoyed my trip and cant wait to go back. But for now, ive got school and work to focus on. Ill attach a few photos below.\n","date":"2023-09-07T10:32:58-04:00","image":"https://unorthodoxdev-bucket-public.s3.amazonaws.com/scorpion-hand.jpeg","permalink":"http://localhost:1313/p/2023-09-07-vacation/","title":"Vacation"},{"content":"Advent of Code is a annual set of Christmas themed programming problem that follow an advent calendar. I have heard about Advent of Code (AoC from now on) before but never committed time or resources to it.\nStruggling to learn C, I decided to go through the AoC content from 2015 to current and complete each of the challenges with at a minimum, attempting to use C. The nice thing about doing the older problems, well really any problem, is that there are plenty of resources around online to help me work through and solve the problems.\nI plan to go through at least one problem a day on my lunch break if not more given time permits and upload it to my github repository. Depending on how I feel I may produce a write up of the problem, challenges I faced, my resolutions, how I could optimize, etc\u0026hellip; I think that this will be a fun exercise and prep me for when the 2023 AoC comes around.\nFun Fact! I did not know that people could prestige programming problems but I recently learned, that people have prestige AoC. I guess at the end of the day, it is a game :)\n","date":"2023-08-09T15:07:00-04:00","image":"https://images.unsplash.com/photo-1606482512676-255bf02be7cf","permalink":"http://localhost:1313/p/2023-08-09-advent-of-code/","title":"Advent of Code"},{"content":"This is a guide i\u0026rsquo;ve created with some notes I have created while working through the networking+ content. While I do plenty of networking troubleshooting experience, these instructions ensure that I STOP, and SLOWN DOWN and think about the changes. Something else I enjoy about these instructions is they force me to think more about change management. Something I need more practice with.\nGather as much information as possible. If possible, duplicate the problem. Break the problem down into meaningful bytes. What steps need to occur and in what order? a lot of people use this step as an opportunity to begin working their way up or down the OSI Model identifying the processes that take place. Generate a few different hypothesis\u0026rsquo;s and the steps needed to take to resolve these issues. Document these issues somewhere publicly where you and your peers can look back at them. When you begin making changes, document the steps taken to test your hypothesis and perform one change at a time. After you have completed the change, assess the situation and determine if the change has produced a favorable result. Once you have confirmed that you have resolved the issue, reach out the customer and confirm that they are seeing the same behavior as you are. Document, Document, Document everything. ","date":"2023-08-09T14:17:19-04:00","permalink":"http://localhost:1313/p/2023-08-09-network-troubleshooting-methodology/","title":"Network Troubleshooting Methodology"},{"content":"I am the ultimate procrastinator. I can never seem to commit, or consider a project done. I have a perpetual train of thought going on when I think of projects or problems. I often wont even start a project, unless I can envision the end. Some people may see this as a good trait, being that I am able to plan the project, and goals out from start to finish instead of aimlessly working on something. Sometimes, I may already have the end goal of my project or problem determined, but my issue is then, finding a way to complete it. Maybe not all the tools are there for me that I hope there would have been.\nLately I have been learning C. Not C++, not C#\u0026hellip; C. One thing I learned very quickly with C is that there is no hand holding. If you do not manage your memory, you\u0026rsquo;ve blown your program up. You don\u0026rsquo;t know how to do something, you\u0026rsquo;ve made your project 100 times harder now trying to include some foreign library, versus developing the solution your self. My initial Idea was to create a program, that pulls the API information from the local Transit station, and parses out the information into a pleasant way. This program in rust, hypothetically would be pretty quick, and i\u0026rsquo;ve already got an idea on how I would do it!\nI would start by using actix to pull the API get request. parse the JSON response using serde. Then use rata-tui to generate a beautiful text UI for it. All together, given I didn\u0026rsquo;t run into any hiccups, this project would probably be done in maybe~ 2 to 3 days If I used rust.\nAfter almost a month of running through C projects and experiments. Ive found that, I am absolutely destroyed by the lack of features with C. My first challenge was making a get request to the Transit web api. I eventually resolved that issue using libcurl which is very terribly documented, and everything is just a pain in the ass to read an understand. But one other issue with using libcurl, is that it requires that the system the program is running on, contains the application curl. That is an issue that I haven\u0026rsquo;t really ran into before when programming with rust. Everything is just code, that compiles to assembler that compiles to binary, that the machine understands and executes. Now i have to add another contingent, an application I cant/don\u0026rsquo;t want to package with my application.\nNow I understand why applications ship with DLLs. Or why the applications have underlying conditions when installing them. Regardless of how I felt about including libcurl, I moved forth and began to deal with my newly found string that contains the response from my API. After many segfault\u0026rsquo;s I\u0026rsquo;ve got to parse this JSON string. Like I stated above, I would simply just use the serde library. But because C doesn\u0026rsquo;t have a JSON library (C was made way before the web, or JSON existed) I need to create my own parser.\nThe above two issues, is reason enough for me to understand why some hardcore C developers keep every piece of code they have. Because when they run into the same JSON parsing issue, they can look at the function, or file that they made last time, and implement the same function or file into the new program.Rust and most modern languages have provided such a standard, containing large standard libraries and easy to import and manage 3rd party libraries that It was hard for me to think of a time where that wasn\u0026rsquo;t an option.\nThe thing I like the most about C is that it forces me to think. To use my smooth brain on how to parse a JSON element, what are the rules that JSON employs? How can I connect to a HTTP Web server, on port 80? How can I save the response? All of these thoughts come from a rough brain. One with ridges and valleys and peaks. Not mine.\nWhile, I think the Transit app i was planning on building with C was a bit too big for me to handle right now, my plan now is to finish it in Rust, and then In preparation for the 2023 Advent of Code, i would like to begin practicing my C solving those problems. Problems which are small and manageable, and I\u0026rsquo;m sure have plenty of resources online for the language that I will be using. Shoot, I\u0026rsquo;ve even found a guy who created an entire language, for solving the Advent of Code problems conveniently in\u0026hellip;. Rust. So while i\u0026rsquo;ve completely changed the way I will handle my next app. I have added a completely other thing that I have dedicated my self to. Finding more things to do, when there is already so much.\n","date":"2023-08-07T09:36:33-04:00","permalink":"http://localhost:1313/p/2023-08-07-finding-things-to-do/","title":"Finding Things to Do"},{"content":"I recently migrated my website from ghost blog to hugo which is a static site generator compared to the all in one package you get with ghost blog. One of the reasons I decided to make this change was honestly, I had no need for all of the many features that ghost blog provided. Something like Hugo was simple, and effective. It also allowed me to write my documents in mark down, and store the entirety of it in a git repository. Making the portability of my website insanely simple, compared to managing the ghost blog.\nOne of the features I missed from ghost blog though, was the comment feature. Something I really enjoyed. With some Hugo blogs, they do enable you to add a comment feature, but requires that you have some kind of third party application that you sign up for. That pretty much was a no go for me. I don\u0026rsquo;t want to have my self or readers sign up for some ooey gooey third party provider. So because i\u0026rsquo;m lazy, I decided to create my own comment board.\nIve been learning rust for some time now so I settled on that language. It would be a good proof of concept and really help me get my foot in the door when it comes to getting confidence in the language.\nPlanning Lets break down how we are going to do this.\nUser must reach URL. User inputs the following, username, comment. User submits comment. Program submits comment to database after running it through some checks. Comment board is updated. Now that we have a general road map there are quite a few things we can extrapolate from this. One, I can already imagine how my data will look. Two, we can create a general rest API from this point forward. Lets start with our data template\nData I decided to go with sqlite because Im not sure that this website will ever get enough use that I will need to migrate away from an sqlite file. Although if it ever did, im sure it wouldn\u0026rsquo;t be too much more complicated to migrate to a MariaDB or a full fledged Sql database.\nIn general lets get what our data structure will look like\n1 2 3 4 5 6 7 Comment { id: String, ip: String, username: String, timestamp: String, visible: int32, } You\u0026rsquo;ll notice there are a few things here that I have added besides the username and comment. One of them being ID. That will be our entry\u0026rsquo;s primary key. I plan on keeping the IP for governance reasons (issue bans, etc), as well as a timestamp, for historical records. The visible key, will be a simple 1 or 0. If it is 1 then it is visible. If it is 0 then it is hidden. Say I get a derogatory or inappropriate comment, I would\u0026rsquo;t want to necessarily delete it these comments should be kept to be referenced to for example for a ban appeal.I would want to especially keep them if it were to say be life threatening etc. So to prevent displaying it, I will switch the visible to 0 and contact or inform the police of said threat. This way, I still have the comment but its not visible.\nAPI From the requirements above, theres a few things we can already build out API wise.\n/comment/new /comment/id/ /comment/ip/ /comment/username/ Building out the API this way also allows us to tailor, how and what we write when we begin to create our program. I now know that I will need quite a few get functions that return data based off of 3 unique queries. I can also identify that I only need one query to create any data.\nI hope that by now you can very clearly see the benefit of planning your program out, before actually typing any code. This will help you keep from getting lost while creating your program.\nThats about it for the theory on how this comment board will work. In the future, when i\u0026rsquo;ve got everything figured out. I may look into creating either a tutorial series on what i\u0026rsquo;ve done so far, or create youtube videos (as there are not many tutorials out on youtube for rust quite yet).\n","date":"2023-08-01T10:07:32-04:00","permalink":"http://localhost:1313/p/2023-08-01-in-dire-need-of-comments/","title":"In dire need of comments"},{"content":"Rust takes forever to build. Im sure I could do alot better deploying the application. But who knows, maybe im doing great at deploying my [comment board](https://unorthodoxdev. net/comment) but what if there is some bug that I introduced that crashes the server 👻. What if while the server is crashed, Im at work??? Well good thing we can customize the default 504 page that nginx uses. So lets get started.\nFirst we will go to our /var/www/html folder and create a page called maintenance.html. Inside of maintenance I have put the following.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026lt;!doctype html\u0026gt; \u0026lt;title\u0026gt;Site Maintenance\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; body { text-align: center; padding: 150px; } h1 { font-size: 50px; } body { font: 20px Helvetica, sans-serif; color: #333; } article { display: block; text-align: left; width: 650px; margin: 0 auto; } a { color: #dc8100; text-decoration: none; } a:hover { color: #333; text-decoration: none; } \u0026lt;/style\u0026gt; \u0026lt;article\u0026gt; \u0026lt;h1\u0026gt;I\u0026amp;rsquo;ll be back soon!\u0026lt;/h1\u0026gt; \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;Sorry for the inconvenience but Im performing some maintenance at the moment. If you need to you can always \u0026lt;a href=\u0026#34;mailto:joshuawintersbrown@gmail.com\u0026#34;\u0026gt;contact me\u0026lt;/a\u0026gt;, otherwise I\u0026amp;rsquo;ll be back online shortly!\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026amp;mdash; Joshua Winters-Brown\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/article\u0026gt; Simple and sweet right? next, we have to edit our nginx default config. You can find that at /etc/nginx/sites-available/default.\nRemember! You must edit this files as sudo!\nInside of our config file, just below your ssl certificates (or your port 80 config. Who knows maybe your rocking http naked). paste the following\n1 2 3 4 5 error_page 502 /maintenance.html; location = /maintenance.html { root /var/www/html; internal; } Next, you will need to restart your nginx server. You can do so via the following command\n1 sudo systemctl restart nginx Now, kill your service, and run to the url to try to capture the error.\n","date":"2023-07-27T12:09:39-04:00","image":"https://images.unsplash.com/photo-1623018035782-b269248df916","permalink":"http://localhost:1313/p/2023-07-27-implementing-a-sick-504-page/","title":"Implementing a Sick 504 Page"},{"content":"Ive migrated my website from the ghost blogging platform to hugo (go hugo, go hugo, go!). Its a little simpler and easier to manage. I also feel as though I have more controll. Currently, im using the hugo-stacked-theme as it looks the most appealing to me, and is not a massive website with insane overhead. It also comes with a indexing feature that allows me (and you ofcourse) to search my content for specific keywords.\nAnother great thing about it being simple is I dont have to constantly monitor that the ghost instance isnt taking too much resources as the web server just lives on a static nginx route. The only thing I will have to get used to is making sure that before I push to the remote repository, that I have ran hugo so that it can build each of my pages.\nCurrently I am manually logging into the web server and pulling the repostory whenever I feel like it. In the future, ideally id set a cron job for every 30 minutes or something like that.\nehhh either way this new cms seems to be working. Keep in touch as im hoping to release a new feature to my website soon :)\n","date":"2023-07-21T10:58:35-04:00","image":"http://localhost:1313/p/2023-07-21-new-bloging-system/this-is-fine_hu14797731310120090098.png","permalink":"http://localhost:1313/p/2023-07-21-new-bloging-system/","title":"New Bloging System"},{"content":"Read the damn instructions. Im working on a new project for the website, and Im trying to upload what I have to github (a simple readme nothing more).\nI create an empty repository, init, add, and commit locally. Set the remote repository, and try to push to the remote\u0026hellip; And it fails? What have I done? What did I do? I have done this probably thousands of times. Where did I mess up? Will I have to recreate the folder? Should I re init the local repo?\nWhat do i do?\nimmediately I search the error error, failed to push some refs to the remote github repository.. I find some stack overflow repository, and I begin reading. I trust stack over flow, they got some smart guys on there. Alot smarter guys on there than me because theres always awnsers to my questions.\nIt doesnt work. It doesnt work, what did I do. I followed the advice of this internet stranger. They posted the awnser recently (2021) what have I done. This is a catosrophic faliure on my end. Ill never be able to recover from this.\nI switch tabs back to my github repository after reading the advice one strange lonlely internet post, and I read the instructions given to me by github.\nOh\u0026hellip;\nIve forgotten to set the primary branch. Maybe ive had too much coffee.\n","date":"2023-07-21T10:50:07-04:00","image":"https://images.unsplash.com/photo-1534481016308-0fca71578ae5","permalink":"http://localhost:1313/p/2023-07-21-read-the-damn-instructions/","title":"Read the Damn Instructions"},{"content":"Ive recently had an encounter with a printer that creates 100s of copies of its self within the computers printer settings. Ive spent quite a bit of time tinkering with this printer and its settings. I think I’ve come to a resolution. Overall, to recap what I did; Opening up the Regedit there were 100’s of keys associated with the Xerox printer. Typically, these registry keys are created when installing the printer and the windows printui.dll handles it. But the amount of registry keys meant that windows kept recreating these keys. I dug a little bit more into the registry keys and it appears that each of these keys had the following properties assigned to them. Name “PRT-AWH-321-COLOR”, Driver “Xerox …” that was pretty much it. The rest of the fields were empty.\nI started off looking into removing these printers via a script etc. Doing so I found the existence of a registry key we can create that would have windows remove the printers on exit. To enable this feature you would have to create a 32bit dWord key in the following location \u0026quot;HKLM:\\Software\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Providers\\Client Side Rendering Print Provider\u0026quot; with the name \u0026quot;RemovePrintersAtLogoff\u0026quot; and the value of 1.\nAfter creating this key, when a user logs out it should clear out any installed printers, and apply the group policy user settings next time a user logs in. Well creating that key and then logging out seemed to work. But those xerox registry keys persisted for some reason. I grabbed one of the GUIDS from a ghost printer and ran a search for all the instances I could find it in regedit. I ran across quite a few instances and ended up writing a script.\nWe start by stopping the printer spooler, and then removing the following:\n1 2 3 4 5 6 7 8 9 10 11 HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Connections HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Printers HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Providers HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\V4 Connections HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Connections HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Printers HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Providers HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\V4 Connections HKCU:\\Printers HKCU:\\Software\\Microsoft\\Windows NT\\CurrentVersion\\PrinterPorts HKEY_USERS\\.DEFAULT\\Printers The following below you need a system user context to remove. You can do so by using PSExec from Windows PowerToys.\n1 2 3 4 5 6 7 HKLM:\\SYSTEM\\CurrentControlSet\\Enum\\SWD\\PRINTENUM HKLM:\\SYSTEM\\CurrentControlSet\\Control\\DeviceClasses\\{0ecef634-6ef0-472a-8085-5ad023ecbccd} HKLM:\\SYSTEM\\ControlSet001\\Enum\\SWD\\PRINTENUM HKLM:\\SYSTEM\\ControlSet001\\Control\\DeviceClasses\\{0ecef634-6ef0-472a-8085-5ad023ecbccd} HKLM:\\SYSTEM\\ControlSet002\\Enum\\SWD\\PRINTENUM HKLM:\\SYSTEM\\ControlSet002\\Control\\DeviceClasses\\{0ecef634-6ef0-472a-8085-5ad023ecbccd} HKLM:\\SYSTEM\\CurrentControlSet\\Control\\Class\\{1ed2bbf9-11f0-4084-b21f-ad83a8e6dcdc} After doing so, when you open up the control panel all the printers should be grayed out. Because these printers are being added via group policy, doing a reboot, should resolve any issues we had previously. Once the computer comes back up again, all of those printers should remain grey, and anything that gets installed via group policy should then fill in with color. But shortly after, it started happening again. I kept getting notifications of the printer installing, over and over and over again.\nWith that, its confirms that it is not some residual left over install, but narrows it down to one or two things. A messed up group policy or a bad driver. Looking at the group policy I could find anything wrong, so I decided to start at the driver. I took the computer off the domain, and downloaded the PCL, General, and PS, driver for the printer.\nOnce the computers off the domain, I remove all printers. And repeat the above steps. After doing so I started with the identical driver installed, the General driver. I setup the printer and as soon as the install finishes. I immediately get the same issue again.\nIts no longer a group policy issue, its now a driver issue. Uninstall all the printers again and start from step one. Once I get to installing the printer I use the PCL driver. I had similar issues. Finally the Post Script (PS) driver ended up working for me and resolved in no issues.\nEither way, cleaning up the ghost printers is a pain in my ass, and is nothing but manual labor. I ended up reimaging the comptuers after fixing the driver on the print server and going from there.\nSince then its seemed to have been fixed.\nScripts part-one.ps1\n1 2 New-ItemProperty -Path \u0026#34;HKLM:\\Software\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Providers\\Client Side Rendering Print Provider\u0026#34; -Name \u0026#34;RemovePrintersAtLogoff\u0026#34; -Value 1 -Force Restart-Computer -Force part-two.ps1\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 Stop-Service spooler -Force Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Connections\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Printers\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Providers\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Print\\V4 Connections\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Connections\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Printers\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\Providers\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows NT\\CurrentVersion\\Print\\V4 Connections\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKCU:\\Printers\u0026#34; -Recurse Remove-Item -Path \u0026#34;HKCU:\\Software\\Microsoft\\Windows NT\\CurrentVersion\\PrinterPorts\u0026#34; -Recurse Remove-Item -Path \u0026#34;Registry::HKEY_USERS\\.DEFAULT\\Printers\u0026#34; -Recurse .\\PsExec.exe /accepteula .\\PsExec.exe powershell Remove-Item -Path \u0026#34;HKLM:\\SYSTEM\\CurrentControlSet\\Enum\\SWD\\PRINTENUM\u0026#34; -Recurse .\\PsExec.exe powershell Remove-Item -Path \u0026#34;HKLM:\\SYSTEM\\CurrentControlSet\\Control\\DeviceClasses\\{0ecef634-6ef0-472a-8085-5ad023ecbccd}\u0026#34; -Recurse .\\PsExec.exe powershell Remove-Item -Path \u0026#34;HKLM:\\SYSTEM\\ControlSet001\\Enum\\SWD\\PRINTENUM\u0026#34; -Recurse -ErrorAction SilentlyContinue .\\PsExec.exe powershell Remove-Item -Path \u0026#34;HKLM:\\SYSTEM\\ControlSet001\\Control\\DeviceClasses\\{0ecef634-6ef0-472a-8085-5ad023ecbccd}\u0026#34; -Recurse -ErrorAction SilentlyContinue .\\PsExec.exe powershell Remove-Item -Path \u0026#34;HKLM:\\SYSTEM\\ControlSet002\\Enum\\SWD\\PRINTENUM\u0026#34; -Recurse -ErrorAction SilentlyContinue .\\PsExec.exe powershell Remove-Item -Path \u0026#34;HKLM:\\SYSTEM\\ControlSet002\\Control\\DeviceClasses\\{0ecef634-6ef0-472a-8085-5ad023ecbccd}\u0026#34; -Recurse -ErrorAction SilentlyContinue .\\PsExec.exe powershell Remove-Item -Path \u0026#34;HKLM:\\SYSTEM\\CurrentControlSet\\Control\\Class\\{1ed2bbf9-11f0-4084-b21f-ad83a8e6dcdc}\u0026#34; -Recurse Restart-Computer -Force ","date":"2023-07-20T16:03:40-04:00","permalink":"http://localhost:1313/p/2023-07-20-ghost-printers/","title":"Ghost Printers"},{"content":"Currently im looking into creating an application to harvest device information using the MECM API. Since I constantly have to research where the MECM Admin service has its hooks, i thought it would be a good idea to add some general information here.\nThe Basics The AdminService is a REST API that runs as a service, independent of the other web components in IIS on your site servers.\nService You can check the status of the service in the console under \\Monitoring\\Overview\\System Status\\Component Status - SMS_REST_PROVIDER\nRead-Only Query Basics Note: All queries in this section use a HTTP GET method. Also, everything is CASE SenSiTiVe.\nGet all Devices https://\u0026lt;ServerName\u0026gt;/AdminService/wmi/SMS_R_System Get All Users https://\u0026lt;ServerName\u0026gt;/AdminService/wmi/SMS_R_User Get Device By ResourceID (same syntax for users) https://\u0026lt;ServerName\u0026gt;/AdminService/wmi/SMS_R_System(12345678) Get User By ResourceID https://\u0026lt;ServerName\u0026gt;/AdminService/wmi/SMS_R_User(12345678) Retrieve related class information. This example gets Operating System information for a specific device. https://\u0026lt;ServerName\u0026gt;/AdminService/wmi/SMS_R_System(12345678)/SMS_G_System_OPERATING_SYSTEM ","date":"2023-07-19T21:02:50-04:00","image":"https://images.unsplash.com/photo-1569653402334-2e98fbaa80ee","permalink":"http://localhost:1313/p/2023-07-19-mecm-api/","title":"MECM API"},{"content":"\nRepository: https://github.com/ofgrenudo/tattoo/tree/master\nTattoo is the first complete program that I have written in rust. It consists of two parts, a library and the binary. One of the challenges I experienced when writing this application was the lack of abbility to include files outside of module\u0026rsquo;s folder that I was writing in. While I understand now why you should not do so and the kinds of compiler problems you would encounter. I think that forcing me to write a library to manage my goals was very benificial for me.\nThis is the first library that I have had to write that actually does something. Something more than one plus one, or something simple you make when you learn C. This library was immediately applicable to my needs. It also helped me keep my programs logically seperate from eachother. The UI was allowed to get input from the UI and handle that. The backend was able to take the information from the UI and transcribe it into the database. This way of seperating the program made a dream like fusion for me when it came to keeping things clean.\nWriting the library also forced me to leverage the rust documentation feature. Really cementing the whole experience together.\nOverall, I really enjoyed the experience making this application and hope to have many more safe adventures with rust :)\nDescription Tattoo is a program designed to automatically collect device information on run, and insert it into the registry of the device. This information is intended for archival purposes and will remain there for later inspection. Some of the bennifits of storing information in the registry is that it provides a static and proctected way to maintain information like,\nThe day the computer was deployed. The task sequence used when you deployed the computer. The asset tag assigned. The device name when deployed. The serial number of the device. The device model. The device make. Requirements Windows \u0026gt;=10, or Windows Server 2016. PowerShell 5.1 or later Running In order to run tattoo.exe you will need at a minimum, the following file along side the executable.\ntatto.exe.manifest\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; standalone=\u0026#34;yes\u0026#34;?\u0026gt; \u0026lt;assembly xmlns=\u0026#34;urn:schemas-microsoft-com:asm.v1\u0026#34; manifestVersion=\u0026#34;1.0\u0026#34;\u0026gt; \u0026lt;assemblyIdentity version=\u0026#34;1.0.0.0\u0026#34; processorArchitecture=\u0026#34;*\u0026#34; name=\u0026#34;app\u0026#34; type=\u0026#34;win32\u0026#34; /\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;dependentAssembly\u0026gt; \u0026lt;assemblyIdentity type=\u0026#34;win32\u0026#34; name=\u0026#34;Microsoft.Windows.Common-Controls\u0026#34; version=\u0026#34;6.0.0.0\u0026#34; processorArchitecture=\u0026#34;*\u0026#34; publicKeyToken=\u0026#34;6595b64144ccf1df\u0026#34; language=\u0026#34;*\u0026#34; /\u0026gt; \u0026lt;/dependentAssembly\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/assembly\u0026gt; Otherwise it will throw an error exit code: 0xc0000139, STATUS_ENTRYPOINT_NOT_FOUND when trying to run the program. This is a bug with the native windows gui API that has not been resolved.\nExample Screenshots ","date":"2023-07-19T21:01:44-04:00","permalink":"http://localhost:1313/p/2023-07-19-tattoo/","title":"Tattoo"},{"content":"Give a man a fish, and you feed him for a day. Teach a man to fish, and you feed him for a lifetime.\nCI, Continuous onus Integration allows for each member of a team to integrate their changes into the main branch, multiple times a day.\nContinuous Integration allows us to tighten the feed back loop. We are less likely to go off on your own and develop for days or weeks just to find out the approach you have taken isn\u0026rsquo;t working, or isn\u0026rsquo;t approved by peers. Continuous Integration forces you to work with your teammates earlier than when you feel is comfortable allowing for course correcting actions to be taken before you have wasted your time. So how do we make Continuous Integration a reality?\nTests Code Coverage Linting Formatting Security Vulnerabilities Tests Tests in rust are a first-class concept. This being said rust allows you to easily leverage the rust ecosystem to run unit and integration tests using\n1 cargo test cargo test also takes care of building the project before running tests saving you a command or two.\nCode Coverage Code coverage is a easy way to see if we have overlooked any section of the code base that have been poorly tested. The easiest way to measure code coverage of a rust project is via cargo tarpaulin a cargo subcommand developed by xd009642. You can install tarpaulin with\n1 cargo install cargo-tarpaulin You can run cargo-tarpaulin with\n1 cargo tarpaulin --ignore-tests Linting Rust maintains clippy the official rust linter. Clippy is included in the set of components installed by rustup if you are using the default profile. You can run clippy with\n1 cargo clippy In this CI pipeline we would like to fail the linter check if clippy emits any warnings. To do so we can run the following command\n1 cargo clippy -- -D warnings Note, from time to time clippy might suggest something you do not belive to be correct or desirable. You can mute these warnings with the following\n1 #[allow(clippy::lint_name)] Formatting Let machines deal with formatting while reviewers focus on architecture, testing thoroughness, reliability, and observability. Automated formatting removes a distraction from the complex equation of the PR review process. You might dislike this or that formatting choice but the complete erasure of formatting bikeshedding is worth the minor discomfort.\nRust actually has a built in formatter called rustfmt. rustfmt should be included in the default rustup components but if you are missing it you can install it via\n1 rustup component add rustfmt To format your whole project you can run\n1 cargo fmt In the CI pipeline we will ad a formatting step.\n1 cargo fmt -- --check This will ultimately fail when a commit contains unformatted code, printing the difference to the console. You can tune a project with a configuration file rustfmt.toml.\nSecurity Vulnerabilities Caro makes it very easy to leverage existing crates in the ecosystem to solve at hand. On the flip side, each of those crates might hide an exploitable vulnerability that could compromise the security posture of your software. The Rust Secure Code group maintains an Advisory Database on reported vulnerabilities for crates published on crates.io. You can leverage this advisory database with a tool called cargo-audit. You can install it with\n1 cargo install cargo-audit To use it you can run\n1 cargo audit Github Actions Below are some github actions you can add to your CI routines. To use them you will want too create the github actions folder and drop each of these files inside.\n1 2 mkdir -p .github/workflows cd .github/workflows audit.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 name: Security audit on: schedule: - cron: \u0026#39;0 0 * * *\u0026#39; push: paths: - \u0026#39;**/Cargo.toml\u0026#39; - \u0026#39;**/Cargo.lock\u0026#39; jobs: security_audit: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - uses: taiki-e/install-action@cargo-deny - name: Scan for vulnerabilities run: cargo deny check advisories general.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 name: Rust on: push: branches: - main pull_request: types: [ opened, synchronize, reopened ] branches: - main env: CARGO_TERM_COLOR: always SQLX_VERSION: 0.6.2 SQLX_FEATURES: \u0026#34;rustls\u0026#34; jobs: test: name: Test runs-on: ubuntu-latest services: steps: - uses: actions/checkout@v3 - uses: dtolnay/rust-toolchain@stable - uses: Swatinem/rust-cache@v2 - name: Run tests run: cargo test fmt: name: Rustfmt runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - uses: dtolnay/rust-toolchain@stable with: components: rustfmt - name: Enforce formatting run: cargo fmt --check clippy: name: Clippy runs-on: ubuntu-latest services: postgres: image: postgres:14 env: POSTGRES_USER: postgres POSTGRES_PASSWORD: password POSTGRES_DB: postgres ports: - 5432:5432 steps: - uses: actions/checkout@v3 - uses: dtolnay/rust-toolchain@stable with: components: clippy - uses: Swatinem/rust-cache@v2 - name: Linting run: cargo clippy -- -D warnings coverage: name: Code coverage runs-on: ubuntu-latest services: steps: - name: Checkout repository uses: actions/checkout@v3 - uses: dtolnay/rust-toolchain@stable - name: Generate code coverage run: cargo tarpaulin --verbose --workspace ","date":"2023-07-19T21:01:12-04:00","image":"https://images.unsplash.com/photo-1609213244695-7d6902be89da","permalink":"http://localhost:1313/p/2023-07-19-ci-pipelines-with-rust/","title":"Ci Pipelines With Rust"},{"content":"Everybody knows about uBlock Origin. The browser extension that blocks ads right? Well most ads. Theres often ads from social medias sites like facebook and twitter that slip through really.\nAlthough I recently learned that uBlock has the capability to extend those block lists. The easiset way to add capabilities to your uBlock is to find these pre made lists of URLs and it should begin to block those ads for you. These are really the same lists that DNS filters like pi-hole use.\nA good website that has some of these lists are https://easylist.to\nBrowse to the website, and find what ever list you want and then select the button add it to your blocker.\nThis will open a new tab, and then uBlock will prompt you to subscribe it it. Select \u0026lsquo;Subscribe\u0026rsquo; and then you will be live with that list.\n","date":"2023-07-19T21:00:06-04:00","image":"https://images.unsplash.com/photo-1496442226666-8d4d0e62e6e9","permalink":"http://localhost:1313/p/2023-07-19-ublock-origin-and-more/","title":"Ublock Origin and More"},{"content":"Outline What is a Digital Garden? A place for ideas to grow. A place for critiques. An exercise in learning in public. Learn In Public Humility. Honesty. Generate Resources that you wish you had. Work In Public Document Your Self. Document Your Steps Working In Public Forces you to Work your Metacognitive Mind. Resources What is a digital garden? https://notes.joschua.io/50+Slipbox/Digital+garden Work In Public https://nesslabs.com/work-in-public Learn In Public https://www.swyx.io/learn-in-public Pick Up What They Put Down https://www.swyx.io/puwtpd Learn In Private https://www.swyx.io/learn-in-private How do Rocket Scientists Learn https://www.govloop.com/community/blog/how-do-rocket-scientists-learn-aka-knowledge-management-lessons-learned-at-goddard-nasa/ What is a Digital Garden? A digital garden to me is a place for for my ideas, projects, and thoughts to be planted in, and sprout and grow in the future. Besides a personal journal on my computer Ive decided to make it a publicly facing blog. Ive decided to so for a few reasons. A digital garden allows space for critiques from others. I don\u0026rsquo;t know everything, nor do I know the best way to do one thing. Posting things publicly allows for a criticism from netizens.\n\u0026ldquo;As I grow, my notes will grow. They will mature from that seed to a full grown plant later in the future.\u0026rdquo; (Digital Garden, Joschua) This is a practice of Working in Public.\nWorking In Public Studies show that statistically, people are more likely to do stuff if they keep their intentions in private. But at times though that statement can seem counter intuitive. Often, people share their weight loss publicly on Facebook or Twitter or Instagram. Many report that doing so is a great way to stay motivated.\nWhen you think about it, some of the reason, people post things online is because it provides a way for you to receive praise along the way. A quote that sticks with me is\n\u0026ldquo;Become a documentarian of what you do\u0026rdquo; - Austin Kleon, Author of Show Your Work\nBecoming a documentarian means that you will develop very quickly\nYour Metacognition Quick Feedback Loops on Content Increased Creativity. By documenting your self, you are working your Metacognition. You are working on thinking of your thoughts. Should I have done that? Should I have done this instead. Why did I take that route? Was it because of an experience I had? Working your metacognition and thinking about your thinking allows for you to quickly determine fallacies in your thought pattern. It also helps you explain in better depth, what you are working on.\nWorking in public also forces you to document not only your thoughts, but also your steps taken to get there. Doing this its self can help you identify un necessary steps and find better work flows.\n","date":"2023-07-19T20:59:39-04:00","image":"https://images.unsplash.com/photo-1550948390-6eb7fa773072","permalink":"http://localhost:1313/p/2023-07-19-digital-gardens/","title":"Digital Gardens"},{"content":" ⚠️ Danger You will need administrative access to the device in question. Changing a hostname can have unintended catastrophic consequences if done without proper consideration.\nA hostname is a computers human readable address that allows you to communicate with it, regardless of weather or not you know what its IP address is. Hostnames are pratcial and easy to remember. For whatever reason if you need to reset your hostname on a linux machine, you can follow the below instructions\nTo view your current hostname type\n1 $ hostname When I do so on the current machine, I see that for whatever reason the machines name is set to localhost. This is a problem as localhost also happens to be an alias to 127.0.0.1.\nTemporarily To temporarily reset the hostname of the machine I should do the following\n1 $ hostname changeme Again though, unfortunately this only keeps the hostname that way until the next reboot. This might be good for testing or even just to get a prod server off of a bearing load and replace it with a backup server. But for a more permanent and serious effect, we should do the following.\nPermanently 1 $ hostnamectl set-hostname imstuck The above command should set the hostname immediately as well as it should stick beyond a reboot. To confirm that the name has been configured permanently we can check the following file /etc/hostname and confirm the contents are what we are expecting. The thing I would do in this case is to reboot as soon as possible so that permanent hostname can really take affect and your DNS servers can update accordingly.\n","date":"2023-07-19T20:58:46-04:00","image":"https://images.unsplash.com/photo-1532630174493-69e1fe9fead2","permalink":"http://localhost:1313/p/2023-07-19-setting-a-hostname-on-linux/","title":"Setting a Hostname on Linux"},{"content":"These notes should work on given any GNU / Linux based operating system. Although, should you run into any road blocks future me. Im sorry for lying to you :(.\nService Monitoring Services are a integral part of every operating system. How can I monitor and troubleshoot system services when things go wrong?\nSystem Services This command in a very cute way, will display all of the services installed on your server, and then display them accordingly with + or - signs to indicate weather or not it is running.\n1 service --status-all Using grep, you can highlight services that are running (+) or stopped (-) for easy identification.\n1 service --status-all | grep \u0026#34;[ + ]\u0026#34; Grep can also help you identify a specific service given you know the name like ssh\nRunning Process\u0026rsquo;s PS displays information about a selection of the active processes. It is an alternative to TOP that only prints once. By default ps selects all processes with the same user id (EUID). It will show you the Process ID (PID) and the terminal associated with the process (TTY), the cumulated cpu time in [DD-]hh:mm:ss and the executable name (CMD).\nThe below command will display all processes initiated by the user.\n1 ps If you want to see a specific users processes you can do the following\n1 ps -U root -u root u If you want to view every process on the system, you can do\n1 ps -e Network Related Services The below command will allow you to view all current connections and listening services on a system along with the processes and PIDs for each connection. It requires that you have the net-tools package installed.\n1 netstat -tulpn Say I wanted to look at what process was running on port 22\n1 netstat -tulpn | grep \u0026#34;22\u0026#34; The above command will return an output of any port that has 22 in it. For me currently, I have two services listening on port 22. One for IPv4 and IPv6\nExample Output\n1 2 3 $ netsatat -tulpn | grep \u0026#34;22\u0026#34; tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN - tcp6 0 0 :::22 :::* LISTEN - Networking Shenanigans Soy baboon, hay problemas de redes; ooh ooh ahh ahh.\nFirst things first Where am i on the subnet? The below tools will help you troubleshoot where your are on the subnet, what might be missing, and or misconfigured. To get a quick overview of all of your connected network cards, you can run the following command\n1 networkctl status It will print out the following information:\nState: Routable or Not Online Status Address (IPv4 and IPv6) Gateway Address including the associated port. DNS Servers Domains NTP Servers. Network Card Configurations. If everything above looks good we can move on to looking more closely at our network cards.\nWhats my ip? The ip command allows you to show address information, manipulate routing, and display network devices, interfaces, and tunnels. It is a simple concept and hard tool to learn. There really five (5) modes to ip.\nTunnel (Tunnel over IP) Route (Routing table entry) Rule (rule in routing policy database) VRF (Manage virtual routing and forwarding devices) XFRM (Manage IPSec policies) To find the IP addresses assigned to your server, use\n1 ip address show This will give you each interface, numbered from 1 to ♾️ including the status (UP or DOWN), IPv4 and IPv6 address, and subnet mask and broadcast address.\n![[ip-address-show.png]]\nTo force a static IP address on a interface, you can do the following\n1 ip address add 10.66.10.9/16 dev eth0 Then you will want to reboot the network card.\n1 2 ip link set eth0 down ip link set eth0 up Make sure for the above command you are physically connected to the server otherwise, you may lose connection if your actively using eth0.\nIf things are still looking good, we can move on too routes.\n1 ip route This will show all of routes advertised by our DHCP server as available as well as their weighted value identified by the metric lable. You should have a few things listed here. If not I would investigate that.\nMy connection is getting dropped, or reset somewhere along the wire. MTR (Matts Trace-route) is a program that allows you to diagnose issues like these. To use MTR, you will want to do the following\n1 mtr google.com My favorite flag to use with this is -b it shows the dns name as well as the IP side by side allowing for a quick analysis of the network having issues.\n1 mtr -b google.com You can also send a predetermined amount of pings with the -c flag. Otherwise known as count it allows you to select how many packets to send.\n1 mtr -c 100 -b google.com The final command you will need to know about with mtr is -r or record. This allows you to output the information into a txt file for later usage.\n1 mtr -r -c 20 google.com \u0026gt; mtr-google.log Note that doing so will lock your terminal working on dumping that data so I would recommend a smaller count. If you really wanted to get something running and then do something else in the mean time, you could apply a ampersand (\u0026amp;) to the end of your command to have it run in the background. It will spit out a PID that you can search for later to see if its complete with\n1 ps -e | grep 15225 Monitoring network traffic So, everything looks good, but data is still coming back corrupted? Lets look at the raw packets.\nThe below command allows us to capture all traffic that comes or goes from this interface within the following ip and subnet range.\n1 tcpdump -i eth0 net 10.66.0.0/16 We can also filter based on source (src) or destination (dst).\n1 tcpdump -i eth src net 10.1.0.0/24 or\n1 tcpdump -i eth dst net 10.1.0.0/24 Finally we can also capture traffic only coming or going from a specific port.\n1 tcpdump -i eth0 port 53 Combining the port traffic with a specific host\n1 tcpdump -i eth0 host 10.66.10.123 and port 53 ","date":"2023-07-19T20:58:00-04:00","image":"https://images.unsplash.com/photo-1640552435388-a54879e72b28","permalink":"http://localhost:1313/p/2023-07-19-linux-administration-tips-and-tricks/","title":"Linux Administration Tips and Tricks"},{"content":"Windows 11 and Start Menus suck. Nothing works the way Microsoft says it should unless you use Intune. So to get around it, we just copy the bin. For now I\u0026rsquo;m doing both, considering sometime in the future Microsoft might get its stuff together and allow the JSON file to work.\nCreating a new Layout On a build PC configure your new layout. run the Export-StartLayout command. Modify the StartLayout file and change the pinnedList to primaryOEMPins Copy the JSON file to C:\\Users\\Default\\AppData\\Local\\Microsof\\Windows\\Shell Alternatively, windows holds an encrypted version of the startup file in the %LocalAppData%\\Packages\\Microsoft.Windows.StartMenuExperienceHost_cw5n1h2txyewy\\LocalState folder. Copying the start.bin file to whatever computers same folder, will essentially do the same thing.\nI\u0026rsquo;ve also created a mini program that you can use to quickly do the above commands to quickly reproduce the steps above. I will put the latest version of the source blow, alternatively you can check my Github repository out here https://github.com/ofgrenudo/confs/tree/main/scripts/windows/start-layouts\nInstall.bat\n1 2 cmd /c copy LayoutModification.json C:\\Users\\Default\\appdata\\local\\Microsoft\\Windows\\Shell\\LayoutModification.json /y cmd /c copy start.bin C:\\Users\\Default\\AppData\\Local\\Packages\\Microsoft.Windows.StartMenuExperienceHost_cw5n1h2txyewy\\LocalState do-it-again.bat\n1 2 3 4 5 6 7 @echo off powershell.exe Invoke-Command -scriptbloc {\u0026#34;Export-StartLayout -Path LayoutModifications.json\u0026#34;} cmd /c copy %LocalAppdata%\\Packages\\Microsoft.Windows.StartMenuExperienceHost_cw5n1h2txyewy\\LocalState\\start.bin start.bin /y cmd /c copy %LocalAppdata%\\Packages\\Microsoft.Windows.StartMenuExperienceHost_cw5n1h2txyewy\\LocalState\\start2.bin start.bin /y cls Echo Remember to Update pinnedList to primaryOEMPins pause ","date":"2023-07-19T12:31:03-04:00","permalink":"http://localhost:1313/p/2023-07-19-custom-start-menu-layouts/","title":"Custom Start Menu Layouts"},{"content":" Note! I have migrated away from ghost blog and now manage my site on hugo!\nFor some reason when I was looking up how to change [[domain names]] for my ghost blog, I kept running into recommendations that stated I should just reinstall ghost. I really don\u0026rsquo;t want to do that especially since so much content exists on this server already. It also reminded me that I probably need to take regular backups of the server anyways. Or at least, double book blog posts somewhere just in case! (Truthfully most posts end up in my notebook to begin with, and end up polished on the website). Below are my steps to migrate my blogs DNS record.\nSet your new DNS record, a day in advanced to the IP address of your server. In my case I was migrating from https://blog.unorthodoxdev.net to https://unorthodoxdev.net. I created a ANAME record and allowed it to propagate overnight. In the morning, I did the below steps.\nghost config url {new_url} rm /etc/nginx/sites-enabled/*.conf ghost setup ssl ghost restart Finally you want to visit your website and check your cert and go from there!\nI would also like to throw in that you might want to remove your ANAME record for whatever your website was before and upgrade it to a CNAME record. CNAME records are really just a redirect to whatever ANAME record you provide it.\n","date":"2023-07-19T12:20:21-04:00","image":"https://images.unsplash.com/photo-1628595351029-c2bf17511435","permalink":"http://localhost:1313/p/2023-07-19-migrating-ghost-blog-domain-names/","title":"Migrating Ghost Blog Domain Names"}]